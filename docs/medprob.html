<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>A Breve Resumo de Medida e Probabilidade | Fundamentos de Inferência Bayesiana</title>
  <meta name="description" content="Notas de aula de Infência Bayesiana." />
  <meta name="generator" content="bookdown 0.23 and GitBook 2.6.7" />

  <meta property="og:title" content="A Breve Resumo de Medida e Probabilidade | Fundamentos de Inferência Bayesiana" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notas de aula de Infência Bayesiana." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Breve Resumo de Medida e Probabilidade | Fundamentos de Inferência Bayesiana" />
  
  <meta name="twitter:description" content="Notas de aula de Infência Bayesiana." />
  

<meta name="author" content="Victor Fossaluza e Luís Gustavo Esteves" />


<meta name="date" content="2021-09-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="R.html"/>
<link rel="next" href="referências.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.4.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.57.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notas de Aula de Inferência Bayesiana</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prefácio</a></li>
<li class="chapter" data-level="2" data-path="ProbSubj.html"><a href="ProbSubj.html"><i class="fa fa-check"></i><b>2</b> Probabilidade Subjetiva</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ProbSubj.html"><a href="ProbSubj.html#definição-axiomática"><i class="fa fa-check"></i><b>2.1</b> Definição Axiomática</a></li>
<li class="chapter" data-level="2.2" data-path="ProbSubj.html"><a href="ProbSubj.html#interpretações-de-probabilidade"><i class="fa fa-check"></i><b>2.2</b> Interpretações de Probabilidade</a></li>
<li class="chapter" data-level="2.3" data-path="ProbSubj.html"><a href="ProbSubj.html#relação-de-crença-precsim"><i class="fa fa-check"></i><b>2.3</b> Relação de Crença <span class="math inline">\(\precsim\)</span></a></li>
<li class="chapter" data-level="2.4" data-path="ProbSubj.html"><a href="ProbSubj.html#medida-de-probabilidade-que-representa-precsim"><i class="fa fa-check"></i><b>2.4</b> Medida de Probabilidade que “representa” <span class="math inline">\(\precsim\)</span></a></li>
<li class="chapter" data-level="2.5" data-path="ProbSubj.html"><a href="ProbSubj.html#medida-de-probabilidade-condicional"><i class="fa fa-check"></i><b>2.5</b> Medida de Probabilidade Condicional</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Bayes.html"><a href="Bayes.html"><i class="fa fa-check"></i><b>3</b> Introdução à Inferência Bayesiana</a>
<ul>
<li class="chapter" data-level="3.1" data-path="Bayes.html"><a href="Bayes.html#BasBayes"><i class="fa fa-check"></i><b>3.1</b> Conceitos Básicos</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="Bayes.html"><a href="Bayes.html#inferência-frequentista-ou-clássica"><i class="fa fa-check"></i><b>3.1.1</b> Inferência Frequentista (ou Clássica)</a></li>
<li class="chapter" data-level="3.1.2" data-path="Bayes.html"><a href="Bayes.html#inferência-bayesiana"><i class="fa fa-check"></i><b>3.1.2</b> Inferência Bayesiana</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="Bayes.html"><a href="Bayes.html#teorema-de-de-finetti"><i class="fa fa-check"></i><b>3.2</b> Teorema de De Finetti</a></li>
<li class="chapter" data-level="3.3" data-path="Bayes.html"><a href="Bayes.html#suficiência"><i class="fa fa-check"></i><b>3.3</b> Suficiência</a></li>
<li class="chapter" data-level="3.4" data-path="Bayes.html"><a href="Bayes.html#distribuição-a-priori"><i class="fa fa-check"></i><b>3.4</b> Distribuição a Priori</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="Bayes.html"><a href="Bayes.html#método-do-histograma"><i class="fa fa-check"></i><b>3.4.1</b> Método do Histograma</a></li>
<li class="chapter" data-level="3.4.2" data-path="Bayes.html"><a href="Bayes.html#elicitação-de-hiperparâmetros"><i class="fa fa-check"></i><b>3.4.2</b> Elicitação de Hiperparâmetros</a></li>
<li class="chapter" data-level="3.4.3" data-path="Bayes.html"><a href="Bayes.html#prioris-conjugadas"><i class="fa fa-check"></i><b>3.4.3</b> Prioris Conjugadas</a></li>
<li class="chapter" data-level="3.4.4" data-path="Bayes.html"><a href="Bayes.html#prioris-não-informativas"><i class="fa fa-check"></i><b>3.4.4</b> Prioris “Não-Informativas”</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="Bayes.html"><a href="Bayes.html#alguns-princípios-de-inferência"><i class="fa fa-check"></i><b>3.5</b> Alguns Princípios de Inferência</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="TeoDec.html"><a href="TeoDec.html"><i class="fa fa-check"></i><b>4</b> Introdução à Teoria da Decisão</a>
<ul>
<li class="chapter" data-level="4.1" data-path="TeoDec.html"><a href="TeoDec.html#BasDec"><i class="fa fa-check"></i><b>4.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="4.2" data-path="TeoDec.html"><a href="TeoDec.html#Aleat"><i class="fa fa-check"></i><b>4.2</b> Aleatorização e Decisões Mistas</a></li>
<li class="chapter" data-level="4.3" data-path="TeoDec.html"><a href="TeoDec.html#DecDados"><i class="fa fa-check"></i><b>4.3</b> Problemas com Dados</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Estimacao.html"><a href="Estimacao.html"><i class="fa fa-check"></i><b>5</b> Estimação</a>
<ul>
<li class="chapter" data-level="5.1" data-path="Estimacao.html"><a href="Estimacao.html#estimação-pontual"><i class="fa fa-check"></i><b>5.1</b> Estimação Pontual</a></li>
<li class="chapter" data-level="5.2" data-path="Estimacao.html"><a href="Estimacao.html#estimação-por-regiões"><i class="fa fa-check"></i><b>5.2</b> Estimação por Regiões</a></li>
<li class="chapter" data-level="5.3" data-path="Estimacao.html"><a href="Estimacao.html#custo-das-observações"><i class="fa fa-check"></i><b>5.3</b> Custo das Observações</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Test.html"><a href="Test.html"><i class="fa fa-check"></i><b>6</b> Testes de Hipóteses</a>
<ul>
<li class="chapter" data-level="6.1" data-path="Test.html"><a href="Test.html#BasTest"><i class="fa fa-check"></i><b>6.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="6.2" data-path="Test.html"><a href="Test.html#revisão-abordagem-frequentista"><i class="fa fa-check"></i><b>6.2</b> Revisão: Abordagem Frequentista</a></li>
<li class="chapter" data-level="6.3" data-path="Test.html"><a href="Test.html#abordagem-bayesiana-via-teoria-da-decisão"><i class="fa fa-check"></i><b>6.3</b> Abordagem Bayesiana (via Teoria da Decisão)</a></li>
<li class="chapter" data-level="6.4" data-path="Test.html"><a href="Test.html#probabilidade-posterior-de-h_0"><i class="fa fa-check"></i><b>6.4</b> Probabilidade Posterior de <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="6.5" data-path="Test.html"><a href="Test.html#fator-de-bayes"><i class="fa fa-check"></i><b>6.5</b> Fator de Bayes</a></li>
<li class="chapter" data-level="6.6" data-path="Test.html"><a href="Test.html#teste-de-jeffreys"><i class="fa fa-check"></i><b>6.6</b> Teste de Jeffreys</a></li>
<li class="chapter" data-level="6.7" data-path="Test.html"><a href="Test.html#hipóteses-precisas"><i class="fa fa-check"></i><b>6.7</b> Hipóteses Precisas</a></li>
<li class="chapter" data-level="6.8" data-path="Test.html"><a href="Test.html#fbst---full-bayesian-significance-test"><i class="fa fa-check"></i><b>6.8</b> FBST - <em>Full Bayesian Significance Test</em></a></li>
<li class="chapter" data-level="6.9" data-path="Test.html"><a href="Test.html#p-value---nível-de-significância-adaptativo"><i class="fa fa-check"></i><b>6.9</b> P-value - Nível de Significância Adaptativo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Comp.html"><a href="Comp.html"><i class="fa fa-check"></i><b>7</b> Métodos Computacionais</a>
<ul>
<li class="chapter" data-level="7.1" data-path="Comp.html"><a href="Comp.html#método-de-monte-carlo"><i class="fa fa-check"></i><b>7.1</b> Método de Monte Carlo</a></li>
<li class="chapter" data-level="7.2" data-path="Comp.html"><a href="Comp.html#monte-carlo-com-amostragem-de-importância"><i class="fa fa-check"></i><b>7.2</b> Monte Carlo com Amostragem de Importância</a></li>
<li class="chapter" data-level="7.3" data-path="Comp.html"><a href="Comp.html#método-de-rejeição"><i class="fa fa-check"></i><b>7.3</b> Método de Rejeição</a></li>
<li class="chapter" data-level="7.4" data-path="Comp.html"><a href="Comp.html#abc-aproximated-bayesian-computation"><i class="fa fa-check"></i><b>7.4</b> ABC (Aproximated Bayesian Computation)</a></li>
<li class="chapter" data-level="7.5" data-path="Comp.html"><a href="Comp.html#mcmc---monte-carlo-via-cadeias-de-markov"><i class="fa fa-check"></i><b>7.5</b> MCMC - Monte Carlo via Cadeias de Markov</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="Comp.html"><a href="Comp.html#pequena-introdução-às-cadeias-de-markov"><i class="fa fa-check"></i><b>7.5.1</b> Pequena Introdução às Cadeias de Markov</a></li>
<li class="chapter" data-level="7.5.2" data-path="Comp.html"><a href="Comp.html#o-algoritmo-de-metrópolis-hastings"><i class="fa fa-check"></i><b>7.5.2</b> O algoritmo de <strong>Metrópolis-Hastings</strong></a></li>
<li class="chapter" data-level="7.5.3" data-path="Comp.html"><a href="Comp.html#amostrador-de-gibbs"><i class="fa fa-check"></i><b>7.5.3</b> Amostrador de Gibbs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="R.html"><a href="R.html"><i class="fa fa-check"></i><b>8</b> Bibliotecas de R para Inferência Bayesiana</a>
<ul>
<li class="chapter" data-level="8.1" data-path="R.html"><a href="R.html#o-modelo-de-regressão-linear"><i class="fa fa-check"></i><b>8.1</b> O Modelo de Regressão Linear</a></li>
<li class="chapter" data-level="8.2" data-path="R.html"><a href="R.html#laplaces-demon"><i class="fa fa-check"></i><b>8.2</b> Laplace’s Demon</a></li>
<li class="chapter" data-level="8.3" data-path="R.html"><a href="R.html#stan"><i class="fa fa-check"></i><b>8.3</b> Stan</a></li>
<li class="chapter" data-level="8.4" data-path="R.html"><a href="R.html#mlg"><i class="fa fa-check"></i><b>8.4</b> MLG</a></li>
<li class="chapter" data-level="8.5" data-path="R.html"><a href="R.html#modelos-dinâmicos"><i class="fa fa-check"></i><b>8.5</b> Modelos Dinâmicos</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="R.html"><a href="R.html#dados-de-amoxicilina-fonte-cea"><i class="fa fa-check"></i><b>8.5.1</b> Dados de Amoxicilina (fonte: CEA)</a></li>
<li class="chapter" data-level="8.5.2" data-path="R.html"><a href="R.html#dados-de-covid-19"><i class="fa fa-check"></i><b>8.5.2</b> Dados de Covid-19</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Apêndice</b></span></li>
<li class="chapter" data-level="A" data-path="medprob.html"><a href="medprob.html"><i class="fa fa-check"></i><b>A</b> Breve Resumo de Medida e Probabilidade</a>
<ul>
<li class="chapter" data-level="A.1" data-path="medprob.html"><a href="medprob.html#basprob"><i class="fa fa-check"></i><b>A.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="A.2" data-path="medprob.html"><a href="medprob.html#lebesgue"><i class="fa fa-check"></i><b>A.2</b> Valor Esperado de <span class="math inline">\(X\)</span> (OU uma ideia da tal Integral de Lebesgue)</a></li>
<li class="chapter" data-level="A.3" data-path="medprob.html"><a href="medprob.html#funções-de-variáveis-aleatórias"><i class="fa fa-check"></i><b>A.3</b> Funções de Variáveis Aleatórias</a></li>
<li class="chapter" data-level="A.4" data-path="medprob.html"><a href="medprob.html#função-de-distribuição"><i class="fa fa-check"></i><b>A.4</b> Função de Distribuição</a></li>
<li class="chapter" data-level="A.5" data-path="medprob.html"><a href="medprob.html#probabilidade-condicional"><i class="fa fa-check"></i><b>A.5</b> Probabilidade Condicional</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referências.html"><a href="referências.html"><i class="fa fa-check"></i>Referências</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Inferência Bayesiana</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="medprob" class="section level1" number="9">
<h1><span class="header-section-number">A</span> Breve Resumo de Medida e Probabilidade</h1>
<p>Essa seção tem o objetivo de apresentar as ideias de probabilidade como uma medida e da integral de Lebesgue. Para maiores detalhes, ver <span class="citation"><a href="#ref-Ash00" role="doc-biblioref">Ash and Doleans-Dade</a> (<a href="#ref-Ash00" role="doc-biblioref">2000</a>)</span>, <span class="citation"><a href="#ref-Billingsley86" role="doc-biblioref">Billingsley</a> (<a href="#ref-Billingsley86" role="doc-biblioref">1986</a>)</span>, <span class="citation"><a href="#ref-Shiryaev96" role="doc-biblioref">Shiryaev</a> (<a href="#ref-Shiryaev96" role="doc-biblioref">1996</a>)</span> ou, para uma versão mais resumida, os Apêndices de <span class="citation"><a href="#ref-Schervish12" role="doc-biblioref">Schervish</a> (<a href="#ref-Schervish12" role="doc-biblioref">2012</a>)</span>.</p>
<div id="basprob" class="section level2" number="9.1">
<h2><span class="header-section-number">A.1</span> Conceitos Básicos</h2>
<ul>
<li><p><span class="math inline">\(\Omega\)</span>: espaço amostral (um conjunto não vazio).</p></li>
<li><p><span class="math inline">\(\mathcal{A}\)</span>: <em><span class="math inline">\(\sigma\)</span>-álgebra de subconjuntos</em> de <span class="math inline">\(\Omega\)</span>, isto é,</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\Omega \in \mathcal{A}\)</span>;</li>
<li><span class="math inline">\(A \in \mathcal{A} \Longrightarrow A^{c} \in \mathcal{A}\)</span>;</li>
<li><span class="math inline">\(\displaystyle A_1, A_2, \ldots \in \mathcal{A} \Longrightarrow \bigcup_{i\geq1} A_i \in \mathcal{A}\)</span>.</li>
</ol></li>
<li><p>Os elementos de <span class="math inline">\(\mathcal{A}\)</span> são chamados de <em>eventos</em> e serão denotados por <span class="math inline">\(A, B, C, \ldots, A_1, A_2, \ldots\)</span></p></li>
<li><p>Uma coleção de eventos <span class="math inline">\(A_1,A_2,\ldots\)</span> forma uma <em>partição</em> de <span class="math inline">\(\Omega\)</span> se <span class="math inline">\(A_i \cap A_j = \varnothing\)</span>, <span class="math inline">\(\forall i \neq j\)</span>, e <span class="math inline">\(\displaystyle \bigcup_{i=1}^{\infty} A_i = \Omega\)</span>.</p></li>
<li><p><span class="math inline">\((\Omega, \mathcal{A})\)</span>: <em>espaço mensurável</em>.</p></li>
<li><p>Usualmente, denota-se a <span class="math inline">\(\sigma\)</span>-álgebra gerada por um conjunto <span class="math inline">\(\mathcal{C}\)</span> como <span class="math inline">\(\sigma(\mathcal{C})\)</span>. Por exemplo:</p>
<ul>
<li><span class="math inline">\(\sigma(\Omega) = \{\varnothing,\Omega\}~~\)</span> (<span class="math inline">\(\sigma\)</span>-ágebra trivial);</li>
<li>Para <span class="math inline">\(A \subset \Omega\)</span>, <span class="math inline">\(\sigma(A) = \{\varnothing, A, A^c, \Omega\}\)</span>;</li>
<li><span class="math inline">\(\sigma(\mathbb{N}) = \mathcal{P}(\mathbb{N})~~\)</span> (partes de <span class="math inline">\(\mathbb{N}\)</span>, todos o subconjuntos de <span class="math inline">\(\mathbb{N}\)</span>);</li>
<li><span class="math inline">\(\sigma\left(\left\{(-\infty,x): x \in \mathbb{R}\right\}\right) = \mathcal{B}\left(\mathbb{R}\right)~~\)</span> (borelianos de <span class="math inline">\(\mathbb{R}\)</span>)</li>
</ul></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição:</strong> A função <span class="math inline">\(\mu: \mathcal{A} \longrightarrow \bar{\mathbb{R}}_+\)</span> é uma <em>medida</em> se<br />
1. <span class="math inline">\(\mu(\varnothing) = 0\)</span>;<br />
2. <span class="math inline">\(\displaystyle A_1, A_2, \ldots \in \mathcal{A}\)</span> com <span class="math inline">\(A_i \bigcap A_j = \varnothing\)</span> , <span class="math inline">\(\forall i \neq j\)</span> , <span class="math inline">\(\displaystyle \mu\left(\bigcup_{i \geq 1} A_i\right) = \sum_{i \geq 1} \mu\left(A_i\right)\)</span>.</p>
<ul>
<li><span class="math inline">\((\Omega,\mathcal{A}, \mu)\)</span> é chamado de <em>espaço de medida</em>.</li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo 1 (medida de contagem):</strong> Seja <span class="math inline">\(\Omega\)</span> um conjunto não vazio e <span class="math inline">\(A\subseteq \Omega\)</span>. Defina <span class="math inline">\(\nu(A)=|A|\)</span> como o número de elementos (cardinalidade) de <span class="math inline">\(A\)</span>. Assim, <span class="math inline">\(\nu(\Omega) &gt; 0\)</span>, <span class="math inline">\(\nu(\varnothing)=0\)</span> e, se <span class="math inline">\((A_n)_{n \geq 1}\)</span> é uma sequência de eventos disjuntos, então <span class="math inline">\(\nu(\cup A_n) = \sum \nu(A_n)\)</span>. Note que <span class="math inline">\(\nu(A)=\infty\)</span> é possivel se <span class="math inline">\(\Omega\)</span> tem infinitos elementos.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo 2 (medida de Lebesgue):</strong> Seja <span class="math inline">\(\Omega=\mathbb{R}\)</span> e <span class="math inline">\(A\subseteq \Omega\)</span> um intervalo. Se <span class="math inline">\(A\)</span> é limitado, defina <span class="math inline">\(\lambda(A)\)</span> como o comprimento do intervalo <span class="math inline">\(A\)</span>. Se <span class="math inline">\(A\)</span> não é limitado, <span class="math inline">\(\lambda(A)=\infty\)</span>. Note que <span class="math inline">\(\lambda(\mathbb{R})=\infty\)</span>, <span class="math inline">\(\lambda(\varnothing)=0\)</span> e, se <span class="math inline">\(A_1 \cap A_2 = \varnothing\)</span> e <span class="math inline">\(A_1 \cup A_2\)</span> é um intervalo (ou uma união de intervalos disjuntos), então <span class="math inline">\(\lambda(A_1 \cup A_2) = \lambda(A_1) + \lambda(A_2)\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo 3:</strong> Seja <span class="math inline">\(f: \mathbb{R} \longrightarrow \mathbb{R}_+\)</span> uma função contínua e não nula. Para cada intervalo <span class="math inline">\(A\)</span>, defina <span class="math inline">\(\displaystyle \mu(A) = \int_A f(x) dx = \int_{\mathbb{R}} \mathbb{I}_A(x) f(x) dx\)</span>. Então, <span class="math inline">\(\mu(\mathbb{R})&gt;0\)</span>, <span class="math inline">\(\mu(\varnothing)=0\)</span> e, se <span class="math inline">\(A_1 \cap A_2 = \varnothing\)</span> e <span class="math inline">\(A_1 \cup A_2\)</span> é um intervalo (ou uma união de intervalos disjuntos), então <span class="math inline">\(\mu(A_1 \cup A_2) = \mu(A_1) + \mu(A_2)\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<ul>
<li>Se <span class="math inline">\(\mu(\Omega) &lt; \infty\)</span> dizemos que <span class="math inline">\(\mu\)</span> é uma <em>medida finita</em>. Se existe uma partição enumerável de <span class="math inline">\(\Omega\)</span>, <span class="math inline">\(A_1,A_2,\ldots\)</span>, tal que cada elemento da partição tem medida finita, <span class="math inline">\(\mu(A_i)&lt;\infty\)</span>, <span class="math inline">\(\forall i\)</span>, dizemos que <span class="math inline">\(\mu\)</span> é uma <em>medida <span class="math inline">\(\sigma\)</span>-finita</em>.</li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição:</strong> <span class="math inline">\(P: \mathcal{A} \longrightarrow [0,1]\)</span> é uma <strong>medida de probabilidade</strong> se<br />
1. <span class="math inline">\(P(\Omega) = 1\)</span>;<br />
2. <span class="math inline">\(\displaystyle A_1, A_2, \ldots \in \mathcal{A}\)</span> com <span class="math inline">\(A_i \bigcap A_j = \varnothing\)</span> , <span class="math inline">\(\displaystyle P\left(\bigcup_{i \geq 1} A_i\right) = \sum_{i \geq 1} P\left(A_i\right)\)</span>.</p>
<ul>
<li><span class="math inline">\((\Omega, \mathcal{A}, P)\)</span>: espaço de probabilidade</li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição:</strong> Seja <span class="math inline">\((\Omega,\mathcal{A})\)</span> e <span class="math inline">\((\mathfrak{X},\mathcal{F})\)</span> dois espaços mensuráveis. Uma função <span class="math inline">\(X: \Omega \longrightarrow \mathfrak{X}\)</span> é chamado de <em>quantidade aleatória</em> se é uma <em>função mensurável</em>, isto é, se <span class="math inline">\(\forall B \in \mathcal{F}\)</span>, o evento <span class="math inline">\(A = X^{-1}(B)\)</span> <span class="math inline">\(= \left\{\omega \in \Omega:~X(\omega)\in B\right\}\)</span> pertence à <span class="math inline">\(\sigma\)</span>-álgebra original <span class="math inline">\(\mathcal{A}\)</span>.<br />
Se <span class="math inline">\(\mathfrak{X} = \mathbb{R}\)</span> e <span class="math inline">\(\mathcal{F}=\mathcal{B}(\mathbb{R})\)</span> (<span class="math inline">\(\sigma\)</span>-álgebra de Borel), <span class="math inline">\(X\)</span> é chamada <strong>variável aleatória</strong> (v.a.).</p>
<ul>
<li><p>Considere <span class="math inline">\((\Omega,\mathcal{A},P)\)</span>. A medida de probabilidade <span class="math inline">\(P_X\)</span> induzida por <span class="math inline">\(X\)</span> recebe o nome de <em>distribuição de <span class="math inline">\(X\)</span></em>. Se <span class="math inline">\(B \in \mathcal{F}\)</span> e <span class="math inline">\(A = \{\omega \in \Omega : X(\omega) \in B\} \in \mathcal{A}\)</span>, a medida induzida por <span class="math inline">\(X\)</span> é
<span class="math display">\[P_X(B) = P_X\left(X \in B\right) = P\left(\{\omega \in \Omega :  X(\omega) \in B\}\right) = P(A)~.\]</span></p></li>
<li><p>A distribuição de <span class="math inline">\(X\)</span> é dita ser <em>discreta</em> se existe um conjunto enumerável <span class="math inline">\(A \subseteq \mathfrak{X}\)</span> tal que <span class="math inline">\(P_X(A)=1\)</span>. A distribuição de <span class="math inline">\(X\)</span> é <em>contínua</em> se <span class="math inline">\(P_X\left(\{x\}\right)=0\)</span> para todo <span class="math inline">\(x \in \mathfrak{X}\)</span>.</p></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="lebesgue" class="section level2" number="9.2">
<h2><span class="header-section-number">A.2</span> Valor Esperado de <span class="math inline">\(X\)</span> (OU uma ideia da tal Integral de Lebesgue)</h2>
<p>Por simplicidade, considere o espaço <span class="math inline">\(\Big(\Omega = [0,1]~,~~ \mathcal{A} = \mathcal{B}\left([0,1]\right)~,~~ P=\lambda\Big)\)</span>.</p>
<p>Seja <span class="math inline">\(X: \Omega \longrightarrow \mathbb{R}_+\)</span> uma variável aleatória discreta, assumindo valores não negativos <span class="math inline">\(\mathfrak{X}=\{x_1,x_2,\ldots,x_k\}\)</span> com probabilidades <span class="math inline">\(\{p_1,p_2,\ldots,p_k\}\)</span>. Nos cursos básicos de probabilidade é visto que o <em>valor esperado</em> (ou <em>esperança</em>) de <span class="math inline">\(X\)</span> é <span class="math inline">\(E[X] =\)</span> <span class="math inline">\(\sum x_i P(X=x_i) =\)</span> <span class="math inline">\(\sum x_i p_i\)</span>.</p>
<p>Podemos definir essa v.a. como</p>
<p><span class="math inline">\(X(\omega) = \left\{\begin{array}{ll} x_1, &amp; \omega \in [0,p_1] = A_1 \\  x_2, &amp; \omega \in [p_1,p_1+p_2] = A_2 \\  \vdots &amp; \\  x_j, &amp; \omega \in \left[\displaystyle\sum_{i=1}^{j-1} p_i,\sum_{i=1}^{j} p_i\right] = A_j \\  \vdots &amp; \\  x_k, &amp; \omega \in [1-p_k,1] = A_k \end{array}\right.\)</span></p>
<p><img src="InfBayes_files/figure-html/va_discreta-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Note que a medida <span class="math inline">\(\lambda\)</span> define uma distribuição uniforme no espaço <span class="math inline">\((\Omega,\mathcal{A})\)</span>. Assim, temos que</p>
<ul>
<li><p><span class="math inline">\(P_X(X=x_1)\)</span> <span class="math inline">\(=P\left(X^{-1}(x_1)\right)\)</span> <span class="math inline">\(=P\left(\{\omega \in \Omega : X(\omega)=x_1\}\right)\)</span> <span class="math inline">\(=P(A_1)\)</span> <span class="math inline">\(=\lambda\left([0,p_1]\right)\)</span> <span class="math inline">\(=p_1\)</span>,</p></li>
<li><p><span class="math inline">\(P_X(X=x_j)\)</span> <span class="math inline">\(=P\left(\{\omega \in \Omega : X(\omega)=x_j\}\right)\)</span> <span class="math inline">\(=\lambda\left(\left[\sum_{i=1}^{j-1} p_i,\sum_{i=1}^{j} p_i\right]\right)\)</span> <span class="math inline">\(=p_j ~,~\)</span> <span class="math inline">\(j \in \{2,\ldots,k\}\)</span>.</p></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição:</strong> Uma função mensurável <span class="math inline">\(X: \Omega \longrightarrow \mathbb{R}_+\)</span> é dita <em>simples</em> se assumir um número finito de valores.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição:</strong> Considere um espaço de probabilidade <span class="math inline">\((\Omega, \mathcal{A}, P)\)</span>, <span class="math inline">\(X:\Omega\longrightarrow \mathbb{R}_+\)</span> v.a. assumindo valores <span class="math inline">\(\{x_1,x_2,\ldots,x_k\}\)</span> e <span class="math inline">\(A_1,A_2,\ldots,A_k\)</span> eventos disjuntos em <span class="math inline">\(\mathcal{A}\)</span>. Seja <span class="math inline">\(\displaystyle X(\omega) = \sum_{i=1}^{k} x_i ~\mathbb{I}_{A_i}(\omega)\)</span>, uma função simples com <span class="math inline">\(A_i = X^{-1}(x_i)\)</span>, <span class="math inline">\(i=1,\ldots,k\)</span>. A <em>integral de Lebesgue</em> de <span class="math inline">\(X\)</span> em relação à medida <span class="math inline">\(P\)</span> é
<span class="math display">\[E[X] = \int_\Omega X dP = \sum_{i=1}^{k} x_i P(A_i).\]</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Propriedades:</strong> se <span class="math inline">\(X, Y: \Omega \longrightarrow \mathbb{R}_+\)</span> são funções simples, então</p>
<p><strong>1.</strong> <span class="math inline">\(\displaystyle\int_\Omega X dP \geq 0\)</span>;</p>
<p><strong>2.</strong> <span class="math inline">\(\displaystyle\int_\Omega cX dP = c\int_\Omega X dP\)</span>;</p>
<p><strong>3.</strong> <span class="math inline">\(\displaystyle\int_\Omega (X+Y) dP = \int_\Omega X dP + \int_\Omega Y dP\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Demo 1.</strong> Segue de <span class="math inline">\(x_i \geq 0\)</span> e <span class="math inline">\(P(A_i) \geq 0\)</span>.</p>
</blockquote>
<blockquote>
<p><strong>Demo 2.</strong><br />
Para <span class="math inline">\(X\)</span> v.a. temos<br />
<span class="math inline">\(X =\displaystyle \sum_{i=1}^kx_i~\mathbb{I}_{A_i}\)</span> e <span class="math inline">\(cX = \displaystyle\sum_{i=1}^k c~x_i ~\mathbb{I}_{A_i}\)</span>. Logo,<br />
<span class="math inline">\(\displaystyle\int_\Omega cX~dP = \sum_{i=1}^k c~x_i~P(A_i)\)</span> <span class="math inline">\(=\displaystyle c\sum_{i=1}^kx_i P(A_i) = c\int_\Omega X dP\)</span>.</p>
</blockquote>
<blockquote>
<p><strong>Demo 3.</strong><br />
<span class="math inline">\(X = \sum_{i=1}^kx_i~\mathbb{I}_{A_i}\)</span> e <span class="math inline">\(Y = \sum_{j=1}^ly_j~\mathbb{I}_{B_j}\)</span>.<br />
<span class="math inline">\(X + Y\)</span> <span class="math inline">\(=\displaystyle \sum_{i=1}^k x_i ~\mathbb{I}_{A_i} + \sum_{j=1}^l y_j~\mathbb{I}_{B_j}\)</span> <span class="math inline">\(=\displaystyle\sum_{i=1}^k\sum_{j=1}^lx_i~\mathbb{I}_{A_i\cap B_j} + \sum_{i=1}^k\sum_{j=1}^ly_j~\mathbb{I}_{A_i\cap B_j}\)</span> <span class="math inline">\(=\displaystyle\sum_{i=1}^k\sum_{j=1}^l(x_i+y_j)~\mathbb{I}_{A_i\cap B_j}\)</span>.<br />
<span class="math inline">\(\displaystyle \int_\Omega (X + Y) dP\)</span> <span class="math inline">\(=\displaystyle \sum_{i=1}^k\sum_{j=1}^l (x_i + y_j)P(A_i\cap B_j)\)</span> <span class="math inline">\(=\displaystyle\sum_{i=1}^k\sum_{j=1}^l x_iP(A_i\cap B_j) + \sum_{i=1}^k\sum_{j=1}^l y_jP(A_i\cap B_j)\)</span> <span class="math inline">\(=\displaystyle\sum_{i=1}^k x_i P(A_i) + \sum_{j=1}^l y_j P(B_j)\)</span> <span class="math inline">\(=\displaystyle\int_\Omega X dP + \int_\Omega Y dP\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p>A generalização da integral de Lebesgue é feita usando resultados como o <em>Lema de Fatou</em> e os teoremas da <em>convergência monótona</em> e da <em>convergência dominada</em>. Aqui será apresentado apenas uma ideia dessa extensão. Para maiores detalhes, veja as referências citadas anteriormente <span class="citation">(<a href="#ref-Ash00" role="doc-biblioref">Ash and Doleans-Dade 2000</a>; <a href="#ref-Schervish12" role="doc-biblioref">Schervish 2012</a>; <a href="#ref-Billingsley86" role="doc-biblioref">Billingsley 1986</a>; <a href="#ref-Shiryaev96" role="doc-biblioref">Shiryaev 1996</a>)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição:</strong> Seja <span class="math inline">\(X:\Omega\longrightarrow \mathbb{R}_+\)</span> uma função mensurável não negativa e considere o conjunto de funções <span class="math inline">\(\mathcal{C}_X\)</span> <span class="math inline">\(= \{ f:\Omega\longrightarrow \mathbb{R}_+~,~~f~~\text{simples}~,~~f \leq X\}\)</span>. O <em>valor esperado de <span class="math inline">\(X\)</span></em> é
<span class="math display">\[E[X]=\int_\Omega XdP=\sup\left\{\int_\Omega fdP: f\in \mathcal{C}_X\right\}~.\]</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado:</strong> Para toda função <span class="math inline">\(X:\Omega \longrightarrow \mathbb{R}_+\)</span>, existe uma sequência <span class="math inline">\((X_n)_{n\geq 1}\)</span> de funções simples não-negativas tais que <span class="math inline">\(X_n(\omega)\leq X_{n+1}(\omega)\)</span>, <span class="math inline">\(\forall \omega \in \Omega\)</span>, <span class="math inline">\(\forall n \in \mathbb{N}\)</span> com <span class="math inline">\(X_n(\omega)\uparrow X(\omega)\)</span>, <span class="math inline">\(\forall \omega \in \Omega\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo</strong> de sequência <span class="math inline">\((X_n)_{n\geq 1}\)</span> atendendo as condições anteriores</p>
<p>Para cada <span class="math inline">\(n\)</span>, considere <span class="math inline">\(1+n2^n\)</span> conjuntos em <span class="math inline">\(\mathcal{A}:\)</span></p>
<ul>
<li><p><span class="math inline">\(E_j^n = \left\{\omega \in \Omega: \dfrac{j}{2^n} \leq X(\omega) \leq \dfrac{j+1}{2^n} \right\}\)</span>, <span class="math inline">\(j = 0,1,\ldots,n2^n-1.\)</span></p></li>
<li><p><span class="math inline">\(E_{n2^n}^n = \Big\{ \omega \in \Omega: X(\omega)\geq n \Big\}\)</span></p></li>
</ul>
<p>e defina <span class="math inline">\(\displaystyle X_n(\omega) = \sum_{j=0}^{n2^n} \dfrac{j}{2^n} ~\mathbb{I}_{E_j^n}(\omega)\)</span>. Pode-se provar que <span class="math inline">\((X_n)_{n\geq 1}\)</span> é tal que</p>
<ul>
<li><p><span class="math inline">\(X_n\)</span> é simples, <span class="math inline">\(\forall n \geq 1\)</span></p></li>
<li><p><span class="math inline">\(X_n \leq X_{n+1}\)</span></p></li>
<li><p><span class="math inline">\(X_{n}(\omega) \uparrow X(\omega)\)</span></p></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p>A primeira função dessa sequência é</p>
<p><span class="math inline">\(X_1(\omega)\)</span>
<span class="math inline">\(= \displaystyle\sum_{i=0}^2 \frac{i}{2}~\mathbb{I}_{{E}_i^1}(\omega)\)</span>
<span class="math inline">\(=\displaystyle\left\{\begin{array}{ll}0,&amp;\omega\in{E}_0^1\\ 0.5,&amp;\omega\in{E}_1^1\\1,&amp;\omega\in{E}_2^1 \end{array}\right.\)</span>.</p>
<p><img src="InfBayes_files/figure-html/X1w-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>O gráfico a seguir mostra os quatro primeiras funções da sequência <span class="math inline">\(\left(X_n\right)_{n\geq 1}\)</span> e é possível ter uma ideia da convergência para <span class="math inline">\(X\)</span>.</p>
<p><img src="InfBayes_files/figure-html/convergXn-1.gif" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado:</strong> <span class="math inline">\(X,Y: \Omega \longrightarrow\mathbb{R}_+,\)</span> com <span class="math inline">\(X\leq Y\)</span>. Então <span class="math inline">\(E[X] \leq E[Y]\)</span>.</p>
<blockquote>
<p><strong>Demo:</strong> Como <span class="math inline">\(X \leq Y\)</span> (isto é, <span class="math inline">\(X(\omega) \leq Y(\omega)\)</span> <span class="math inline">\(\forall \omega \in \Omega\)</span>), <span class="math inline">\(\mathcal{C}_X \subseteq \mathcal{C}_Y\)</span><br />
<span class="math inline">\(\Rightarrow \sup\left\{\displaystyle\int_\Omega f~dP:~ f\in \mathcal{C}_X\right\} \leq \sup\left\{\displaystyle\int_\Omega g~dP:~ g\in \mathcal{C}_Y\right\}\)</span> <span class="math inline">\(\Rightarrow \displaystyle\int_\Omega XdP \leq \displaystyle\int_\Omega YdP\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição</strong>: Seja <span class="math inline">\(X:\Omega \longrightarrow\mathbb{R}_+\)</span> e <span class="math inline">\(E \in \mathcal{A}\)</span> definimos <span class="math inline">\(E(X~\mathbb{I}_E) = \displaystyle\int_EXdP\)</span> <span class="math inline">\(=\displaystyle\int_\Omega X~\mathbb{I}_EdP\)</span>.<br />
Se <span class="math inline">\(E,F \in \mathcal{A}\)</span> com <span class="math inline">\(E\subseteq F\)</span>, <span class="math inline">\(\displaystyle\int_E XdP \leq \int_F XdP.\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Propriedades:</strong> se <span class="math inline">\(X, Y: \Omega \longrightarrow \mathbb{R}_+\)</span> são funções mensuráveis positivas, então</p>
<p><strong>1.</strong> <span class="math inline">\(\displaystyle\int_\Omega cXdP =\)</span> <span class="math inline">\(c\displaystyle\int_\Omega XdP, c\geq 0\)</span>;</p>
<p><strong>2.</strong> <span class="math inline">\(\displaystyle\int_\Omega (X+Y)dP =\)</span> <span class="math inline">\(\displaystyle\int_\Omega XdP + \int_\Omega YdP\)</span>.</p>
<blockquote>
<p><strong>Demo 1.</strong> Seja <span class="math inline">\(X_n\uparrow X,\)</span> <span class="math inline">\(X_n \geq 0\)</span> simples. Então <span class="math inline">\(cX_n\uparrow cX,\)</span> <span class="math inline">\(cX_n \geq 0,\)</span> simples.<br />
<span class="math inline">\(\displaystyle\int_\Omega cX dP\)</span> <span class="math inline">\(=\displaystyle\lim_{n\rightarrow\infty}\int_\Omega cX_n dP\)</span> <span class="math inline">\(=\displaystyle\lim_{n\rightarrow\infty}c\int_\Omega X_n dP\)</span> <span class="math inline">\(=\displaystyle c\lim_{n\rightarrow\infty}\int_\Omega X_n dP\)</span> <span class="math inline">\(=\displaystyle c\int_\Omega X dP\)</span>.</p>
</blockquote>
<blockquote>
<p><strong>Demo 2.</strong> Exercício.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo:</strong> Suponha que <span class="math inline">\(X\)</span> assume valores em <span class="math inline">\(\mathbb{N}\)</span>. Pode-se escrever <span class="math inline">\(X =\displaystyle\sum_{i=1}^\infty i ~\mathbb{I}_{A_i}~\)</span>, com <span class="math inline">\(A_i = X^{-1}\left(\{i\}\right)\)</span>.<br />
Defina <span class="math inline">\(X_n =\displaystyle\sum_{i=1}^{n-1} i ~\mathbb{I}_{A_i}+n~\mathbb{I}_{\underset{j=n}{\cup} A_j}\)</span>. Então <span class="math inline">\(X_n\)</span> é simples, <span class="math inline">\(X_n \geq 0~\)</span>, <span class="math inline">\(X_n \leq X_{n+1}\)</span> e <span class="math inline">\(X_n \uparrow X\)</span>, de modo que <span class="math inline">\(E(X)\)</span> <span class="math inline">\(=\displaystyle\int_\Omega X dP\)</span> <span class="math inline">\(=\displaystyle\lim_{n \rightarrow\infty}\int_\Omega X_n dP\)</span>. Além disso,<br />
<span class="math inline">\(\displaystyle\int_\Omega X_n dP\)</span> <span class="math inline">\(=\displaystyle\sum_{i=1}^{n-1} i~P(A_i) + n~P\left(\bigcup_{j=n}^{\infty} A_j\right)\)</span> <span class="math inline">\(=\displaystyle\sum_{i=1}^{n-1}i~P(X = i) + n~P(X \geq n)\)</span> <span class="math inline">\(=\displaystyle\sum_{i=1}^{n-1} \sum_{j=1}^{i} P(X = i) + n~P(X \geq n)\)</span> <span class="math inline">\(\displaystyle=\sum_{j=1}^{n-1} \sum_{i=j}^{n-1} P(X = i) + n~P(X \geq n)\)</span> <span class="math inline">\(=\displaystyle\sum_{j=1}^{n-1}P(j \leq X \leq n-1) + n~P(X \geq n)\)</span> <span class="math inline">\(=\displaystyle\sum_{j=1}^n P(X \geq j)\)</span>,<br />
então, <span class="math inline">\(E(X)\)</span> <span class="math inline">\(\displaystyle=\lim_{n\rightarrow \infty}\sum_{j=1}^nP(X \geq j)\)</span> <span class="math inline">\(\displaystyle=\sum_{j=1}^{\infty}P(X \geq j)\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p>Seja <span class="math inline">\(X: \Omega \longrightarrow \mathbb{R}\)</span> e <span class="math inline">\(X^-,X^+: \Omega \longrightarrow \mathbb{R}\)</span> dados por</p>
<ul>
<li><p><span class="math inline">\(X^- = \max\{-X,0\}~\)</span> (parte negativa de <span class="math inline">\(X\)</span>) e</p></li>
<li><p><span class="math inline">\(X^+ = \max\{X,0\}~\)</span> (parte positiva de <span class="math inline">\(X\)</span>)</p></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><img src="InfBayes_files/figure-html/Xmaismenos-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p>Note que <span class="math inline">\(X = X^+ - X^-\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p>Se <span class="math inline">\(\displaystyle\int_\Omega X^+ dP &lt; \infty\)</span> ou <span class="math inline">\(\displaystyle\int_\Omega X^- dP &lt; \infty\)</span>, definimos</p>
<p><span class="math inline">\(E[X]\)</span> <span class="math inline">\(=\displaystyle\int X dP\)</span> <span class="math inline">\(=\displaystyle\int_\Omega X^+dP - \int_\Omega X^- dP\)</span> <span class="math inline">\(=E\left[X^+\right] - E\left[X^-\right]\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Além disso, seja <span class="math inline">\(|X| = X^+ + X^-\)</span>. Então, <span class="math inline">\(E\left[~|X|~\right] &lt; \infty\)</span> se <span class="math inline">\(E(X^+) &lt; \infty\)</span> e <span class="math inline">\(E(X^-) &lt; \infty\)</span>, e, nesse caso, dizemos que <span class="math inline">\(X\)</span> é <em>integrável</em>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Propriedades:</strong> se <span class="math inline">\(X, Y: \Omega \longrightarrow \mathbb{R}\)</span> são funções mensuráveis, então</p>
<p><strong>1.</strong> <span class="math inline">\(X \leq Y \Rightarrow E(X) \leq E(Y)\)</span>;</p>
<p><strong>2.</strong> <span class="math inline">\(c \in \mathbb{R},\)</span> <span class="math inline">\(E(cX) = cE(X)\)</span>;</p>
<p><strong>3.</strong> <span class="math inline">\(X,Y\)</span> integráveis. <span class="math inline">\(E(X+Y) = E(X) + E(Y)\)</span>.</p>
<blockquote>
<p><strong>Demo 1.</strong><br />
<span class="math inline">\(X \leq Y \Rightarrow\)</span> <span class="math inline">\(\left\{\begin{array}{c}X^+ \leq Y^+\\ X^- \geq Y^-\end{array}\right.\)</span><br />
<span class="math inline">\(E(X) =\)</span> <span class="math inline">\(E(X^+) - E(X^-)\)</span> <span class="math inline">\(\leq E(Y^+) - E(Y^-)\)</span> <span class="math inline">\(=E(Y).\)</span></p>
</blockquote>
<blockquote>
<p><strong>Demo 2.</strong><br />
<span class="math inline">\((cX)^+ =\)</span> <span class="math inline">\(\left\{\begin{array}{rcl}cX^+ &amp;,&amp; c \geq 0\\ -cX^- &amp;,&amp; c &lt; 0 \end{array}\right.\)</span><br />
<span class="math inline">\((cX)^- =\)</span> <span class="math inline">\(\left\{\begin{array}{rcl}cX^- &amp;,&amp; c \geq 0\\ -cX^+ &amp;,&amp; c &lt; 0 \end{array}\right.\)</span><br />
Para <span class="math inline">\(c&lt;0\)</span>,<br />
<span class="math inline">\(E[cX]\)</span> <span class="math inline">\(= E[(cX)^+] - E[(cX)^-]\)</span> <span class="math inline">\(= E[-cX^-] - E[-cX^+]\)</span> <span class="math inline">\(= -cE[X^-] + cE[X^+]\)</span> <span class="math inline">\(= cE[X]\)</span>.</p>
</blockquote>
<blockquote>
<p><strong>Demo 3.</strong><br />
<span class="math inline">\(\displaystyle\int_\Omega \left(X^+ + Y^+\right) dP &lt; \infty\)</span> ou <span class="math inline">\(\displaystyle\int_\Omega \left(X^- + Y^-\right) dP &lt; \infty\)</span><br />
<span class="math inline">\(X + Y\)</span> <span class="math inline">\(= (X + Y)^+ - (X+Y)^-\)</span> <span class="math inline">\(= X^+ - X^- + Y^+ - Y^-\)</span><br />
<span class="math inline">\(\Rightarrow (X+Y)^+ + X^- + Y^-\)</span> <span class="math inline">\(= X^+ + Y^+ + (X+Y)^-\)</span><br />
<span class="math inline">\(\Rightarrow \displaystyle\int_\Omega (X+Y)^+dP + \int_\Omega X^-dP + \int_\Omega Y^-dP\)</span><br />
<span class="math inline">\(=\displaystyle\int_\Omega X^+dP + \int_\Omega Y^+dP + \int_\Omega (X+Y)^-dP\)</span>.<br />
<span class="math inline">\(|X+Y|\)</span> <span class="math inline">\(= |X^+-X^-+Y^+-Y^-|\)</span> <span class="math inline">\(\leq X^++X^-+Y^++Y^-\)</span><br />
<span class="math inline">\(\Rightarrow \displaystyle\int_\Omega (X+Y)^+dP - \int_\Omega(X+Y)^-dP\)</span> <span class="math inline">\(=\displaystyle \int_\Omega X^+dP -\int_\Omega X^-dP + \int_\Omega Y^+dP -\int_\Omega Y^-dP\)</span>.<br />
<span class="math inline">\(\Rightarrow \displaystyle\int_\Omega(X+Y)dP = \int_\Omega XdP + \int_\Omega YdP\)</span></p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="funções-de-variáveis-aleatórias" class="section level2" number="9.3">
<h2><span class="header-section-number">A.3</span> Funções de Variáveis Aleatórias</h2>
<p>Considere agora uma v.a. <span class="math inline">\(X: \Omega \longrightarrow \mathbb{R}\)</span> e uma função real <span class="math inline">\(g: \mathbb{R} \longrightarrow \mathbb{R}\)</span>. Defina <span class="math inline">\(Y = g(X)\)</span>. Então</p>
<p><span class="math display">\[(\Omega, \mathcal{A},P) \overset{X}{\longrightarrow}(\mathbb{R},\mathcal{B}(\mathbb{R}),P_X)\overset{g}{\longrightarrow}(\mathbb{R},\mathcal{B}(\mathbb{R}),P_Y)\]</span></p>
<p><span class="math display">\[(\Omega, \mathcal{A},P)\overset{Y = g(X)}{\longrightarrow}(\mathbb{R},\mathcal{B}(\mathbb{R}),P_Y)\]</span></p>
<p>Logo, se <span class="math inline">\(g\)</span> é uma função mensurável, <span class="math inline">\(Y=g(X)\)</span> também é v.a. e as medidas induzidas por X e Y são</p>
<p><span class="math inline">\(P_X(A)\)</span> <span class="math inline">\(= P(X^{-1}(A))\)</span> <span class="math inline">\(= P\left(\{\omega \in \Omega : X(\omega) \in A\}\right)\)</span>;</p>
<p><span class="math inline">\(P_Y(B)\)</span> <span class="math inline">\(= P_X(g^{-1}(B))\)</span> <span class="math inline">\(= P_X\left(\{x \in \mathbb{R} : g(x) \in B\}\right)\)</span> <span class="math inline">\(= P\left(\{\omega \in \Omega : g\left(X(\omega)\right) \in B\}\right)\)</span>.</p>
<p>Assim, uma pergunta natural é como obter o valor esperado de <span class="math inline">\(Y\)</span>.</p>
<p><span class="math inline">\(E(Y) = \displaystyle\int_\Omega YdP\)</span> <span class="math inline">\(=\displaystyle\int_\Omega g(X)dP\)</span> <span class="math inline">\(\overset{?}{=} \displaystyle\int_{\mathbb{R}}g~dP_X\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Caso 1.</strong> Seja <span class="math inline">\(g:\mathbb{R}\longrightarrow\mathbb{R}_+\)</span> uma função simples tal que <span class="math inline">\(g = \sum_{i=1}^kg_i~\mathbb{I}_{B_i}\)</span>, <span class="math inline">\(g_1,\ldots,g_k \in \mathbb{R}\)</span> e <span class="math inline">\(B_1,\ldots,B_k \in \mathcal{B}(\mathbb{R})\)</span>. Então,<br />
<span class="math inline">\(\displaystyle\int_\Omega Y~dP\)</span>
<span class="math inline">\(=\displaystyle\int_\Omega g(X)~dP\)</span>
<span class="math inline">\(=\displaystyle\int_\Omega \left(\sum_{i=1}^k g_i ~\mathbb{I}_{B_i}(X)\right)dP\)</span>
<span class="math inline">\(=\displaystyle\int_\Omega \left(\sum_{i=1}^k g_i ~\mathbb{I}_{X^{-1}(B_i)}\right)dP\)</span>
<span class="math inline">\(~\displaystyle\overset{def}{=}~\sum_{i=1}^k g_i~P(X^{-1}(B_i))\)</span>
<span class="math inline">\(=\displaystyle\sum_{i=1}^k g_i~P_X(B_i)\)</span>
<span class="math inline">\(=\displaystyle\int_{\mathbb{R}}\left(\sum_{i=1}^kg_i~\mathbb{I}_{B_i}\right)dP_X\)</span>
<span class="math inline">\(=\displaystyle\int_{\mathbb{R}} g~dP_X\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Caso 2.</strong> Seja <span class="math inline">\(g:\mathbb{R}\longrightarrow\mathbb{R}_+\)</span> uma função não negativa e <span class="math inline">\((g_n)_{n\geq1}\)</span>, <span class="math inline">\(g_n \geq 0\)</span>, uma sequência crescente de funções simples tal que <span class="math inline">\(g_n\uparrow g\)</span>. Como <span class="math inline">\(g_n\)</span> é simples,<br />
<span class="math inline">\(\displaystyle\int_\Omega g_n(X)dP\)</span> <span class="math inline">\(=\displaystyle\int_{\mathbb{R}}g_n~dP_X\)</span> <span class="math inline">\(\displaystyle~\underset{n\uparrow\infty}{\longrightarrow}~ \int_\Omega g(X)dP\)</span> <span class="math inline">\(=\displaystyle\int_{\mathbb{R}}g~dP_X\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Caso 3.</strong> Agora para <span class="math inline">\(g: \mathbb{R} \longrightarrow \mathbb{R}\)</span>, temos<br />
<span class="math inline">\(\displaystyle\int_\Omega g^+(X)dP\)</span> <span class="math inline">\(=\displaystyle\int_{\mathbb{R}}g^+dP_X\)</span> e <span class="math inline">\(\displaystyle\int_\Omega g^-(X)dP\)</span> <span class="math inline">\(=\displaystyle\int_{\mathbb{R}}g^-dP_X\)</span>.<br />
Logo, <span class="math inline">\(\displaystyle\int_\Omega g(X)dP\)</span> <span class="math inline">\(=\displaystyle\int_{\mathbb{R}}g~dP_X\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p>Suponha agora <span class="math inline">\(X\)</span> v.a. discreta assumindo valores em <span class="math inline">\(\{x_1,x_2,\ldots\}\)</span> com probabilidade <span class="math inline">\(1\)</span>. Nesse caso, para <span class="math inline">\(A\subseteq\mathcal{B}(\mathbb{R})\)</span>,</p>
<p><span class="math inline">\(P_X(A)\)</span> <span class="math inline">\(=P_X(X \in A)\)</span> <span class="math inline">\(=P\left(\{\omega\in\Omega: X(\omega) \in A\}\right)\)</span> <span class="math inline">\(=\displaystyle\sum_{i:~x_i\in A} P_X(X=x_i)\)</span>.</p>
<p>Vamos “verificar” que <span class="math inline">\(E\left[g(X)\right]\)</span> <span class="math inline">\(=\displaystyle\sum_{i=1}^\infty g(x_i)P_X(X=x_i)\)</span>.</p>
<blockquote>
<p><strong>Caso 1.</strong> <span class="math inline">\(g\)</span> simples com <span class="math inline">\(g = \displaystyle\sum_{i=1}^kg_i~\mathbb{I}_{B_i}\)</span>, <span class="math inline">\(g_1,\ldots,g_k \in \mathbb{R}_+\)</span> <span class="math inline">\(B_1,\ldots,B_k \in \mathcal{B}(\mathbb{R})\)</span>. Então,<br />
<span class="math inline">\(E\left[g(X)\right]\)</span> <span class="math inline">\(=\displaystyle\int_\Omega g(X)~dP\)</span>
<span class="math inline">\(=\displaystyle\sum_{i=1}^k g_i~P\left(X^{-1}(B_i)\right)\)</span>
<span class="math inline">\(=\displaystyle\sum_{i=1}^k g_i~P_X(B_i)\)</span>
<span class="math inline">\(=\displaystyle\sum_{i=1}^k g_i \sum_{j:~x_j \in B_i}^k P_X(X = x_j)\)</span>
<span class="math inline">\(=\displaystyle\sum_{i=1}^k g_i \sum_{j=1}^\infty \mathbb{I}_{B_i}(x_j)P_X(X=x_j)\)</span>
<span class="math inline">\(=\displaystyle\sum_{j=1}^\infty \underbrace{\left(\sum_{i=1}^k g_i ~\mathbb{I}_{B_i}(x_j)\right)}_{g(x_j)}P_X(X = x_j)\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Caso 2.</strong> <span class="math inline">\(g\geq 0,\)</span> <span class="math inline">\(g_n\geq0,\)</span> <span class="math inline">\(g_n\)</span> simples tal que <span class="math inline">\(g_n \uparrow g\)</span><br />
<span class="math inline">\(\displaystyle\int_\Omega g(X)dP\)</span> <span class="math inline">\(=\displaystyle\lim_{n\rightarrow\infty}\int_\Omega g_n(X)dP\)</span> <span class="math inline">\(=\displaystyle\lim_{n\rightarrow\infty}\left\{\sum_{j=1}^\infty g_n(x_j)P_X(X=x_j)\right\}\)</span> <span class="math inline">\(=\displaystyle\sum_{j=1}^\infty g(x_j)P_X(X = x_j)\)</span></p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Caso 3.</strong> Agora para <span class="math inline">\(g: \mathbb{R} \longrightarrow \mathbb{R}\)</span>, temos<br />
<span class="math inline">\(\displaystyle\int_\Omega g^+(X)dP\)</span>
<span class="math inline">\(=\displaystyle\sum_{j=1}^\infty g^+(x_j)P_X(X = x_j)\)</span> e
<span class="math inline">\(\displaystyle\int_\Omega g^-(X)dP\)</span>
<span class="math inline">\(=\displaystyle\sum_{j=1}^\infty g^-(x_j)P_X(X = x_j)\)</span>.<br />
Logo, <span class="math inline">\(\displaystyle\int_\Omega g(X)dP\)</span> <span class="math inline">\(=\displaystyle\sum_{j=1}^\infty g(x_j)P_X(X = x_j)\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p>Suponha agora <span class="math inline">\(X\)</span> v.a. absolutamente contínua com função de densidade de probabilidade <span class="math inline">\(f_X\)</span>, ou seja, pode-se escrever <span class="math inline">\(P_X(X\in A)\)</span> <span class="math inline">\(=\displaystyle\int_Af_X(t)dt\)</span> <span class="math inline">\(=\displaystyle\int_{\mathbb{R}}\mathbb{I}_A(t)f_X(t)dt\)</span>. Vamos “verificar” que <span class="math inline">\(E\left[g(X)\right]\)</span> <span class="math inline">\(=\displaystyle\int_{\mathbb{R}} g(x)f_X(x)dx\)</span>.</p>
<blockquote>
<p><strong>Caso 1.</strong> <span class="math inline">\(g\)</span> simples com <span class="math inline">\(g = \displaystyle\sum_{i=1}^kg_i~\mathbb{I}_{B_i}\)</span>, <span class="math inline">\(g_1,\ldots,g_k \in \mathbb{R}_+\)</span> <span class="math inline">\(B_1,\ldots,B_k \in \mathcal{B}(\mathbb{R})\)</span>. Então,<br />
<span class="math inline">\(E\left[g(X)\right]\)</span> <span class="math inline">\(=\displaystyle\int_\Omega g(X)~dP\)</span>
<span class="math inline">\(=\displaystyle\int_\Omega\left(\sum_{i=1}^k g_i~\mathbb{I}_{B_i}(X)\right)dP\)</span>
<span class="math inline">\(=\displaystyle\int_\Omega\left(\sum_{i=1}^k g_i~\mathbb{I}_{X^{-1}(B_i)}\right)dP\)</span>
<span class="math inline">\(=\displaystyle\sum_{i=1}^k g_i~P(X^{-1}(B_i))\)</span>
<span class="math inline">\(=\displaystyle\sum_{i=1}^k g_i~P_X(B_i)\)</span>
<span class="math inline">\(=\displaystyle\sum_{i=1}^k g_i~\int_{\mathbb{R}}\mathbb{I}_{B_i}(x)f_X(x)dx\)</span>
<span class="math inline">\(=\displaystyle\int_{\mathbb{R}}\sum_{i=1}^k g_i\mathbb{I}_{B_i}(x)f_X(x)dx\)</span>
<span class="math inline">\(=\displaystyle\int_{\mathbb{R}}g(x)f_X(x)dx\)</span>.</p>
</blockquote>
<blockquote>
<p>A extensão para funções positivas e para funções reais é análogo ao que foi feito nos exemplos anteriores.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p>Assim, em geral, vale que:</p>
<ul>
<li><p><span class="math inline">\(X\)</span> discreto: <span class="math inline">\(E[g(X)]\)</span> <span class="math inline">\(=\displaystyle\sum_{j=1}^\infty g(x_j)P_X(X=x_j)\)</span>;</p></li>
<li><p><span class="math inline">\(X\)</span> (absolutamente) contínuo: <span class="math inline">\(E[g(X)]\)</span> <span class="math inline">\(=\displaystyle\int_{\mathbb{R}}g(x)f_X(x)dx\)</span>.</p></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p>Esses resultados valem também se <span class="math inline">\(X: \Omega \longrightarrow \mathbb{R}^k\)</span> e <span class="math inline">\(g: \mathbb{R}^k\longrightarrow \mathbb{R}.\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo 1.</strong> Seja <span class="math inline">\(X\)</span> uma v.a. definida em <span class="math inline">\(\mathbb{N}\)</span> com função de probabilidade <span class="math inline">\(P_X(X=x)=\dfrac{e^{-\lambda}\lambda^x}{x!}~\mathbb{I}_{\mathbb{N}}(x)\)</span>, para <span class="math inline">\(\lambda&gt;0\)</span> fixado. Dizemos nesse caso que <span class="math inline">\(X \sim \text{Poisson}(\lambda)\)</span>. Então, o valor esperado de <span class="math inline">\(X\)</span> é<br />
<span class="math inline">\(E\left[X\right]\)</span> <span class="math inline">\(=\displaystyle\sum_{x=0}^\infty x~P_X(X=x)\)</span>
<span class="math inline">\(=\displaystyle\sum_{x=0}^\infty x~\dfrac{e^{-\lambda}\lambda^x}{x!}\)</span>
<span class="math inline">\(=\displaystyle\sum_{x=1}^\infty \dfrac{e^{-\lambda}\lambda^x}{(x-1)!}\)</span>
<span class="math inline">\(=\displaystyle\lambda~\sum_{x=1}^\infty \dfrac{e^{-\lambda}\lambda^{x-1}}{(x-1)!}\)</span>
<span class="math inline">\(~\overset{t=x-1}{=}~\displaystyle\lambda~\sum_{t=0}^\infty \dfrac{e^{-\lambda}\lambda^{t}}{t!}\)</span>
<span class="math inline">\(\Longrightarrow E\left[X\right] = \lambda\)</span>.<br />
<span class="math inline">\(~\)</span><br />
Ainda neste exemplo, considere <span class="math inline">\(g:\mathbb{R}\rightarrow\mathbb{R}\)</span> com <span class="math inline">\(g(t) = e^t\)</span>. Então,<br />
<span class="math inline">\(E\left[g(X)\right]\)</span> <span class="math inline">\(=\displaystyle\sum_{x=0}^\infty g(x)P_X(X=x)\)</span> <span class="math inline">\(=\displaystyle\sum_{x=0}^\infty e^x~\dfrac{e^{-\lambda}\lambda^x}{x!}\)</span> <span class="math inline">\(=\displaystyle e^{-\lambda}\sum_{x=0}^\infty \dfrac{(\lambda e)^x}{x!}\)</span> <span class="math inline">\(=\displaystyle e^{-\lambda}e^{\lambda e}\underbrace{\sum_{x=0}^{\infty} \dfrac{e^{-\lambda e}(\lambda e)^x}{x!}}_{1}\)</span>
<span class="math inline">\(=e^{\lambda e-\lambda}\)</span> <span class="math inline">\(=e^{\lambda(e-1)}\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo 2.</strong> Seja <span class="math inline">\(X\)</span> uma v.a. definida em <span class="math inline">\([0,1]\)</span> com função densidade de probabilidade <span class="math inline">\(f_X(x)=\dfrac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}~x^{a-1}(1-x)^{b-1}~\mathbb{I}_{[0,1]}(x)\)</span>, para <span class="math inline">\(a,b&gt;0\)</span> fixados. Dizemos nesse caso que <span class="math inline">\(X \sim \text{Beta}(a,b)\)</span>. Então, o valor esperado de <span class="math inline">\(X\)</span> é<br />
<span class="math inline">\(E[X]\)</span> <span class="math inline">\(=\displaystyle\int_{-\infty}^\infty x~f_X(x)dx\)</span>
<span class="math inline">\(=\displaystyle\int_0^1 x~\dfrac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}~x^{a-1}(1-x)^{b-1}dx\)</span>
<span class="math inline">\(=\displaystyle\dfrac{\Gamma (a+1)}{\Gamma(a+1+b)}\dfrac{\Gamma(a+b)}{\Gamma(a)}\int_0^1\dfrac{\Gamma(a+1+b)}{\Gamma(a+1)\Gamma(b)}~x^{(a+1)-1}(1-x)^{b-1}dx\)</span>
<span class="math inline">\(=\dfrac{\Gamma (a+1)}{\Gamma(a+1+b)}\dfrac{\Gamma(a+b)}{\Gamma(a)}\)</span>.<br />
<span class="math inline">\(~\)</span><br />
Considere agora <span class="math inline">\(g:\mathbb{R}\rightarrow\mathbb{R}\)</span> com <span class="math inline">\(g(t) = t^c(1-t)^d\)</span>, com <span class="math inline">\(c,d&gt;0\)</span> fixados. Então,<br />
<span class="math inline">\(E[g(X)]\)</span> <span class="math inline">\(=\displaystyle\int_{-\infty}^\infty g(x)~f_X(x)dx\)</span>
<span class="math inline">\(=\displaystyle\int_0^1 \dfrac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}~x^{a+c-1}(1-x)^{b+d-1}dx\)</span>
<span class="math inline">\(=\displaystyle\dfrac{\Gamma (a+c)\Gamma(b+d)}{\Gamma(a+c+b+d)}\dfrac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\int_0^1\dfrac{\Gamma(a+c+b+d)}{\Gamma(a+b)\Gamma(b+d)}~x^{(a+c)-1}(1-x)^{(b+d)-1}dx\)</span>
<span class="math inline">\(=\dfrac{\Gamma(a+c)\Gamma(b+d)}{\Gamma(a+c+b+d)}\dfrac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\)</span>
<span class="math inline">\(=\dfrac{\beta(a+c,b+d)}{\beta(a,b)}\)</span>.</p>
</blockquote>
<!-- 4. $X \sim Geo(\theta)$  -->
<!-- $P(X=x)=$ $(1-\theta)^{x-1}\theta ~\mathbb{I}_{\{1,2\ldots\}}(x)$ como $X$ é inteira não-negativa, vale que: -->
<!-- $E(X)=$ $\sum_{i=1}^\infty P(X \geq 1)=$ $\sum_{i=1}^\infty \left\{\sum_{j=1}^\infty P(X=j)\right\}=$ $\sum_{i=1}^\infty \left\{\sum_{j=1}^\infty (1-\theta)^{j-1}\theta\right\}=$ $\sum_{i=1}^\infty (1-\theta)^{i-1}\Rightarrow$ $E(x)=\dfrac{1}{\theta}$ -->
<!-- Se $X$ é contínua não-negativa, então -->
<!-- $E(X)=$ $\int_0^\infty P(X>t)dt.$ -->
<!-- **Exemplo** -->
<!-- $X\sim Exp(\lambda)$ -->
<!-- $f_X(x)=\lambda e^{\lambda x}~\mathbb{I}_{\mathbb{R}_+}(x)$ -->
<!-- $P(X > t)=$ $\int_t^\infty \lambda e^{-\lambda s}ds=$ $e^{-\lambda t}$ -->
<!-- Assim, $E(X)=$ $\int_0^\infty P(X>t)dt=$ $\dfrac{1}{\lambda}\underbrace{\int_0^\infty \lambda e^{-\lambda t}dt}_{1} \Rightarrow$ $E(X)=\dfrac{1}{\lambda}$ -->
<!-- 5. $(X,Y)$ absolutamente contínuo com densidade -->
<!-- $f(x,y)=$ $\dfrac{1}{y}e^{-y}~\mathbb{I}_{(0,y)}(x)~\mathbb{I}_{\mathbb{R}_+}(y);$ $g(x,y)=xy$  -->
<!-- $E(g(X,Y))=?$ -->
<!-- $E(XY)=$ $\int_{-\infty}^\infty \int_{-\infty}^\infty xyf(x,y)dxdy=$ $\int_{-\infty}^\infty \left[\int_{-\infty}^\infty xy\dfrac{1}{y}e^{-y}dx\right]dy=$ $\int_{0}^\infty \dfrac{y^2}{2}e^{-y}dy=$ $\dfrac{1}{2}\dfrac{\Gamma(3)}{1^3}\int_0^\infty \dfrac{1^3}{\Gamma(3)}y^2e^{-y}dy \Rightarrow$ $E(XY)=1$ -->
<!-- 6. $(X_1,\ldots,X_k) \sim DIR(a_1,\ldots,a_k)$ -->
<!-- $g(X_1,\ldots,X_k) = X_1^{n_1}X_2^{n_2}\cdots X_k^{n_k}(1-X_1-\ldots-X_k)^{n_0}$ -->
<!-- $E[g(X_1,\ldots,X_k)]=$ $\int_{S_k} X_1^{n_1}\cdots X_k^{n_k}(1-X_1-\ldots-X_k)^{n_0}$ $\underbrace{\dfrac{\Gamma(a_0+a_1+\ldots+a_k)}{\Gamma(a_0)\Gamma(a_1)\ldots\Gamma(a_k)}}_{c(a_0,a_1,\ldots,a_k)}$ $x_1^{a_1-1}x_2^{a_2-1}\ldots x_k^{a_k-1}$ $(1-x_1-\ldots-x_k)^{a_0-1}dx,$ -->
<!-- onde $S_k = \left\{(y_1,y_2,\ldots,y_k)\in \mathbb{R}^K_+: y_1+\ldots+y_k \leq 1\right\}$ -->
<!-- Então, $E[g(y_1,\ldots,y_k)]=$ $c(a_0,a_1,\ldots,a_k)$ $\int_{S_K}x_1^{a_1+n_1-1}\ldots x_k^{a_k+n_k-1}$ $(1-x_1-\ldots-x_k)^{a_0+n_0-1}dx$ -->
<!-- $\Rightarrow E[g(x_1,\ldots,x_k)]=$ $\dfrac{c(a_0,\ldots,a_k)}{c(a_0+n_0,a_1+n_1,\ldots,a_k+n_k)}$ -->
<!-- 7. n lançamentos de uma moeda. Dizemos que ocorre um "rum" de tamanho $k$ se são observadas $k$ caras consecutivas. -->
<!-- $X:$ Número de lançamentos de "run" de tamanho $k$ observados. -->
<!-- $n=4$ $cc\bar{c}c$ -->
<!-- $k=2$ $ccc\bar{c}$ -->
<!-- Definimos  -->
<!-- $X_i=\left\{\begin{array}{ll} -->
<!-- 1, & \text{ se ocorre rum de tamanho k iniciando no i=ésimo lançamento}\\ -->
<!-- 0 & c.c. -->
<!-- \end{array}\right.$ -->
<!-- $X=\sum_{i=1}^{n-k+1}X_i$ -->
<!-- $E(X) = E\left(\sum_{i=1}^{n-k+1}X_i\right)=$ $=\sum_{i=1}^{n-k+1}E(X_i)=$ $\sum_{i=1}^{n-k+1}\left\{1P(X_i=1)+0P(X_i=0)\right\}=$ $\sum_{i=1}^{n-k+1}P(X_i=1)=$ $\sum_{i=1}^{n-k+1}p^k \Rightarrow$  -->
<!-- $E(X)=(n-k+1)p^k.$ -->
<!-- 8. Problema dos pareaentos ($n$ objetos) -->
<!-- $X:$ NÚmero de pareamentos -->
<!-- $X = X_1+X_2+\ldots+X_n$ onde -->
<!-- $X_i=\left\{\begin{array}{ll} -->
<!-- 1, & \text{há areamento na i-ésima posição}\\ -->
<!-- 0, & c.c.\end{array}\right.$ -->
<!-- $E(X)=$ $E\left(\sum_{i=1}^n X_i\right)=$  $\sum_{i=1}^n E(X_i)=$ $\sum_{i=1}^nP(X_i=1)=$ $\sum_{i=1}^n \dfrac{(n-1)!}{n!} \Rightarrow$ $E(X)=1$ -->
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="função-de-distribuição" class="section level2" number="9.4">
<h2><span class="header-section-number">A.4</span> Função de Distribuição</h2>
<p><strong>Definição:</strong> Uma função <span class="math inline">\(F: \mathbb{R} \longrightarrow [0,1]\)</span> é uma <em>função de distribuição</em> (f.d.) se</p>
<ol style="list-style-type: lower-roman">
<li><span class="math inline">\(F\)</span> é não-decrescente e contínua à direita;</li>
<li><span class="math inline">\(\displaystyle\lim_{x\downarrow-\infty}F(x)=0\)</span> e <span class="math inline">\(\displaystyle\lim_{x\uparrow+\infty}F(x)=1\)</span>.</li>
</ol>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Proposição:</strong> Se <span class="math inline">\(X\)</span> é uma v.a., então <span class="math inline">\(F_X(x)=P_X(X\leq x)\)</span> é uma f.d. Recíprocamente, se <span class="math inline">\(F_X\)</span> é uma f.d, então existe uma v.a. <span class="math inline">\(X\)</span> com f.d. <span class="math inline">\(F_X\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<ul>
<li><p>É possível usar uma f.d. <span class="math inline">\(F\)</span> para criar uma medida em <span class="math inline">\((\mathbb{R},\mathcal{B}(\mathbb{R}))\)</span>. Para tal, defina <span class="math inline">\(P\left((a,b]\right)=F(b)-F(a)\)</span> e essa medida pode ser estendida para a <span class="math inline">\(\sigma\)</span>-álgebra usando o Teorema de Extensão de Caratheodory (veja, por exemplo, <span class="citation"><a href="#ref-Schervish12" role="doc-biblioref">Schervish</a> (<a href="#ref-Schervish12" role="doc-biblioref">2012</a>)</span>, pág. 578).</p></li>
<li><p>Reciprocamente, se <span class="math inline">\(P\)</span> é uma medida de probabilidade em <span class="math inline">\((\mathbb{R},\mathcal{B}(\mathbb{R}))\)</span> então <span class="math inline">\(F(x)=P\left((-\infty,x]\right)\)</span> é uma f.d.</p></li>
<li><p>Neste caso, se <span class="math inline">\(g: \mathbb{R}\longrightarrow \mathbb{R}\)</span> é uma função mensurável, não será feita distinção entre <span class="math inline">\(\displaystyle\int g(x)dF(x)=\)</span> <span class="math inline">\(\displaystyle\int g(x)~dP_X(x)\)</span>.</p></li>
<li><p>Se <span class="math inline">\(P\)</span> é uma medida de probabilidade em <span class="math inline">\((\mathbb{R}^k,\mathcal{B}(\mathbb{R}^k))\)</span> então <span class="math inline">\(F(x_1,\ldots,x_k)=\)</span> <span class="math inline">\(P((-\infty,x_1]\times \ldots\times (-\infty,x_k])\)</span> é a <em>função de distribuição conjunta</em> do <em>vector aleatório</em> <span class="math inline">\(\boldsymbol{X} = (X_1,\ldots,X_K)\)</span>.</p></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição:</strong> Uma função de distribuição é dita</p>
<ol style="list-style-type: lower-roman">
<li><p><em>Discreta</em> se existe um conjunto enumerável <span class="math inline">\(B=\{x_1,x_2,\ldots\}\subset \mathbb{R}\)</span> tal que <span class="math inline">\(P_X(B)=1\)</span> e <span class="math inline">\(F_d(x)=\displaystyle\sum_{x_i\leq x} P_X(X=x_i)\)</span>. Nesse caso, <span class="math inline">\(f(x_i)=P_X(X=x_i)\)</span> é chamada <em>função de probabilidade</em> de <span class="math inline">\(X\)</span>;</p></li>
<li><p><em>Absolutamente Contínua</em> é contínua se existe <span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span> tal que <span class="math inline">\(P_X\left((a,b]\right)=F_c(b)-F_c(a) = \displaystyle\int_{a}^{b} f(t)~dt\)</span>. A função <span class="math inline">\(f\)</span> é a <em>função de densidade de probabilidade</em> de <span class="math inline">\(X\)</span>;</p></li>
<li><p><em>Singular</em> se <span class="math inline">\(F_s\)</span> é contínua com <span class="math inline">\(F_s&#39;=0~\)</span> <span class="math inline">\([\lambda]\)</span> q.c. (<span class="math inline">\(F_s\)</span> é singular com relação à medida de Lebesgue <span class="math inline">\(\lambda\)</span>).</p></li>
</ol>
<p><strong>Resultado:</strong> Toda f.d. <span class="math inline">\(F\)</span> pode ser escrita como <span class="math inline">\(F=\alpha_1F_d+\alpha_2F_c+(1-\alpha_1+\alpha_2)F_s\)</span>, com <span class="math inline">\(\alpha_1,\alpha_2\geq 0\)</span> tal que <span class="math inline">\(\alpha_1+\alpha_2\leq 1\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição:</strong> Seja <span class="math inline">\((\Omega,\mathcal{A})\)</span> um espaço mensurável e <span class="math inline">\(\mu_1\)</span> e <span class="math inline">\(\mu_2\)</span> medidas nesse espaço. Dizemos que <span class="math inline">\(\mu_2\)</span> é <em>absolutamente contínua</em> com relação à <span class="math inline">\(\mu_1\)</span> se, <span class="math inline">\(\forall A \in \mathcal{A}\)</span>, <span class="math inline">\(\mu_1(A)=0\)</span> <span class="math inline">\(~\Rightarrow~ \mu_2(A)=0\)</span>.</p>
<ul>
<li>Nesse caso, dizemos que <span class="math inline">\(\mu_2\)</span> é dominada por <span class="math inline">\(\mu_1\)</span> ou que <span class="math inline">\(\mu_1\)</span> é uma medida dominante para <span class="math inline">\(\mu_2\)</span> e denotamos <span class="math inline">\(\mu_2 \ll \mu_1\)</span>.</li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Teorema (de Radon-Nikodin):</strong> Seja <span class="math inline">\(\mu_2 \ll \mu_1\)</span> com <span class="math inline">\(\mu_1\)</span> <span class="math inline">\(\sigma\)</span>-finita. Então, <span class="math inline">\(\exists f: \Omega \longrightarrow [0,+\infty]\)</span> tal que, <span class="math inline">\(\forall A \in \mathcal{A}\)</span>,
<span class="math display">\[\mu_2(A) = \int_A f(x) d\mu_1(x).\]</span>
Além disso, se <span class="math inline">\(g:\Omega \longrightarrow \mathbb{R}\)</span> é <span class="math inline">\(\mu_2\)</span>-integrável, então
<span class="math display">\[\int g(x) d\mu_2(x) = \int g(x) f(x) d\mu_1(x).\]</span>
A função <span class="math inline">\(f=\frac{d\mu_2}{d\mu_1}\)</span> é chamada de derivada de Radon-Nikodin da medida <span class="math inline">\(\mu_2\)</span> com relação à medida <span class="math inline">\(\mu_1\)</span> e é única <span class="math inline">\([\mu_1]\)</span> q.c. (ou seja, é única em todo conjunto <span class="math inline">\(\Omega\)</span> com eventual excessão de um conjunto <span class="math inline">\(C\)</span> tal que <span class="math inline">\(\mu_1(C)=0\)</span>).</p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição:</strong> <span class="math inline">\((\Omega, \mathcal{A}, P)\)</span> espaço de probabilidade e <span class="math inline">\((\mathfrak{X},\mathcal{F},\mu)\)</span> espaço mensurável. Considere <span class="math inline">\(X: \Omega \longrightarrow \mathfrak{X}\)</span> uma v.a. e <span class="math inline">\(P_X\)</span> a medida induzida por <span class="math inline">\(X\)</span> de <span class="math inline">\(P\)</span>, i.e. <span class="math inline">\(P_X(B) = P(X^{-1}(B))\)</span>. Suponha que <span class="math inline">\(P_X \ll \mu\)</span>. Então, a derivada de Radon-Nikodin <span class="math inline">\(f_X = \dfrac{dP_X}{d\mu}\)</span> é chamada <em>densidade de <span class="math inline">\(X\)</span> com respeito à <span class="math inline">\(\mu\)</span></em>.</p>
<p><strong>Proposição:</strong> Se <span class="math inline">\(h: \mathfrak{X}\longrightarrow\mathbb{R}\)</span> é mensurável e <span class="math inline">\(f_X = \dfrac{dP_X}{d\mu}\)</span> é a densidade de <span class="math inline">\(X\)</span> com respeito à <span class="math inline">\(\mu\)</span>, então <span class="math inline">\(\displaystyle\int h(x)dF_X(x)\)</span> <span class="math inline">\(=\displaystyle\int h(x)f_X(x)d\mu\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo 1:</strong> Seja <span class="math inline">\(\Omega=\mathfrak{X}=\mathbb{R}\)</span> com a <span class="math inline">\(\sigma\)</span>-álgebra de Borel e <span class="math inline">\(f\)</span> uma função não negativa tal que <span class="math inline">\(\displaystyle\int f(x) dx = 1\)</span>. Defina <span class="math inline">\(\displaystyle P(A)= \int_A f(x) dx\)</span> e <span class="math inline">\(X(\omega)=\omega\)</span>. Então, <span class="math inline">\(X\)</span> é uma variável aleatória absolutamente contínua com função de densidade de probabilidade (f.d.p.) <span class="math inline">\(f\)</span> e <span class="math inline">\(P_X = P\)</span>. Além disso, <span class="math inline">\(P_X\)</span> é absolutamente contínua com relação à medida de Lebesgue <span class="math inline">\((P_X \ll \lambda)\)</span> e <span class="math inline">\(\frac{dP_X}{d\lambda}=f\)</span>.</p>
</blockquote>
<p><img src="InfBayes_files/figure-html/FDcontinua-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo 2:</strong> Seja <span class="math inline">\(\Omega=\mathbb{R}\)</span> com a <span class="math inline">\(\sigma\)</span>-álgebra de Borel, <span class="math inline">\(\mathfrak{X} = \{x_1,x_2,\ldots\}\)</span> um conjunto enumerável. Seja <span class="math inline">\(f\)</span> uma função não negativa definida em <span class="math inline">\(\mathfrak{X}\)</span> tal que <span class="math inline">\(\displaystyle \sum_{i=1}^{\infty} f(x_i) = 1\)</span>. Defina <span class="math inline">\(\displaystyle P_X(A) = \sum_{\{i:~x_i \in A\}} f(x_i)\)</span>. Então <span class="math inline">\(X\)</span> é uma variável aleatória discreta com função de probabilidade (f.d.p.) <span class="math inline">\(f\)</span>. Além disso, <span class="math inline">\(P_X\)</span> é absolutamente contínua com relação à medida de contagem <span class="math inline">\((P_X \ll \nu)\)</span> e <span class="math inline">\(\frac{dP_X}{d\nu}=f\)</span>.</p>
</blockquote>
<p><img src="InfBayes_files/figure-html/FDdiscreta-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado</strong> Sejam <span class="math inline">\((\Omega,\mathcal{A})\)</span> espaço mensurável, <span class="math inline">\(P_1,P_2: \mathcal{A}\longrightarrow [0,1]\)</span> medidas de probabilidade, <span class="math inline">\(X: \Omega \longrightarrow \mathbb{R}\)</span> v.a. e <span class="math inline">\(P=\alpha P_1+(1-\alpha)P_2\)</span> com <span class="math inline">\(0\leq\alpha\leq1\)</span>. Então,<br />
<span class="math inline">\(\displaystyle\int_\Omega XdP\)</span> <span class="math inline">\(=\displaystyle\alpha \int_\Omega XdP_1 + (1-\alpha)\int_\Omega XdP_2\)</span>.</p>
<blockquote>
<p><strong>Caso 1.</strong> <span class="math inline">\(X\)</span> simples, <span class="math inline">\(X=\displaystyle\sum_{i=1}^kX_i~\mathbb{I}_{A_i}\)</span>.<br />
<span class="math inline">\(\displaystyle\int_\Omega XdP\)</span> <span class="math inline">\(=\displaystyle\sum_{i=1}^kx_i~P(A_i)\)</span> <span class="math inline">\(=\displaystyle\sum_{i=1}^k x_i[\alpha P_1(A_i)+(1-\alpha)P_2(A_i)]\)</span> <span class="math inline">\(=\displaystyle\alpha \sum_{i=1}^k x_iP_1(A_i)+(1-\alpha)\sum_{i=1}^k x_iP_2(A_i)\)</span> <span class="math inline">\(=\displaystyle\alpha \int_\Omega XdP_1+(1-\alpha)\int_\Omega XdP_2\)</span>.</p>
</blockquote>
<blockquote>
<p><strong>Caso 2.</strong> <span class="math inline">\(X \geq 0\)</span>.<br />
Considere a sequência <span class="math inline">\(\left(X_n\right)_{n\geq 1}\)</span> tal que <span class="math inline">\(X_n \uparrow X\)</span>, <span class="math inline">\(X_n \geq 0\)</span> simples. Então,<br />
<span class="math inline">\(=\displaystyle\int_\Omega XdP\)</span> <span class="math inline">\(=\displaystyle\lim_{n\rightarrow\infty}\int_\Omega X_n dP\)</span> <span class="math inline">\(=\displaystyle\lim_{n\rightarrow\infty}\left\{\alpha\int_\Omega X_ndP_1+(1-\alpha)\int_\Omega X_ndP_2\right\}\)</span> <span class="math inline">\(=\displaystyle\alpha\lim_{n\rightarrow\infty}\int_\Omega X_ndP_1 + (1-\alpha)\lim_{n\rightarrow\infty}\int_\Omega X_n dP_2\)</span> <span class="math inline">\(=\displaystyle\alpha\int XdP_1 + (1-\alpha)\int_\Omega XdP_2\)</span>.</p>
</blockquote>
<blockquote>
<p><strong>Caso 3.</strong> <span class="math inline">\(X\)</span> qualquer.<br />
Basta escrever <span class="math inline">\(X=X^+-X^-\)</span> e repetir o procedimento anterior.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p>Seja <span class="math inline">\(P_1\)</span> uma distribuição discreta com <span class="math inline">\(P_1\left(\left\{x_1,x_2,\ldots\right\}\right)=1\)</span>, <span class="math inline">\(P_2\)</span> uma distribuição absolutamente contínua com função densidade de probabilidade <span class="math inline">\(f_x\)</span> e <span class="math inline">\(X:\Omega \longrightarrow \mathbb{R}\)</span> tal que <span class="math inline">\(P_X(X \in A)=\)</span> <span class="math inline">\(\alpha P_1\left(X^{-1}(A)\right)+(1-\alpha)P_2\left(X^{-1}(A)\right)\)</span>. Então,</p>
<p><span class="math inline">\(E(X)\)</span> <span class="math inline">\(=\displaystyle\int_\Omega XdP\)</span> <span class="math inline">\(=\displaystyle\alpha \int_\Omega XdP_1 + (1-\alpha)\int_\Omega XdP_2\)</span> <span class="math inline">\(=\displaystyle\alpha \sum_{i=1}^\infty x_iP_1(X=x_i)+(1-\alpha)\int_{-\infty}^\infty x f_X(x)dx~.\)</span></p>
<blockquote>
<p><strong>Exemplo.</strong> Considere uma v.a. <span class="math inline">\(X\)</span> com f.d. dada por<br />
<span class="math inline">\(F_X(t)=\left\{\begin{array}{ll} 0, &amp; t&lt;0\\ \dfrac{1}{15}+\dfrac{2}{3}t, &amp; 0\leq t &lt; 1\\ 1, &amp; t \geq 1\end{array}\right.\)</span></p>
</blockquote>
<p><img src="InfBayes_files/figure-html/FDmistura-1.png" width="80%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Temos que <span class="math inline">\(P(X=0)=1/15\)</span>, <span class="math inline">\(P(X=1)=4/15\)</span> e, assim, <span class="math inline">\(P(0&lt;X&lt;1)=10/15=2/3=1-\alpha\)</span>, de modo que<br />
<span class="math inline">\(\dfrac{1}{15}\)</span> <span class="math inline">\(=P(X=0)\)</span> <span class="math inline">\(=\alpha P_1(X=0)\)</span> <span class="math inline">\(=1/3~P_1(X=0)\)</span>
<span class="math inline">\(\Rightarrow P_1(X=0)=\dfrac{1}{5} = 1-P_1(X=1)\)</span>.<br />
<span class="math inline">\(E(X)\)</span> <span class="math inline">\(=\displaystyle\alpha\int_\Omega XdP_1+(1-\alpha)\int_\Omega X dP_2\)</span> <span class="math inline">\(=\displaystyle\dfrac{1}{3}\left\{0\cdot\dfrac{1}{5}+1\cdot\dfrac{4}{5}\right\}+\dfrac{2}{3}\int_{0}^{1} x~f_X(x)dx\)</span> <span class="math inline">\(=\displaystyle\dfrac{1}{3}\cdot\dfrac{4}{5}+\dfrac{2}{3}\int_0^1 xdx\)</span> <span class="math inline">\(=\dfrac{4}{15}+\dfrac{1}{3}\)</span> <span class="math inline">\(=\dfrac{4}{15}+\dfrac{5}{15}\)</span> <span class="math inline">\(=\dfrac{9}{15}\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="probabilidade-condicional" class="section level2" number="9.5">
<h2><span class="header-section-number">A.5</span> Probabilidade Condicional</h2>
<p><strong>Motivação:</strong> <span class="math inline">\(P(B|A)=\)</span> <span class="math inline">\(\dfrac{P(A\cap B)}{P(A)}\)</span> é bem definido se <span class="math inline">\(P(A)&gt;0.\)</span></p>
<p>Seja <span class="math inline">\(X,Y: \Omega \longrightarrow \mathbb{R}\)</span> v.a. tais que <span class="math inline">\(P_X\left([0,1]\right)=1\)</span> e <span class="math inline">\(P_Y\left(\{0,1\}\right)=1\)</span>. Considere um experimento em dois estagios onde seleciona-se <span class="math inline">\(X\)</span> segundo uma distribuição absolutamente contínua <span class="math inline">\(F_X\)</span> e, dado <span class="math inline">\(X=x\)</span>, <span class="math inline">\(0\leq x\leq 1\)</span>, uma moeda com probabilidade <span class="math inline">\(x\)</span> é lançada <span class="math inline">\(n\)</span> vezes. Nesse caso, é natural definir <span class="math inline">\(Y~\big|~X=x\sim \text{Bin}(n,x)\)</span>, mesmo que <span class="math inline">\(P(X=x)=0\)</span>, <span class="math inline">\(\forall x \in [0,1]\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Teorema da Medida Produto (para medidas de probabilidade)</strong><br />
Seja <span class="math inline">\((\Omega_1, \mathcal{A}_1,P_1)\)</span> um espaço de probabilidade e <span class="math inline">\((\Omega_2,\mathcal{A}_2)\)</span> um espaço mensurável. Para cada <span class="math inline">\(\omega_1 \in \Omega_1,\)</span> defina uma medida de probabilidade <span class="math inline">\(\mu(\omega_1,.)\)</span> em <span class="math inline">\(\mathcal{A}_2.\)</span> Assuma também que, para cada <span class="math inline">\(B \in \mathcal{A}_2,\)</span> <span class="math inline">\(\mu(.,B)\)</span> é <span class="math inline">\(\mathcal{A}_1\)</span>-mensurável. Então, existe uma única medida de probabilidade <span class="math inline">\(P\)</span> em <span class="math inline">\(\mathcal{A}= \mathcal{A}_1\times\mathcal{A}_2\)</span> tal que</p>
<p><span class="math inline">\(P(A\times B)\)</span> <span class="math inline">\(=\displaystyle\int_A \mu(\omega_1,B)dP_1(\omega_1)~,~\)</span> <span class="math inline">\(\forall A\in \mathcal{A}_1,\)</span> <span class="math inline">\(\forall B\in \mathcal{A}_2.\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p>Se <span class="math inline">\(D(\omega_1)\)</span> denota uma secção de <span class="math inline">\(D\)</span> em <span class="math inline">\(\omega_1,\)</span> isto é, <span class="math inline">\(D(\omega_1)=\)</span> <span class="math inline">\(\{\omega_2\in \Omega_2: (\omega_1,\omega_2)\in D\},\)</span> <span class="math inline">\(D\in \mathcal{A}=\mathcal{A}_1\times\mathcal{A}_2,\)</span> então <span class="math inline">\(P(D)\)</span> <span class="math inline">\(=\displaystyle\int_{\Omega_1}\mu\left(\omega_1,D(\omega_1)\right)dP_1(\omega_1).\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p>Voltando à probabilidade condicional, interprete (informalmente, por enquanto) a medida <span class="math inline">\(\mu(x,B)\)</span> do teorema anterior como <span class="math inline">\(P(Y\in B| X=x).\)</span> Ainda informalmente, considere o evento <span class="math inline">\(\{X=x\}\)</span>. Intuitivamente, a probabilidade que <span class="math inline">\(X\in (x,x+dx]\)</span> é <span class="math inline">\(dF_X(x).\)</span>
Então, sabendo que <span class="math inline">\(X=x\)</span> ocorreu, o evento <span class="math inline">\(\left\{(X,Y)\in C\right\}\)</span> ocorre se, e somente, <span class="math inline">\(Y \in C(x)\)</span> <span class="math inline">\(=\{y:(x,y)\in C\}\)</span> e a probabilidade desse evento é <span class="math inline">\(\mu(x,C(x)).\)</span> Pela regra da probabilidade total,</p>
<p><span class="math inline">\(P(C)\)</span> <span class="math inline">\(=P\left(\left\{(X,Y)\in C\right\}\right)\)</span> <span class="math inline">\(=\displaystyle\int_{\mathbb{R}}\mu\left(x,C(x)\right)dF(x).\)</span></p>
<p>Em particular, quando <span class="math inline">\(C=\{(x,y):~ x\in A, y \in B\}\)</span> <span class="math inline">\(=A\times B~,\)</span> <span class="math inline">\(C(x)=B\)</span> se <span class="math inline">\(x\in A\)</span> e <span class="math inline">\(C(x)=\varnothing\)</span> se <span class="math inline">\(x \notin A~,\)</span> então</p>
<p><span class="math inline">\(P(C)\)</span> <span class="math inline">\(=P(A\times B)\)</span> <span class="math inline">\(=\displaystyle\int_A \mu(x,B)dF(x)\)</span></p>
<p>Se <span class="math inline">\(\mu(x,B)\)</span> é mensurável em <span class="math inline">\(x\)</span> para cada <span class="math inline">\(B\in \mathcal{B}(\mathbb{R}),\)</span> então, pelo Teorema anterior, <span class="math inline">\(P\)</span> é única.</p>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo 1.</strong> Seja <span class="math inline">\(X \sim Beta(a,b)\)</span> e <span class="math inline">\(Y|X=x \sim Bin(n,x)\)</span><br />
<span class="math inline">\(~\)</span><br />
Considere <span class="math inline">\(\left(\Omega_1=[0,1],\mathcal{A}_1=\mathcal{B}([0,1]),P_X\right),\)</span> de modo que, para <span class="math inline">\(A \in \mathcal{A}_1~,\)</span><br />
<span class="math inline">\(P_X(A)\)</span> <span class="math inline">\(=\displaystyle\int_{\mathbb{R}}\mathbb{I}_A dF_X(x)\)</span> <span class="math inline">\(=\displaystyle\int_A f_X(x)dx\)</span> <span class="math inline">\(=\displaystyle\int_A \tfrac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}~x^{a-1}(1-x)^{b-1}dx\)</span>.<br />
Além disso, considere <span class="math inline">\(\left(\Omega_2=\{0,1,\ldots,n\}, \mathcal{A}_2=\mathcal{P}(\Omega_2)\right)\)</span> e, para cada <span class="math inline">\(x \in [0,1]~,\)</span> defina <span class="math inline">\(\mu(x,B)=P(Y \in B~|~ X=x).\)</span> Então, para <span class="math inline">\(k=0,1,\ldots,n,\)</span><br />
<span class="math inline">\(\mu\left(x,\{k\}\right)\)</span> <span class="math inline">\(=P(Y=k~|~ X=x)\)</span> <span class="math inline">\(=\displaystyle\binom{n}{k}x^k(1-x)^{n-k}~\)</span> (que é mensurável em <span class="math inline">\(x\)</span>).<br />
Tomando <span class="math inline">\(\Omega=\Omega_1 \times \Omega_2~,~\)</span> <span class="math inline">\(\mathcal{A}=\mathcal{A}_1 \times \mathcal{A}_2~,~\)</span> <span class="math inline">\(P\)</span> é a única medida de probabilidade determinada por <span class="math inline">\(P_X\)</span> (ou <span class="math inline">\(F_X\)</span>) e <span class="math inline">\(\mu(x,\cdot)~.\)</span> Assim, para <span class="math inline">\(C \in \mathcal{A}~,\)</span><br />
<span class="math inline">\(P(C)\)</span> <span class="math inline">\(=\displaystyle\int_{\Omega_1}\mu\left(x,C(x)\right)dP_X\)</span> <span class="math inline">\(=\displaystyle\int_0^1 \mu\left(x,C(x)\right)dF_X(x)\)</span> <span class="math inline">\(=\displaystyle\int_0^1 \mu\left(x,C(x)\right)f_X(x)dx~.\)</span><br />
<span class="math inline">\(~\)</span><br />
Por exemplo, se <span class="math inline">\(C=\Omega_1 \times \{k\},\)</span> temos<br />
<span class="math inline">\(P\left(\Omega_1 \times \{k\}\right)\)</span>
<span class="math inline">\(=P\left(\left\{X\in[0,1]~,~Y=k\right\}\right)\)</span>
<span class="math inline">\(=P_Y\left(Y=k\right)\)</span>
<span class="math inline">\(=\displaystyle\int_0^1P(Y=k|X=x)dF_X(x)\)</span>
<span class="math inline">\(=\displaystyle\int_0^1P(Y=k|X=x)f_X(x)dx\)</span>
<span class="math inline">\(=\displaystyle\int_0^1 \binom{n}{k}x^k(1-x)^{n-k} ~\tfrac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}~x^{a-1}(1-x)^{b-1}dx\)</span>
<span class="math inline">\(=\displaystyle\binom{n}{k}\tfrac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\tfrac{\Gamma(a+k)\Gamma(b+n-k)}{\Gamma(a+b+n)}\int_0^1\tfrac{\Gamma(a+b+n)}{\Gamma(a+k)\Gamma(b+n-k)}~x^{(a+k)-1}(1-x)^{(b+n-k)-1}~dx\)</span>
<span class="math inline">\(=\displaystyle\binom{n}{k}\tfrac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\tfrac{\Gamma(a+k)\Gamma(b+n-k)}{\Gamma(a+b+n)}\)</span>
<span class="math inline">\(=\displaystyle\binom{n}{k}\dfrac{\beta(a+k,b+n-k)}{\beta(a,b)}~.\)</span><br />
<span class="math inline">\(~\)</span><br />
Nesse caso, diz-se que <span class="math inline">\(Y \sim \text{Beta-Bin}(n,a,b)\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Teorema</strong> Considere <span class="math inline">\((\Omega,\mathcal{A},P)\)</span> e <span class="math inline">\(X:\Omega \longrightarrow \mathfrak{X}\)</span>, <span class="math inline">\(\mathcal{F}\)</span> uma <span class="math inline">\(\sigma\)</span>-álgebra de <span class="math inline">\(\mathfrak{X}\)</span> e <span class="math inline">\(B \in \mathcal{A}.\)</span> Então existe <span class="math inline">\(g:\mathfrak{X} \longrightarrow \mathbb{R}\)</span> tal que, para cada <span class="math inline">\(A \in \mathcal{F},\)</span>
<span class="math inline">\(P(\{X\in A\}\cap B)\)</span> <span class="math inline">\(=\displaystyle\int_Ag(x)dP_X(x).\)</span><br />
Além disso, <span class="math inline">\(g\)</span> é única <span class="math inline">\([P_X]\)</span> q.c., isto é, <span class="math inline">\(g(x)=P(B|X=x)\)</span> é única <span class="math inline">\([P_X]\)</span> q.c. para um dado <span class="math inline">\(B\in\mathcal{A}\)</span>.</p>
<blockquote>
<p><strong>Demo:</strong> segue diretamente do Teorema de Radon-Nikodin: se <span class="math inline">\(\mu(A)=\)</span> <span class="math inline">\(P(\{X\in A\}\cap B)\)</span> então <span class="math inline">\(\mu\)</span> é medida finita em <span class="math inline">\(\mathcal{F}\)</span> com <span class="math inline">\(\mu &lt;&lt; P_X\)</span>.</p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo 2.</strong> Seja <span class="math inline">\(\mathfrak{X}=\{x_1,x_2,\ldots\}\)</span> com <span class="math inline">\(p_i=P(\{X=x_i\})&gt;0.\)</span> Para <span class="math inline">\(i=1,2,\ldots\)</span>, considere a função <span class="math inline">\(g\)</span>, uma “proposta” para <span class="math inline">\(P\left(B|\{X=x_i\}\right)\)</span>, definida por <span class="math inline">\(g(x_i)\)</span> <span class="math inline">\(=P\left(B|\{X=x_i\}\right)\)</span> <span class="math inline">\(=\dfrac{P\left(B\cap \{X=x_i\}\right)}{P\left(\{X=x_i\}\right)}~.\)</span><br />
Seja <span class="math inline">\(A \in \mathcal{F}=\mathcal{P}(\mathfrak{X}),\)</span> então<br />
<span class="math inline">\(\displaystyle\int_A g(x)~dP_X(x)\)</span>
<span class="math inline">\(=\displaystyle\int_{\mathfrak{X}}g(x)~\mathbb{I}_A(x)dP_X(x)\)</span>
<span class="math inline">\(=\displaystyle\sum_{i=1}^\infty g(x_i)~\mathbb{I}_A(x_i)P_X(X=x_i)\)</span>
<span class="math inline">\(=\displaystyle\sum_{x_i \in A}g(x_i)P\left(\{X=x_i\}\right)\)</span>
<span class="math inline">\(=\displaystyle\sum_{x_i \in A}\dfrac{P\left(B\cap \{X=x_i\}\right)}{P\left(\{X=x_i\}\right)}P\left(\{X=x_i\}\right)\)</span>
<span class="math inline">\(=\displaystyle\sum_{x_i \in A}P\left(B \cap \{X=x_i\}\right)\)</span>
<span class="math inline">\(=P\left(\{X\in A\}\cap B\right).\)</span></p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo 3.</strong> Considere agora <span class="math inline">\(\Omega=\mathbb{R}^2,\)</span> <span class="math inline">\(\mathcal{A}= \mathcal{B}\left(\mathbb{R}^2\right),\)</span> <span class="math inline">\(X(x,y)=x,\)</span> <span class="math inline">\(Y(x,y)=y\)</span> e <span class="math inline">\(\left(X,Y\right)\)</span> vetor aleatório (absolutamente) contínuo com <em>densidade conjunta</em> <span class="math inline">\(f\)</span>, isto é, <span class="math inline">\(P(A)=\displaystyle\int \int_A f(x,y)~dxdy~,~~\)</span> <span class="math inline">\(A \in \mathcal{A}~.\)</span> Nesse caso <span class="math inline">\(P\left(\{X=x\}\right)=0~,~~ \forall x~.\)</span><br />
<span class="math inline">\(~\)</span><br />
Seja <span class="math inline">\(f_1(x)=\displaystyle\int_{-\infty}^{\infty} f(x,y)~dy\)</span> a <em>densidade marginal</em> de <span class="math inline">\(X\)</span> e defina <span class="math inline">\(f(y|x)=\dfrac{f(x,y)}{f_1(x)}\)</span> como a <em>densidade condicional</em> de <span class="math inline">\(Y\)</span> dado <span class="math inline">\(X=x.\)</span><br />
<span class="math inline">\(~\)</span><br />
Note que <span class="math inline">\(f(y|x)\)</span> só está definido quando <span class="math inline">\(f_1(x) \neq 0.\)</span> Contudo, se <span class="math inline">\(S=\{(x,y): f_1(x)=0\}\)</span> então<br />
<span class="math inline">\(P\left(\{(X,Y)\in S\}\right)\)</span>
<span class="math inline">\(=\displaystyle\int \int_S f(x,y)dxdy\)</span> <span class="math inline">\(=\displaystyle\int_{\{x:f_1(x)=0\}}\left[\int_{-\infty}^\infty f(x,y)dy\right]dx\)</span>
<span class="math inline">\(=\displaystyle\int_{\{x:f_1(x)=0\}} f_1(x)dx=0~,\)</span>
de modo que <span class="math inline">\(P\left(\{(X,Y)\in S\}\right)=0\)</span> e podemos “ignorar” o conjunto onde <span class="math inline">\(f(y|x)\)</span> não está definida.<br />
<span class="math inline">\(~\)</span><br />
Se <span class="math inline">\(X=x,\)</span> <span class="math inline">\(\forall~ B \in \mathcal{A},\)</span> <span class="math inline">\(B\)</span> ocorre se, e somente se, <span class="math inline">\(Y \in B(x)=\left\{y:(x,y) \in B\right\}.\)</span> Assim, considere a “proposta”<br />
<span class="math inline">\(g(x)\)</span> <span class="math inline">\(=P\left(\left\{Y \in B(x)|X=x\right\}\right)\)</span>
<span class="math inline">\(=\displaystyle\int_{B(x)}f(y|x)dy\)</span>
<span class="math inline">\(=\displaystyle\int_{-\infty}^\infty \mathbb{I}_B(x,y)f(y|x)dy~.\)</span><br />
<span class="math inline">\(~\)</span><br />
Então, se <span class="math inline">\(A \in \mathcal{B}(\mathbb{R}),\)</span><br />
<span class="math inline">\(P\left(\{X \in A\}\cap B\right)\)</span>
<span class="math inline">\(=\displaystyle\underset{\left\{x\in A~;~(x,y)\in B\right\}}{\int\int} f(x,y)dxdy\)</span>
<span class="math inline">\(=\displaystyle\int_{-\infty}^{\infty}\left[\int_{-\infty}^{\infty}\mathbb{I}_B(x,y)f(y|x)dy\right]~\mathbb{I}_A(x)f_1(x)dx\)</span>
<span class="math inline">\(=\displaystyle\int_Af_1(x)dx\underbrace{\int_{B(x)}f(y|x)dy}_{g(x)}dx\)</span>
<span class="math inline">\(=\displaystyle\int_Ag(x)f_1(x)dx\)</span>
<span class="math inline">\(=\displaystyle\int_Ag(x)dP_X(x)~.\)</span><br />
Portanto, <span class="math inline">\(g(x)=P(B|X=x)~.\)</span></p>
</blockquote>
<p><span class="math inline">\(~\)</span></p>
<p>No exemplo anterior, a relações entre as densidades <span class="math inline">\(f(x,y)=f_1(x)f(y|x)\)</span> ou, equivalentemente, <span class="math inline">\(f(x,y)=f_2(y)f(x|y)\)</span>, podem ser usadas para obter a probabilidade condicional <span class="math inline">\(\displaystyle P(Y\in C|X=y)=\int_C f(y|x)dy\)</span>, <span class="math inline">\(C\in\mathcal{B}(\mathbb{R})\)</span>. Além disso, para <span class="math inline">\(A,B\in\mathcal{B}(\mathbb{R})\)</span>, existe uma única medida <span class="math inline">\(P\)</span> satisfazendo<br />
<span class="math inline">\(P(X\in A,Y \in B)\)</span>
<span class="math inline">\(=\displaystyle\int_A P(B|X=x) f_1(x)dxdy\)</span>
<span class="math inline">\(=\displaystyle\int_A \int_Bf(y|x)f_1(x)dydx\)</span>
<span class="math inline">\(=\displaystyle\int_A \int_B f(x,y)dxdy\)</span>
<span class="math inline">\(=\displaystyle\int_B \int_Af(x|y)f_2(y)dxdy~.\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<blockquote>
<p><strong>Exemplo 4. Esperança Condicional</strong><br />
Seja <span class="math inline">\((\Omega=[0,1]^2, \mathcal{A}=\mathcal{B}([0,1]^2),P=\lambda)\)</span> e considere as partições apresentados na figura a seguir.</p>
</blockquote>
<p><img src="InfBayes_files/figure-html/esperanca-1.png" width="80%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Defina as v.a. <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> como<br />
<span class="math inline">\(X(\boldsymbol \omega)=\left\{\begin{array}{lll} x_2, &amp; \omega_1 \geq 1/2 &amp; (A)\\ x_1, &amp; \omega_2 &lt; 1/2 &amp; (A^c)\end{array}\right.\)</span><br />
<span class="math inline">\(Y(\boldsymbol \omega)=\left\{\begin{array}{lll} y_2, &amp; \omega_1 \leq \omega_2 &amp; (B)\\ y_1, &amp; \omega_1 &gt; \omega_2&amp; (B^c)\end{array}\right.\)</span><br />
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(P_X(x_2)\)</span> <span class="math inline">\(=P\left(X^{-1}\left(\{x_2\}\right)\right)\)</span> <span class="math inline">\(=P(\boldsymbol\omega \in A)\)</span> <span class="math inline">\(=\lambda(A)=1/2\)</span><br />
<span class="math inline">\(P_Y(y_2)\)</span> <span class="math inline">\(=P\left(Y^{-1}\left(\{y_2\}\right)\right)\)</span> <span class="math inline">\(=P(\boldsymbol\omega \in B)=\)</span> <span class="math inline">\(\lambda(B)=1/2\)</span><br />
<span class="math inline">\(~\)</span><br />
<span class="math inline">\(\sigma_X\)</span> <span class="math inline">\(=\left\{\varnothing,A,A^c,\Omega\right\} \subseteq \mathcal{B}\left([0,1]^2\right)\)</span> (é sub-<span class="math inline">\(\sigma\)</span>-álgebra de <span class="math inline">\(\mathcal{A}\)</span>)<br />
<span class="math inline">\(\sigma_Y\)</span> <span class="math inline">\(=\left\{\varnothing,B,B^c,\Omega\right\} \subseteq \mathcal{B}\left([0,1]^2\right)\)</span><br />
<span class="math inline">\(~\)</span><br />
Seja <span class="math inline">\(\boldsymbol Z(\boldsymbol \omega)=\)</span> <span class="math inline">\(\left(X(\boldsymbol \omega), Y(\boldsymbol \omega)\right)\)</span> <span class="math inline">\(=(X,Y)(\boldsymbol \omega)~.\)</span> Então, <span class="math inline">\(Z: \Omega\longrightarrow \mathbb{R}^2\)</span>, de modo que <span class="math inline">\(Z(\boldsymbol \omega)\)</span> <span class="math inline">\(=\displaystyle\sum_{i=1}^4 \boldsymbol z_i ~\mathbb{I}_{C_i}(\boldsymbol \omega)\)</span> é uma função simples com<br />
<span class="math inline">\(Z(\boldsymbol \omega)=\left\{\begin{array}{ll} \boldsymbol z_1=(x_1,y_1), &amp; \boldsymbol \omega \in A^c \cap B^c=C_1\\ \boldsymbol z_2=(x_2,y_1), &amp; \boldsymbol \omega \in A \cap B^c=C_2\\ \boldsymbol z_3=(x_1,y_2), &amp; \boldsymbol \omega \in A^c \cap B=C_3\\ \boldsymbol z_4=(x_2,y_2), &amp; \boldsymbol \omega \in A \cap B=C_4 \end{array}\right.~,\)</span><br />
onde <span class="math inline">\(C_i=\boldsymbol Z^{-1}\left(\{\boldsymbol z_i\}\right)\)</span> <span class="math inline">\(= \left\{\boldsymbol\omega\in\Omega:\big(X(\boldsymbol\omega),Y(\boldsymbol\omega)\big)=\boldsymbol z_i\right\}~.\)</span> Então,<br />
<span class="math inline">\(P_Z(\boldsymbol z_1)\)</span> <span class="math inline">\(=P_Z(\boldsymbol z_4)\)</span> <span class="math inline">\(=P_Z\big((x_1,y_1)\big)\)</span> <span class="math inline">\(=P_Z\big((x_2,y_2)\big)\)</span> <span class="math inline">\(=\dfrac{1}{8}\)</span> <span class="math inline">\(=\lambda(A^c\cap B^c)\)</span> <span class="math inline">\(=\lambda(A\cap B)~,\)</span><br />
<span class="math inline">\(P_Z(\boldsymbol z_2)\)</span> <span class="math inline">\(=P_Z(\boldsymbol z_3)\)</span> <span class="math inline">\(=P_Z\big((x_2,y_1)\big)\)</span> <span class="math inline">\(=P_Z\big((x_1,y_2)\big)\)</span> <span class="math inline">\(=\dfrac{3}{8}\)</span> <span class="math inline">\(=\lambda(A\cap B^c)\)</span> <span class="math inline">\(=\lambda(A^c\cap B)~.\)</span><br />
<span class="math inline">\(~\)</span><br />
Pela que foi visto anteriormente, podemos definir<br />
<span class="math inline">\(P_{Y|X=x_i}\left(Y=y_j~|~X=x_i\right)\)</span>
<span class="math inline">\(=\dfrac{P\left(\left\{Y=y_j~,~X=x_i\right\}\right)}{P\left(\left\{X=x_i\right\}\right)}\)</span>
<span class="math inline">\(=\left\{\begin{array}{ll}\dfrac{1/8}{1/2}=\dfrac{1}{4}~,&amp;i=j\\\dfrac{3/8}{1/2}=\dfrac{3}{4}~,&amp;i\neq j\end{array}\right.~~,\)</span><br />
e, assim,<br />
<span class="math inline">\(E\left[Y~|~X=x_i\right]\)</span> <span class="math inline">\(=\displaystyle\int y~dP_{Y|x_i}(y)\)</span>
<span class="math inline">\(=\displaystyle\sum_{j=1}^{2} y_j~P\left(Y=y_j|X=x_i\right)~.\)</span><br />
<span class="math inline">\(~\)</span><br />
Considere, por exemplo, <span class="math inline">\(x_1=y_1=1\)</span> e <span class="math inline">\(x_2=y_2=2\)</span>. Então,<br />
<span class="math inline">\(E[Y|X=1]\)</span> <span class="math inline">\(=1\cdot\dfrac{1}{4}+2\cdot\dfrac{3}{4}\)</span> <span class="math inline">\(=\dfrac{7}{4}~,\)</span><br />
<span class="math inline">\(E[Y|X=2]\)</span> <span class="math inline">\(=1\cdot\dfrac{3}{4}+2\cdot\dfrac{1}{4}\)</span> <span class="math inline">\(=\dfrac{5}{4}~.\)</span><br />
<span class="math inline">\(~\)</span><br />
Deste modo, podemos definir uma nova v.a.<br />
<span class="math inline">\(E[Y|X](\boldsymbol\omega)=\left\{\begin{array}{ll} 5/4~, &amp; \left\{\boldsymbol\omega:X(\boldsymbol\omega)=x_2\right\}=\{\boldsymbol\omega \in A\}\\ 7/4~, &amp; \left\{\boldsymbol\omega:X(\boldsymbol\omega)=x_1\right\}=\{\boldsymbol\omega \in A^c\} \end{array}\right.~.\)</span><br />
<span class="math inline">\(~\)</span><br />
Note que a <span class="math inline">\(\sigma\)</span>-álgebra gerada pela v.a. <span class="math inline">\(E[Y|X]\)</span> coincide com a gerada por <span class="math inline">\(X\)</span>, <span class="math inline">\(\sigma_X\)</span>. Dessa forma, podemos definir, de forma equivalente para esse caso, o <em>valor esperado de <span class="math inline">\(Y\)</span> condicional à <span class="math inline">\(\sigma_X\)</span></em> por<br />
<span class="math inline">\(E[Y|X]=E[Y|\sigma_X]~.\)</span></p>
</blockquote>
<!-- $P_Z(\boldsymbol z_1| \boldsymbol z_1 \cap \boldsymbol z_3)=$ $\dfrac{P_Z(\boldsymbol z_1 \cap (\boldsymbol z_1 \cup \boldsymbol  z_3))}{P_Z(\boldsymbol  z_1 \cup \boldsymbol z_3)}=$ $\dfrac{P_Z(\boldsymbol  z_1)}{P_Z(\boldsymbol  z_1)+P_Z(\boldsymbol  z_3)}=$ $\dfrac{3/8}{3/8 + 1/8}=$ $\dfrac{3}{4}=$ $P_Z((X=x_1,Y=y_1)|\overbrace{X \in \{x_1,x_2\}}^{\Omega}, Y=y_1)=$ $P_{X|Y=y_1}(X=x_1|Y=y_1)=$ $1-P_{X|y_1}(X=x_2|Y=y_1).$ -->
<!-- $P_{X|y_1}(X=x_1|Y=y_2)= \dfrac{1/8}{4/8}=\dfrac{1}{4}$ -->
<p><span class="math inline">\(~\)</span></p>

</div>
</div>
<h3>Referências</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Ash00" class="csl-entry">
Ash, R. B., and C. Doleans-Dade. 2000. <em>Probability and Measure Theory</em>. California: Academic Press.
</div>
<div id="ref-Billingsley86" class="csl-entry">
Billingsley, P. 1986. <em>Probability and Measure</em>. Second. Wiley Series in Probability and Mathematical Statistics. New York: John Wiley &amp; Sons, Inc.
</div>
<div id="ref-Schervish12" class="csl-entry">
Schervish, M. J. 2012. <em>Theory of Statistics</em>. Springer Science &amp; Business Media.
</div>
<div id="ref-Shiryaev96" class="csl-entry">
Shiryaev, A. N. 1996. <em>Probability</em>. Second. Vol. 95. Graduate Texts in Mathematics. New York: Springer-Verlag.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="R.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="referências.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["InfBayes.pdf", "InfBayes.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
