<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Introdução à Teoria da Decisão | Fundamentos de Inferência Bayesiana</title>
  <meta name="description" content="Notas de aula de Infência Bayesiana." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Introdução à Teoria da Decisão | Fundamentos de Inferência Bayesiana" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notas de aula de Infência Bayesiana." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Introdução à Teoria da Decisão | Fundamentos de Inferência Bayesiana" />
  
  <meta name="twitter:description" content="Notas de aula de Infência Bayesiana." />
  

<meta name="author" content="Victor Fossaluza e Luís Gustavo Esteves" />


<meta name="date" content="2021-07-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Bayes.html"/>
<link rel="next" href="Estimacao.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.4.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.57.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notas de Aula de Inferência Bayesiana</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prefácio</a></li>
<li class="chapter" data-level="2" data-path="ProbSubj.html"><a href="ProbSubj.html"><i class="fa fa-check"></i><b>2</b> Probabilidade Subjetiva</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ProbSubj.html"><a href="ProbSubj.html#definição-axiomática"><i class="fa fa-check"></i><b>2.1</b> Definição Axiomática</a></li>
<li class="chapter" data-level="2.2" data-path="ProbSubj.html"><a href="ProbSubj.html#interpretações-de-probabilidade"><i class="fa fa-check"></i><b>2.2</b> Interpretações de Probabilidade</a></li>
<li class="chapter" data-level="2.3" data-path="ProbSubj.html"><a href="ProbSubj.html#relação-de-crença-precsim"><i class="fa fa-check"></i><b>2.3</b> Relação de Crença <span class="math inline">\(\precsim\)</span></a></li>
<li class="chapter" data-level="2.4" data-path="ProbSubj.html"><a href="ProbSubj.html#medida-de-probabilidade-que-representa-precsim"><i class="fa fa-check"></i><b>2.4</b> Medida de Probabilidade que “representa” <span class="math inline">\(\precsim\)</span></a></li>
<li class="chapter" data-level="2.5" data-path="ProbSubj.html"><a href="ProbSubj.html#medida-de-probabilidade-condicional"><i class="fa fa-check"></i><b>2.5</b> Medida de Probabilidade Condicional</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Bayes.html"><a href="Bayes.html"><i class="fa fa-check"></i><b>3</b> Introdução à Inferência Bayesiana</a>
<ul>
<li class="chapter" data-level="3.1" data-path="Bayes.html"><a href="Bayes.html#BasBayes"><i class="fa fa-check"></i><b>3.1</b> Conceitos Básicos</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="Bayes.html"><a href="Bayes.html#inferência-frequentista-ou-clássica"><i class="fa fa-check"></i><b>3.1.1</b> Inferência Frequentista (ou Clássica)</a></li>
<li class="chapter" data-level="3.1.2" data-path="Bayes.html"><a href="Bayes.html#inferência-bayesiana"><i class="fa fa-check"></i><b>3.1.2</b> Inferência Bayesiana</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="Bayes.html"><a href="Bayes.html#teorema-de-de-finetti"><i class="fa fa-check"></i><b>3.2</b> Teorema de De Finetti</a></li>
<li class="chapter" data-level="3.3" data-path="Bayes.html"><a href="Bayes.html#suficiência"><i class="fa fa-check"></i><b>3.3</b> Suficiência</a></li>
<li class="chapter" data-level="3.4" data-path="Bayes.html"><a href="Bayes.html#distribuição-a-priori"><i class="fa fa-check"></i><b>3.4</b> Distribuição a Priori</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="Bayes.html"><a href="Bayes.html#método-do-histograma"><i class="fa fa-check"></i><b>3.4.1</b> Método do Histograma</a></li>
<li class="chapter" data-level="3.4.2" data-path="Bayes.html"><a href="Bayes.html#elicitação-de-hiperparâmetros"><i class="fa fa-check"></i><b>3.4.2</b> Elicitação de Hiperparâmetros</a></li>
<li class="chapter" data-level="3.4.3" data-path="Bayes.html"><a href="Bayes.html#prioris-conjugadas"><i class="fa fa-check"></i><b>3.4.3</b> Prioris Conjugadas</a></li>
<li class="chapter" data-level="3.4.4" data-path="Bayes.html"><a href="Bayes.html#prioris-não-informativas"><i class="fa fa-check"></i><b>3.4.4</b> Prioris “Não-Informativas”</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="Bayes.html"><a href="Bayes.html#alguns-princípios-de-inferência"><i class="fa fa-check"></i><b>3.5</b> Alguns Princípios de Inferência</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="TeoDec.html"><a href="TeoDec.html"><i class="fa fa-check"></i><b>4</b> Introdução à Teoria da Decisão</a>
<ul>
<li class="chapter" data-level="4.1" data-path="TeoDec.html"><a href="TeoDec.html#BasDec"><i class="fa fa-check"></i><b>4.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="4.2" data-path="TeoDec.html"><a href="TeoDec.html#Aleat"><i class="fa fa-check"></i><b>4.2</b> Aleatorização e Decisões Mistas</a></li>
<li class="chapter" data-level="4.3" data-path="TeoDec.html"><a href="TeoDec.html#DecDados"><i class="fa fa-check"></i><b>4.3</b> Problemas com Dados</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Estimacao.html"><a href="Estimacao.html"><i class="fa fa-check"></i><b>5</b> Estimação</a>
<ul>
<li class="chapter" data-level="5.1" data-path="Estimacao.html"><a href="Estimacao.html#estimação-pontual"><i class="fa fa-check"></i><b>5.1</b> Estimação Pontual</a></li>
<li class="chapter" data-level="5.2" data-path="Estimacao.html"><a href="Estimacao.html#estimação-por-regiões"><i class="fa fa-check"></i><b>5.2</b> Estimação por Regiões</a></li>
<li class="chapter" data-level="5.3" data-path="Estimacao.html"><a href="Estimacao.html#custo-das-observações"><i class="fa fa-check"></i><b>5.3</b> Custo das Observações</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Test.html"><a href="Test.html"><i class="fa fa-check"></i><b>6</b> Testes de Hipóteses</a>
<ul>
<li class="chapter" data-level="6.1" data-path="Test.html"><a href="Test.html#BasTest"><i class="fa fa-check"></i><b>6.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="6.2" data-path="Test.html"><a href="Test.html#revisão-abordagem-frequentista"><i class="fa fa-check"></i><b>6.2</b> Revisão: Abordagem Frequentista</a></li>
<li class="chapter" data-level="6.3" data-path="Test.html"><a href="Test.html#abordagem-bayesiana-via-teoria-da-decisão"><i class="fa fa-check"></i><b>6.3</b> Abordagem Bayesiana (via Teoria da Decisão)</a></li>
<li class="chapter" data-level="6.4" data-path="Test.html"><a href="Test.html#probabilidade-posterior-de-h_0"><i class="fa fa-check"></i><b>6.4</b> Probabilidade Posterior de <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="6.5" data-path="Test.html"><a href="Test.html#fator-de-bayes"><i class="fa fa-check"></i><b>6.5</b> Fator de Bayes</a></li>
<li class="chapter" data-level="6.6" data-path="Test.html"><a href="Test.html#teste-de-jeffreys"><i class="fa fa-check"></i><b>6.6</b> Teste de Jeffreys</a></li>
<li class="chapter" data-level="6.7" data-path="Test.html"><a href="Test.html#hipóteses-precisas"><i class="fa fa-check"></i><b>6.7</b> Hipóteses Precisas</a></li>
<li class="chapter" data-level="6.8" data-path="Test.html"><a href="Test.html#fbst---full-bayesian-significance-test"><i class="fa fa-check"></i><b>6.8</b> FBST - <em>Full Bayesian Significance Test</em></a></li>
<li class="chapter" data-level="6.9" data-path="Test.html"><a href="Test.html#p-value---nível-de-significância-adaptativo"><i class="fa fa-check"></i><b>6.9</b> P-value - Nível de Significância Adaptativo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Comp.html"><a href="Comp.html"><i class="fa fa-check"></i><b>7</b> Métodos Computacionais</a>
<ul>
<li class="chapter" data-level="7.1" data-path="Comp.html"><a href="Comp.html#método-de-monte-carlo"><i class="fa fa-check"></i><b>7.1</b> Método de Monte Carlo</a></li>
<li class="chapter" data-level="7.2" data-path="Comp.html"><a href="Comp.html#monte-carlo-com-amostragem-de-importância"><i class="fa fa-check"></i><b>7.2</b> Monte Carlo com Amostragem de Importância</a></li>
<li class="chapter" data-level="7.3" data-path="Comp.html"><a href="Comp.html#método-de-rejeição"><i class="fa fa-check"></i><b>7.3</b> Método de Rejeição</a></li>
<li class="chapter" data-level="7.4" data-path="Comp.html"><a href="Comp.html#abc-aproximated-bayesian-computation"><i class="fa fa-check"></i><b>7.4</b> ABC (Aproximated Bayesian Computation)</a></li>
<li class="chapter" data-level="7.5" data-path="Comp.html"><a href="Comp.html#mcmc---monte-carlo-via-cadeias-de-markov"><i class="fa fa-check"></i><b>7.5</b> MCMC - Monte Carlo via Cadeias de Markov</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="Comp.html"><a href="Comp.html#pequena-introdução-às-cadeias-de-markov"><i class="fa fa-check"></i><b>7.5.1</b> Pequena Introdução às Cadeias de Markov</a></li>
<li class="chapter" data-level="7.5.2" data-path="Comp.html"><a href="Comp.html#o-algoritmo-de-metrópolis-hastings"><i class="fa fa-check"></i><b>7.5.2</b> O algoritmo de <strong>Metrópolis-Hastings</strong></a></li>
<li class="chapter" data-level="7.5.3" data-path="Comp.html"><a href="Comp.html#amostrador-de-gibbs"><i class="fa fa-check"></i><b>7.5.3</b> Amostrador de Gibbs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="R.html"><a href="R.html"><i class="fa fa-check"></i><b>8</b> Bibliotecas de R para Inferência Bayesiana</a>
<ul>
<li class="chapter" data-level="8.1" data-path="R.html"><a href="R.html#o-modelo-de-regressão-linear"><i class="fa fa-check"></i><b>8.1</b> O Modelo de Regressão Linear</a></li>
<li class="chapter" data-level="8.2" data-path="R.html"><a href="R.html#laplaces-demon"><i class="fa fa-check"></i><b>8.2</b> Laplace’s Demon</a></li>
<li class="chapter" data-level="8.3" data-path="R.html"><a href="R.html#stan"><i class="fa fa-check"></i><b>8.3</b> Stan</a></li>
<li class="chapter" data-level="8.4" data-path="R.html"><a href="R.html#mlg"><i class="fa fa-check"></i><b>8.4</b> MLG</a></li>
<li class="chapter" data-level="8.5" data-path="R.html"><a href="R.html#modelos-dinâmicos"><i class="fa fa-check"></i><b>8.5</b> Modelos Dinâmicos</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="R.html"><a href="R.html#dados-de-amoxicilina-fonte-cea"><i class="fa fa-check"></i><b>8.5.1</b> Dados de Amoxicilina (fonte: CEA)</a></li>
<li class="chapter" data-level="8.5.2" data-path="R.html"><a href="R.html#dados-de-covid-19"><i class="fa fa-check"></i><b>8.5.2</b> Dados de Covid-19</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Apêndice</b></span></li>
<li class="chapter" data-level="A" data-path="medprob.html"><a href="medprob.html"><i class="fa fa-check"></i><b>A</b> Breve Resumo de Medida e Probabilidade</a>
<ul>
<li class="chapter" data-level="A.1" data-path="medprob.html"><a href="medprob.html#basprob"><i class="fa fa-check"></i><b>A.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="A.2" data-path="medprob.html"><a href="medprob.html#lebesgue"><i class="fa fa-check"></i><b>A.2</b> Valor Esperado de <span class="math inline">\(X\)</span> (OU uma ideia da tal Integral de Lebesgue)</a></li>
<li class="chapter" data-level="A.3" data-path="medprob.html"><a href="medprob.html#funções-de-variáveis-aleatórias"><i class="fa fa-check"></i><b>A.3</b> Funções de Variáveis Aleatórias</a></li>
<li class="chapter" data-level="A.4" data-path="medprob.html"><a href="medprob.html#função-de-distribuição"><i class="fa fa-check"></i><b>A.4</b> Função de Distribuição</a></li>
<li class="chapter" data-level="A.5" data-path="medprob.html"><a href="medprob.html#probabilidade-condicional"><i class="fa fa-check"></i><b>A.5</b> Probabilidade Condicional</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referências.html"><a href="referências.html"><i class="fa fa-check"></i>Referências</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Inferência Bayesiana</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="TeoDec" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Introdução à Teoria da Decisão</h1>
<p>A teoria da decisão é uma das possíveis formas de embasar a inferência bayesiana. Sob essa abordagem, considera-se uma <em>função de perda</em> (ou <em>função de utilidade</em>) que quantifica numericamente as consequências de sua decisão para um dado valor do parâmetro. Essa quantificação de “preferência” é novamente subjetiva e é possível fazer uma construção de função de perda similar ao que fizemos com probabilidade. Ou seja, dado um conjunto de suposições, existe uma função de perda que representa numericamente suas preferências para cada decisão e cada possível valor do parâmetro. Essa construção não será feita aqui mas pode ser encontrada no livro <em>Optimal Statistical Decisions</em> <span class="citation">(<a href="#ref-DeGroot70" role="doc-biblioref">DeGroot 1970</a>)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<div id="BasDec" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Conceitos Básicos</h2>
<ul>
<li><p><span class="math inline">\(d \in \mathcal{D}:\)</span> <strong>decisão</strong> - uma particular afirmação, por exemplo, sobre <span class="math inline">\(\theta\)</span>. No contexto inferencial, uma decisão pode ser uma estimativa (pontual ou intervalar) para <span class="math inline">\(\theta\)</span> ou a escolha de uma hipótese específica em um teste de hipóteses.</p></li>
<li><p><span class="math inline">\(\mathcal{D}:\)</span> <strong>espaço de decisões</strong> - conjunto de todas as possíveis decisões (afirmações).</p></li>
<li><p><span class="math inline">\(\theta\)</span>: <strong>estado da natureza</strong> - quantidade desconhecida ou parâmetro, no contexto de inferência estatística.</p></li>
<li><p><span class="math inline">\(\Theta\)</span>: <strong>espaço dos estados da natureza</strong> - espaço paramétrico.</p></li>
<li><p><span class="math inline">\(L:\mathcal{D}\times\Theta\longrightarrow\mathbb{R}\)</span>: <strong>função de perda</strong> - <span class="math inline">\(L(d,\theta)\)</span> que representa o prejuízo de uma decisão <span class="math inline">\(d\)</span> quando o estado da natureza é <span class="math inline">\(\theta\)</span>.</p></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.</strong> <!-- (*Making Decisions*, Lindley,D.V.)   -->
Suponha que você está saindo de casa pela manhã e precisa tomar uma importante decisão: levar ou não seu guarda-chuva.</p>
<ul>
<li><p><span class="math inline">\(\mathcal{D}=\{G,G^c\}\)</span> , onde <span class="math inline">\(G:\)</span> levar guarda-chuva.</p></li>
<li><p><span class="math inline">\(\Theta=\{C,C^c\}\)</span> , onde <span class="math inline">\(C:\)</span> chuva.</p></li>
</ul>
<p>Suponha que carregar o guarda-chuva é algo que não lhe agrada mas, por outro lado, você odeia ficar molhado e acredita que a pior situação seria não levá-lo e tomar chuva. Você ficará incomodado se levar o guarda-chuva e chover pois, além de tê-lo carregado, voltou para casa com os sapatos molhados. Note que, nessas circunstâncias, o cenário preferido por você seria não levar o guarda-chuva e não chover.</p>
<p>Para quantificar suas preferências, considere uma função de perda <span class="math inline">\(L:\mathcal{D}\times\Theta\longrightarrow\mathbb{R}\)</span>, de modo que, quanto mais algum cenário lhe gera incômodo, maior sua perda. Um exemplo é apresentado a seguir.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Estados da Natureza</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Decisão</strong></td>
<td><span class="math inline">\(C\)</span></td>
<td><span class="math inline">\(C^c\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(G\)</span></td>
<td>2 (ruim)</td>
<td>1 (bom)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(G^c\)</span></td>
<td>3 (pior)</td>
<td>0 (melhor)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(P(\theta)\)</span></td>
<td>p</td>
<td>1-p</td>
</tr>
</tbody>
</table>
<p>Uma possível maneira de tomar uma decisão é escolher a decisão “menos prejudicial.” Se levar o Guarda chuva, no pior caso, sua perda é <span class="math inline">\(\displaystyle \max_\theta L(G,\theta)=2\)</span> e, se não levá-lo, a maior perda possível é <span class="math inline">\(\displaystyle \max_\theta L(G^c,\theta)=3\)</span>. Assim, a decisão que tem a menor dentre as maiores perdas é levar o guarda-chuva. Esse procedimento para tomada de decisões é chamado <em>min-max</em> e consiste em escolher a decisão <span class="math inline">\(d&#39;\)</span> tal que <span class="math inline">\(d&#39; = \displaystyle \underset{d}{\text{argmin}} \max_\theta L(d,\theta)\)</span>.</p>
<p>Sendo um pouco mais otimista, você pode escolher a decisão que tenha a maior dentre as menores perdas. Esse procedimento é chamado <em>max-min</em> e consiste em escolher a decisão <span class="math inline">\(d&#39; = \displaystyle \underset{d}{\text{argmax}} \min_\theta L(d,\theta)\)</span>. No nosso exemplo, esse procedimento também sugere que você sempre carregue o guarda-chuvas.</p>
<p>Note que a decisão escolhida pelos dois procedimentos descritos anteriormente sugere que você sempre deve carregar o guarda-chuvas. Contudo, isso pode não ser razoável. Imagine que você estava lendo notícias antes de sair de casa e viu que a probabilidade de chuva era <span class="math inline">\(0.01\)</span>. Nesse caso, não parece fazer sentido você levar o guarda-chuva, já que isso vai te trazer um desconforto e a chance de chover é muito baixa. Assim, a probabilidade de chover deveria ser levada em consideração em sua tomada de decisão.</p>
<p>Uma maneira de fazer isso é utilizar a <strong>perda esperada</strong>. Note que <span class="math inline">\(\theta\)</span> é uma quantidade desconhecida e, pelo que já foi discutido anteriormente, você deve descrever sua incerteza em relação a essa quantidade em termos de probabilidade. Suponha que no exemplo <span class="math inline">\(P(C)=p\)</span>, <span class="math inline">\(0\leq p\leq 1\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Para cada decisão <span class="math inline">\(d \in \mathcal{D}\)</span>, é possível calcular o valor esperado da função de perda (<strong>perda esperada</strong> ou <strong>risco</strong> da decisão <span class="math inline">\(d\)</span> contra a priori <span class="math inline">\(P\)</span>)
<span class="math display">\[\rho(d,P) = E\left[L(d,\theta) ~|~ P\right] = \int_{\Theta} L(\theta) dP(\theta).\]</span>
<span class="math inline">\(~\)</span></p>
<p>No exemplo, temos</p>
<ul>
<li><p><span class="math inline">\(E\left[L(G^{},\theta)\right]\)</span> <span class="math inline">\(=L(G,C)P(C) + L(G,C^c)P(C^c)\)</span> <span class="math inline">\(=2p+1(1-p)\)</span> <span class="math inline">\(=p+1\)</span>;</p></li>
<li><p><span class="math inline">\(E\left[L(G^c,\theta)\right]\)</span> <span class="math inline">\(=L(G^c,C)P(C) + L(G^c,C^c)P(C^c)\)</span> <span class="math inline">\(=3p+0(1-p)\)</span> <span class="math inline">\(=3p\)</span>.</p></li>
</ul>
<p>Deste modo, as perdas esperadas associadas a cada decisão dependem da probabilidade de chuva <span class="math inline">\(p\)</span>. Assim, para cada possível valor de <span class="math inline">\(p\)</span>, deve-se tomar a decisão que tem menor perda esperada. Por exemplo, se a probabilidade de chuva é <span class="math inline">\(p=0.1\)</span>, temos que as perdas esperadas para as decisões de levar ou não o guarda-chuva são, respectivamente, <span class="math inline">\(E\left[L(G,\theta)\right]=1.1\)</span> e <span class="math inline">\(E\left[L(G^c,\theta)\right]=0.3\)</span>. Assim, sob essa abordagem, sua decisão seria de não levar o guarda-chuva nesse caso. Por outro lado, se a probabilidade de chuva for <span class="math inline">\(p=0.9\)</span>, suas perdas esperadas seriam respectivamente <span class="math inline">\(E\left[L(G,\theta)\right]=1.9\)</span> e <span class="math inline">\(E\left[L(G^c,\theta)\right]=2.7\)</span>, de modo que a decisão ótima seria levar o guarda-chuva. O gráfico a seguir apresenta as perdas para cada decisão <span class="math inline">\(d\)</span> e para cada valor de <span class="math inline">\(p\)</span>. É possível notar que a decisão ótima é levar o guarda-chuva quando <span class="math inline">\(p&gt;0.5\)</span> e não levá-lo caso contrário.</p>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-18-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p>Vamos denotar por <span class="math inline">\(\rho^*\)</span> o <strong>risco de bayes</strong>, isto é, a perda esperada da <strong>decisão de Bayes</strong> (ou <em>decisão ótima</em>) <span class="math inline">\(d^*\in \mathcal{D}\)</span> tal que <span class="math inline">\(\rho^*(P)\)</span> <span class="math inline">\(=\rho(d^*,P)\)</span> <span class="math inline">\(=\underset{d\in\mathcal{D}}{min}~\rho(d,P)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Para uma argumentação mais formal sobre a escolha pela decisão que minimiza a perda esperada, ver <em>Optimal Statistical Decisions</em> (DeGroot, M.H.).</p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<ul>
<li>Vamos denotar um problema de decisão por <span class="math inline">\(\left(\Theta, \mathcal{D}, L, P\right)\)</span>, onde <span class="math inline">\(\Theta\)</span> é o espaço paramétrico, <span class="math inline">\(\mathcal{D}\)</span> é o espaço de decisões, <span class="math inline">\(L: \mathcal{D} \times \Theta \longrightarrow \mathbb{R}\)</span> é uma função de perda e <span class="math inline">\(P\)</span> é a distribuição de probabilidade que representa sua crença sobre a quantidade desconhecida <span class="math inline">\(\theta\)</span>. Equivalentemente, a função de perda <span class="math inline">\(L\)</span> pode ser substituída por uma <em>função de utilidade</em> <span class="math inline">\(U\)</span> (por exemplo, tome <span class="math inline">\(U=-L\)</span>).</li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<ul>
<li>A solução para um problema de decisão <span class="math inline">\(\left(\Theta, \mathcal{D}, L, P\right)\)</span> é a <em>decisão de Bayes</em>, <span class="math inline">\({d}^* \in \mathcal{D}\)</span>, tal que <span class="math inline">\(\rho^*(P) = \rho({d}^*,P) = \displaystyle \inf_{d \in \mathcal{D}} \rho(d,\theta)\)</span>, com <span class="math inline">\(\rho(d,P) = \displaystyle \int_\Theta L(d,\theta)dP(\theta)\)</span>.</li>
</ul>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="Aleat" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Aleatorização e Decisões Mistas</h2>
<p>Seja <span class="math inline">\(D=\left\{d_1,d_2,\ldots\right\}\)</span> um espaço de decisões e considere <span class="math inline">\(\mathcal{M}\)</span> o conjunto de todas as <em>decisões mistas</em> (ou <em>aleatorizadas</em>), isto é, para toda distribuição de probabilidades <span class="math inline">\(Q=\left\{q_1,q_2,\ldots\right\}\)</span>, uma decisão <span class="math inline">\(d\in\mathcal{M}\)</span> se <span class="math inline">\(d\)</span> consiste em escolher a decisão <span class="math inline">\(d_i\)</span> com probabilidade <span class="math inline">\(q_i\)</span>.</p>
<p>Assim, a perda associada à uma decisão <span class="math inline">\(d\in\mathcal{M}\)</span> é <span class="math inline">\(L(d,\theta) = \sum q_i L(d_i,\theta)\)</span> e o risco dessa decisão é</p>
<p><span class="math inline">\(\rho(d,P)\)</span> <span class="math inline">\(= \displaystyle \int_\Theta L(d,\theta) dP(\theta)\)</span> <span class="math inline">\(=\displaystyle \int_\Theta \sum q_i L(d_i,\theta) dP(\theta)\)</span> <span class="math inline">\(=\displaystyle \sum q_i \int_\Theta L(d_i,\theta) dP(\theta)\)</span> <span class="math inline">\(=\displaystyle \sum q_i~ \rho(d_i,\theta)\)</span>.</p>
<p>Considere a decisão <span class="math inline">\({d}^* \in \mathcal{D}\)</span> tal que <span class="math inline">\(\rho({d}^*,P) = \displaystyle \inf_{d \in \mathcal{D}} \rho(d,\theta)\)</span>.</p>
<p>Então, <span class="math inline">\(\forall ~d \in \mathcal{M}\)</span>,</p>
<p><span class="math inline">\(\rho(d,P)\)</span> <span class="math inline">\(=\displaystyle \sum q_i~ \rho(d_i,\theta)\)</span> <span class="math inline">\(\geq \displaystyle \sum q_i~ \rho({d}^*,\theta)\)</span>.</p>
<ul>
<li>Em palavras, para toda decisão aleatorizada <span class="math inline">\(d\in\mathcal{M}\)</span>, existe uma decisão não aleatorizada <span class="math inline">\({d}^*\in\mathcal{D} \subset\mathcal{M}\)</span>, tal que <span class="math inline">\(\rho({d}^*,P) \leq \rho(d,P)\)</span>.</li>
</ul>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="DecDados" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Problemas com Dados</h2>
<p>Suponha que antes de escolher uma decisão <span class="math inline">\(d \in \mathcal{D}\)</span>, é possível observar um v.a. <span class="math inline">\(\boldsymbol X\)</span> que (supostamente) está relacionado com <span class="math inline">\(\theta\)</span> (isto é, <span class="math inline">\(\boldsymbol X\)</span> traz alguma informação sobre <span class="math inline">\(\theta\)</span>).</p>
<p>Desde modo, considere a família <span class="math inline">\(\mathcal{P}=\left\{ f(\cdot|\theta) : \theta \in \Theta\right\}\)</span> de funções de distribuição condicionais para <span class="math inline">\(\boldsymbol X\)</span>, isto é, para cada <span class="math inline">\(\theta \in \Theta\)</span> é possível determinar a distribuição condicional de <span class="math inline">\(\boldsymbol X|\theta\)</span>. Essa distribuição, juntamente com a distribuição a priori <span class="math inline">\(f(\theta)\)</span>, determina totalmente uma distribuição conjunta <span class="math inline">\(f(\boldsymbol x,\theta) = f(\boldsymbol x|\theta) f(\theta)\)</span>.</p>
<p>Pode-se definir uma <strong>função de decisão</strong> <span class="math inline">\(\delta: \mathfrak{X} \longrightarrow \mathcal{D}\)</span> que associa a cada resultado experimental <span class="math inline">\(\boldsymbol x \in \mathfrak{X}\)</span> uma decisão <span class="math inline">\(d \in \mathcal{D}\)</span>. Denote o conjunto de todas as possíveis funções de decisão por <span class="math inline">\(\Delta\)</span>.</p>
<p>O risco <span class="math inline">\(r(\delta,P)\)</span> da função de decisão <span class="math inline">\(\delta \in \Delta\)</span> é dado por <span class="math inline">\(r(\delta,P)\)</span> <span class="math inline">\(=E\left[L\left(\delta,\theta\right)\right]\)</span> <span class="math inline">\(=\displaystyle \int_\Theta \int_{\mathfrak{X}} L\left(\delta(\boldsymbol x),\theta\right) dP(\boldsymbol x,\theta)\)</span>.</p>
<p>A <em>função de decisão de Bayes</em>, <span class="math inline">\({\delta}^* \in \Delta\)</span>, é tal que <span class="math inline">\({\rho}^*(P)\)</span> <span class="math inline">\(=\rho({\delta}^*,P)\)</span> <span class="math inline">\(=\displaystyle \inf_{\delta\in \Delta} \rho(\delta,P)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.</strong> Seja <span class="math inline">\(\Theta=\{\theta_1,\theta_2\}\)</span>, <span class="math inline">\(\mathcal{D}=\{d_1,d_2\}\)</span>, <span class="math inline">\(X|\theta_1\sim Ber(3/4)\)</span>, <span class="math inline">\(X|\theta_2 \sim Ber(1/3)\)</span>, <span class="math inline">\(\mathfrak{X}=\{0,1\}\)</span> e, a priori, <span class="math inline">\(P(\theta=3/4)=P(\theta=1/3)=1/2\)</span>. Considere a função de perda a seguir.</p>
<table>
<thead>
<tr class="header">
<th>L</th>
<th><span class="math inline">\(\theta_1\)</span></th>
<th><span class="math inline">\(\theta_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(d_1\)</span></td>
<td>0</td>
<td>5</td>
</tr>
<tr class="even">
<td><span class="math inline">\(d_2\)</span></td>
<td>10</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Temos que <span class="math inline">\(|\Delta| = 2^2=4\)</span>, de modo que as possíveis funções de decisão são</p>
<p><span class="math inline">\(\delta_1(x)=\left\{\begin{array}{lr} d_1, &amp; x=1\\ d_2, &amp;x=0\end{array}\right.\)</span></p>
<p><span class="math inline">\(\delta_2(x)=\left\{\begin{array}{lr} d_1, &amp; x=0\\ d_2, &amp;x=1\end{array}\right.\)</span></p>
<p><span class="math inline">\(\delta_3(x)=d_1\)</span> e <span class="math inline">\(\delta_4(x)=d_2\)</span>.</p>
<p>Para a função <span class="math inline">\(\delta_1\)</span>, temos</p>
<table>
<thead>
<tr class="header">
<th>x</th>
<th><span class="math inline">\(\theta\)</span></th>
<th><span class="math inline">\(L(\delta_1(x),\theta)\)</span></th>
<th><span class="math inline">\(P(x|\theta)\)</span></th>
<th><span class="math inline">\(P(\theta)\)</span></th>
<th><span class="math inline">\(P(x,\theta)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td><span class="math inline">\(\theta_1\)</span></td>
<td>10</td>
<td>1/4</td>
<td>1/2</td>
<td>1/8</td>
</tr>
<tr class="even">
<td>0</td>
<td><span class="math inline">\(\theta_2\)</span></td>
<td>0</td>
<td>2/3</td>
<td>1/2</td>
<td>2/6</td>
</tr>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(\theta_1\)</span></td>
<td>0</td>
<td>3/4</td>
<td>1/2</td>
<td>3/8</td>
</tr>
<tr class="even">
<td>1</td>
<td><span class="math inline">\(\theta_2\)</span></td>
<td>5</td>
<td>1/3</td>
<td>1/2</td>
<td>1/6</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(\rho(\delta_1)\)</span> <span class="math inline">\(=\displaystyle \sum_{x=0}^1\sum_{i=1}^2L(\delta_1(x),\theta_i)\underbrace{P(X=x|\theta_i)P(\theta_i)}_{P(x,\theta)}\)</span> <span class="math inline">\(=10~\dfrac{1}{8}+5~\dfrac{1}{6}\)</span> <span class="math inline">\(=\dfrac{50}{24}\)</span></p>
<p>De forma análoga, <span class="math inline">\(~\rho(\delta_2,P)=130/24\)</span> , <span class="math inline">\(~\rho(\delta_3,P)=60/24\)</span> , <span class="math inline">\(~\rho(\delta_4,P)=120/24\)</span> , e, assim.</p>
<p><span class="math inline">\({\delta}^*(x)={\delta}^*_1(x)=\left\{\begin{array}{rl} d_1, &amp; x=1\\ d_2, &amp; x=0\end{array}\right.\)</span></p>
<p><strong>Risco de Bayes:</strong> <span class="math inline">\(\rho^*(P)=\rho({\delta}^*,P)=50/24\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Em problemas mais complicados, pode ser muito trabalhoso (ou impossível) obter a função de decisão dessa forma, chamada <em>forma normal</em>. Sob essa abordagem, é necessário encontrar a função de decisão de bayes <span class="math inline">\({\delta}^*\)</span> dentre todas as possíveis funções de decisão. Nesses casos, pode ser mais fácil resolver o problema usando a <em>forma extensiva</em> em que, para cada <span class="math inline">\(\boldsymbol x \in \mathfrak{X}\)</span>, obtem-se a decisão de Bayes <span class="math inline">\({d}_{x}^*\)</span> que minimiza o <em>risco posterior</em>, definido por <span class="math inline">\(r_x(d)\)</span> <span class="math inline">\(= \displaystyle \int_\Theta L(d,\theta) dP(\theta|\boldsymbol x)\)</span>.</p>
<p>Assim, é posível obter uma decisão de Bayes <span class="math inline">\({d}_x^*\)</span> para um específico ponto <span class="math inline">\(x\)</span> observado ou, ainda, construir uma função de decisão de Bayes, fazendo <span class="math inline">\(~{\delta}^*(\boldsymbol x) = {d}_x^*~\)</span> para cada <span class="math inline">\(\boldsymbol x \in \mathfrak{X}\)</span>. A seguir, é mostrado que essa duas formas produzem resultados que minimizam o risco. Note que</p>
<p><span class="math inline">\(r(\delta,P)\)</span> <span class="math inline">\(=E\left[L\left(\delta,\theta\right)\right]\)</span> <span class="math inline">\(=\displaystyle \int_\Theta \int_{\mathfrak{X}} L\left(\delta(\boldsymbol x),\theta\right) dP(\boldsymbol x,\theta)\)</span> <span class="math inline">\(=\displaystyle \int_\Theta \int_{\mathfrak{X}} L\left(\delta(\boldsymbol x),\theta\right) dP(\boldsymbol x|\theta)dP(\theta)\)</span> <span class="math inline">\(=\displaystyle \int_{\mathfrak{X}} \left[ \underbrace{\int_\Theta L\left(\delta(\boldsymbol x),\theta\right) dP(\theta|\boldsymbol x)}_{r_x\left(\delta(\boldsymbol x)\right)} \right]dP(\boldsymbol x)\)</span>.</p>
<p>Note que a integral interna (em <span class="math inline">\(\theta\)</span>) pode ser resolvida para cada <span class="math inline">\(\boldsymbol x\)</span> fixado. Para cada <span class="math inline">\(\boldsymbol x\)</span>, considere a decisão <span class="math inline">\({d}_x^*\)</span> tal que <span class="math inline">\(r_x\left({d}_x^*\right)\)</span> <span class="math inline">\(=\displaystyle \inf_{d \in \mathcal{D}} r_x(d)\)</span>. Assim</p>
<p><span class="math inline">\(r(\delta,P)\)</span> <span class="math inline">\(=\displaystyle \int_{\mathfrak{X}} \left[ \underbrace{\int_\Theta L\left(\delta(\boldsymbol x),\theta\right) dP(\theta|\boldsymbol x)}_{r_x\left(\delta(\boldsymbol x)\right)} \right]dP(\boldsymbol x)\)</span> <span class="math inline">\(=\displaystyle \int_{\mathfrak{X}} \left[ {r_x\left(\delta(\boldsymbol x)\right)} \right]dP(\boldsymbol x)\)</span> <span class="math inline">\(\geq \displaystyle \int_{\mathfrak{X}} \left[ {r_x\left({d}_x^*\right)} \right]dP(\boldsymbol x)\)</span> <span class="math inline">\(= \displaystyle \int_{\mathfrak{X}} \left[ {r_x\left({d}_x^*\right)} \right]dP(\boldsymbol x)\)</span>.</p>
<p>Assim, a função <span class="math inline">\({\delta}^*(x)={d}^*_{x}\)</span> é uma <em>função de decisão de Bayes</em>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>No Exemplo 1</strong> <span class="math inline">\(~X|\theta_1 \sim Ber(3/4)\)</span> , <span class="math inline">\(~X|\theta_2 \sim Ber(1/3)\)</span> e <span class="math inline">\(~P(\theta_1)=P(\theta_2)=1/2\)</span>.</p>
<p><span class="math inline">\(P(\theta_1|x=0)\)</span> <span class="math inline">\(=\dfrac{P(X=0|\theta_1)P(\theta_1)}{P(X=0|\theta_1)P(\theta_1)+P(X=0|\theta_2)P(\theta_2)}\)</span> <span class="math inline">\(=\dfrac{\frac{1}{4}~\frac{1}{2}}{\frac{1}{4}~\frac{1}{2}+\frac{2}{3}~\frac{1}{2}}\)</span> <span class="math inline">\(=\dfrac{3}{11}\)</span></p>
<p><span class="math inline">\(P(\theta_2|X=0)\)</span> <span class="math inline">\(=\dfrac{8}{11}\)</span></p>
<p><span class="math inline">\(r_x(d_1,P)\)</span> <span class="math inline">\(=\displaystyle \sum_{i=1}^2L(d_1,\theta_i)P(\theta_i|X=0)\)</span> <span class="math inline">\(=0~P(\theta_1|X=0)+10~P(\theta_2|X=0)\)</span> <span class="math inline">\(=\dfrac{80}{11}\)</span></p>
<p><span class="math inline">\(r_x(d_2,P)\)</span> <span class="math inline">\(=5~P(\theta_1|X=0)+0~P(\theta_2|X=0)\)</span> <span class="math inline">\(=\dfrac{15}{11}\)</span></p>
<p>Logo, para <span class="math inline">\(x=0\)</span>, <span class="math inline">\({d}_0^*={d}_2\)</span>. De forma análoga, para <span class="math inline">\(x=1\)</span>, <span class="math inline">\({d}_1^*={d}_2\)</span> e, assim,</p>
<p><span class="math inline">\({\delta}^*(x)=\left\{\begin{array}{rl} {d}_2, &amp; x=0\\ {d}_1, &amp; x=1~.\end{array}\right.\)</span></p>
<p><span class="math inline">\(~\)</span></p>

</div>
</div>
<h3>Referências</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-DeGroot70" class="csl-entry">
DeGroot, M. H. 1970. <em>Optimal Statistical Decisions</em>. New York: MacGraw-Hill.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Bayes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Estimacao.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["InfBayes.pdf", "InfBayes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
