<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Estimação | Fundamentos de Inferência Bayesiana</title>
  <meta name="description" content="Notas de aula de Infência Bayesiana." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Estimação | Fundamentos de Inferência Bayesiana" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notas de aula de Infência Bayesiana." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Estimação | Fundamentos de Inferência Bayesiana" />
  
  <meta name="twitter:description" content="Notas de aula de Infência Bayesiana." />
  

<meta name="author" content="Victor Fossaluza e Luís Gustavo Esteves" />


<meta name="date" content="2020-08-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="TeoDec.html"/>
<link rel="next" href="Test.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notas de Aula de Inferência Bayesiana</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefácio</a></li>
<li class="chapter" data-level="1" data-path="ProbSubj.html"><a href="ProbSubj.html"><i class="fa fa-check"></i><b>1</b> Probabilidade Subjetiva</a><ul>
<li class="chapter" data-level="1.1" data-path="ProbSubj.html"><a href="ProbSubj.html#definição-axiomática"><i class="fa fa-check"></i><b>1.1</b> Definição Axiomática</a></li>
<li class="chapter" data-level="1.2" data-path="ProbSubj.html"><a href="ProbSubj.html#interpretações-de-probabilidade"><i class="fa fa-check"></i><b>1.2</b> Interpretações de Probabilidade</a></li>
<li class="chapter" data-level="1.3" data-path="ProbSubj.html"><a href="ProbSubj.html#relação-de-crença-precsim"><i class="fa fa-check"></i><b>1.3</b> Relação de Crença <span class="math inline">\(\precsim\)</span></a></li>
<li class="chapter" data-level="1.4" data-path="ProbSubj.html"><a href="ProbSubj.html#medida-de-probabilidade-que-representa-precsim"><i class="fa fa-check"></i><b>1.4</b> Medida de Probabilidade que “representa” <span class="math inline">\(\precsim\)</span></a></li>
<li class="chapter" data-level="1.5" data-path="ProbSubj.html"><a href="ProbSubj.html#medida-de-probabilidade-condicional"><i class="fa fa-check"></i><b>1.5</b> Medida de Probabilidade Condicional</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Bayes.html"><a href="Bayes.html"><i class="fa fa-check"></i><b>2</b> Introdução à Inferência Bayesiana</a><ul>
<li class="chapter" data-level="2.1" data-path="Bayes.html"><a href="Bayes.html#BasBayes"><i class="fa fa-check"></i><b>2.1</b> Conceitos Básicos</a><ul>
<li class="chapter" data-level="2.1.1" data-path="Bayes.html"><a href="Bayes.html#inferência-frequentista-ou-clássica"><i class="fa fa-check"></i><b>2.1.1</b> Inferência Frequentista (ou Clássica)</a></li>
<li class="chapter" data-level="2.1.2" data-path="Bayes.html"><a href="Bayes.html#inferência-bayesiana"><i class="fa fa-check"></i><b>2.1.2</b> Inferência Bayesiana</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="Bayes.html"><a href="Bayes.html#suficiência"><i class="fa fa-check"></i><b>2.2</b> Suficiência</a></li>
<li class="chapter" data-level="2.3" data-path="Bayes.html"><a href="Bayes.html#distribuição-a-priori"><i class="fa fa-check"></i><b>2.3</b> Distribuição a Priori</a><ul>
<li class="chapter" data-level="2.3.1" data-path="Bayes.html"><a href="Bayes.html#método-do-histograma"><i class="fa fa-check"></i><b>2.3.1</b> Método do Histograma</a></li>
<li class="chapter" data-level="2.3.2" data-path="Bayes.html"><a href="Bayes.html#elicitação-de-hiperparâmetros"><i class="fa fa-check"></i><b>2.3.2</b> Elicitação de Hiperparâmetros</a></li>
<li class="chapter" data-level="2.3.3" data-path="Bayes.html"><a href="Bayes.html#prioris-conjugadas"><i class="fa fa-check"></i><b>2.3.3</b> Prioris Conjugadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="TeoDec.html"><a href="TeoDec.html"><i class="fa fa-check"></i><b>3</b> Introdução à Teoría da Decisão</a><ul>
<li class="chapter" data-level="3.1" data-path="TeoDec.html"><a href="TeoDec.html#BasDec"><i class="fa fa-check"></i><b>3.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="3.2" data-path="TeoDec.html"><a href="TeoDec.html#aleatorização-e-decisões-mistas"><i class="fa fa-check"></i><b>3.2</b> Aleatorização e Decisões Mistas</a></li>
<li class="chapter" data-level="3.3" data-path="TeoDec.html"><a href="TeoDec.html#problemas-com-dados"><i class="fa fa-check"></i><b>3.3</b> Problemas com Dados</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Estimacao.html"><a href="Estimacao.html"><i class="fa fa-check"></i><b>4</b> Estimação</a><ul>
<li class="chapter" data-level="4.1" data-path="Estimacao.html"><a href="Estimacao.html#estimação-pontual"><i class="fa fa-check"></i><b>4.1</b> Estimação Pontual</a></li>
<li class="chapter" data-level="4.2" data-path="Estimacao.html"><a href="Estimacao.html#estimação-por-regiões"><i class="fa fa-check"></i><b>4.2</b> Estimação por Regiões</a></li>
<li class="chapter" data-level="4.3" data-path="Estimacao.html"><a href="Estimacao.html#custo-das-observações"><i class="fa fa-check"></i><b>4.3</b> Custo das Observações</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Test.html"><a href="Test.html"><i class="fa fa-check"></i><b>5</b> Testes de Hipóteses</a><ul>
<li class="chapter" data-level="5.1" data-path="Test.html"><a href="Test.html#BasTest"><i class="fa fa-check"></i><b>5.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="5.2" data-path="Test.html"><a href="Test.html#revisão-abordagem-frequentista"><i class="fa fa-check"></i><b>5.2</b> Revisão: Abordagem Frequentista</a></li>
<li class="chapter" data-level="5.3" data-path="Test.html"><a href="Test.html#abordagem-bayesiana-via-teoria-da-decisão"><i class="fa fa-check"></i><b>5.3</b> Abordagem Bayesiana (via Teoria da Decisão)</a></li>
<li class="chapter" data-level="5.4" data-path="Test.html"><a href="Test.html#probabilidade-posterior-de-h_0"><i class="fa fa-check"></i><b>5.4</b> Probabilidade Posterior de <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="5.5" data-path="Test.html"><a href="Test.html#fator-de-bayes"><i class="fa fa-check"></i><b>5.5</b> Fator de Bayes</a></li>
<li class="chapter" data-level="5.6" data-path="Test.html"><a href="Test.html#teste-de-jeffreys"><i class="fa fa-check"></i><b>5.6</b> Teste de Jeffreys</a></li>
<li class="chapter" data-level="5.7" data-path="Test.html"><a href="Test.html#hipóteses-precisas"><i class="fa fa-check"></i><b>5.7</b> Hipóteses Precisas</a></li>
<li class="chapter" data-level="5.8" data-path="Test.html"><a href="Test.html#fbst---full-bayesian-significance-test"><i class="fa fa-check"></i><b>5.8</b> FBST - <em>Full Bayesian Significance Test</em></a></li>
<li class="chapter" data-level="5.9" data-path="Test.html"><a href="Test.html#p-value---nivel-de-significância-adaptativo"><i class="fa fa-check"></i><b>5.9</b> P-value - Nivel de Significância Adaptativo</a></li>
</ul></li>
<li class="appendix"><span><b>Apêndice</b></span></li>
<li class="chapter" data-level="A" data-path="medprob.html"><a href="medprob.html"><i class="fa fa-check"></i><b>A</b> Breve Resumo de Medida e Probabilidade</a><ul>
<li class="chapter" data-level="A.1" data-path="medprob.html"><a href="medprob.html#basprob"><i class="fa fa-check"></i><b>A.1</b> Conceitos Básicos</a></li>
<li class="chapter" data-level="A.2" data-path="medprob.html"><a href="medprob.html#lebesgue"><i class="fa fa-check"></i><b>A.2</b> Valor Esperado de <span class="math inline">\(X\)</span> (OU uma ideia da tal Integral de Lebesgue)</a></li>
<li class="chapter" data-level="A.3" data-path="medprob.html"><a href="medprob.html#funções-de-variáveis-aleatórias"><i class="fa fa-check"></i><b>A.3</b> Funções de Variáveis Aleatórias</a></li>
<li class="chapter" data-level="A.4" data-path="medprob.html"><a href="medprob.html#função-de-distribuição"><i class="fa fa-check"></i><b>A.4</b> Função de Distribuição</a></li>
<li class="chapter" data-level="A.5" data-path="medprob.html"><a href="medprob.html#probabilidade-condicional"><i class="fa fa-check"></i><b>A.5</b> Probabilidade Condicional</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referências.html"><a href="referências.html"><i class="fa fa-check"></i>Referências</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Inferência Bayesiana</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Estimacao" class="section level1">
<h1><span class="header-section-number">4</span> Estimação</h1>
<div id="estimação-pontual" class="section level2">
<h2><span class="header-section-number">4.1</span> Estimação Pontual</h2>
<p>Todos os problemas de inferência estatística podem ser vistos como um caso particular de Teoria da Decisão. Um problema de estimação pontual consiste em encontrar um “chute” para o valor do parâmetro <span class="math inline">\(\theta\)</span>, de modo que o espaço de decisões é <span class="math inline">\(\mathcal{D}=\Theta\)</span>. Além disso, nesse tipo de problema é usual considerar funções de perda da forma <span class="math inline">\(L(d,\theta)=s(\theta)\Delta(d,\theta)\)</span>, onde <span class="math inline">\(\Delta\)</span> é alguma distância (ou uma medida de discrepância) relacionada ao erro por tomar a decisão <span class="math inline">\(d\)</span> quando o valor do parâmetro é <span class="math inline">\(\theta\)</span> e <span class="math inline">\(s\)</span> é uma função não-negativa relacionada à gravidade do erro para cada <span class="math inline">\(\theta\)</span> (pode ser constante).</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo</strong> Considere um problema de estimação pontual, isto é, <span class="math inline">\(\mathcal{D}=\Theta\)</span>, onde a função de perda é dada por <span class="math inline">\(L(d,\theta)=(d-\theta)^2\)</span>, conhecida como <em>perda quadrática</em>.</p>
<!-- IMAGEM DA PERDA -->
<p><span class="math inline">\(r_x(d)\)</span> <span class="math inline">\(=\displaystyle \int_\Theta(d-\theta)^2~dP(\theta|x)\)</span>
<span class="math inline">\(=\displaystyle \int_\Theta \left(d^2 - 2d\theta + \theta^2\right) dP(\theta|x)\)</span> <span class="math inline">\(=d^2\displaystyle\int_\Theta dP(\theta|x) - 2d\int_\Theta\theta ~dP(\theta|x) + \int_\Theta \theta^2 ~dP(\theta|x)\)</span> <span class="math inline">\(=d^2-2d~E[\theta|x]+E[\theta^2|x]=g(d)\)</span>.</p>
<p><span class="math inline">\(\dfrac{\partial g(d)}{\partial d}\)</span> <span class="math inline">\(=2d-2E[\theta|x]=0\)</span> <span class="math inline">\(\Rightarrow {d}_x^*=E[\theta|x]\)</span>.</p>
<p>Logo, um estimador para <span class="math inline">\(\theta\)</span> contra a perda quadrática é <span class="math inline">\({\delta}^*(X)=E[\theta|X]\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<ul>
<li><p>Estimador de Bayes para <span class="math inline">\(\theta\)</span> contra diferentes funções de perda:</p>
<ol style="list-style-type: decimal">
<li><p>Perda Quadrática: <span class="math inline">\(L_2(d,\theta)=(d-\theta)^2\)</span> <span class="math inline">\(~\Longrightarrow~\)</span> <span class="math inline">\({\delta}_2^*(X)=E[\theta|X]\)</span>;</p></li>
<li><p>Perda Absoluta: <span class="math inline">\(L_1(d,\theta)=|d-\theta|\)</span> <span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\({\delta}_1^*(X)=Med(\theta|X)\)</span>;</p></li>
<li><p>Perda 0-1: <span class="math inline">\(L_0(d,\theta)=c~\mathbb{I}(d\neq\theta)\)</span> <span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\({\delta}_0^*(X)=Moda(\theta|X)\)</span>.</p></li>
</ol></li>
</ul>
<p><span class="math inline">\(~\)</span></p>
<!-- **Exercício** Mostrar que -->
<!-- a) $L(d,\theta)=\underbrace{|d-\theta|}_{\text{perda absoluta}}\Rightarrow$ ${\delta}^*(X)=Med(\theta|X)$ -->
<!-- b) $L(d,\theta)=\underbrace{c\mathbb{I}(d\neq\theta)}_{\text{perda 0-1}}\Rightarrow$ ${\delta}^*(X)=Moda(\theta|X)$ -->
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.</strong> Voltando à <em>Perda Quadrática:</em> <span class="math inline">\(L(d,\theta)=a(d-\theta)^2\)</span>, <span class="math inline">\(a&gt;0\)</span>.</p>
<p>Já vimos que <span class="math inline">\(\delta^*(\boldsymbol X)=E[\theta|\boldsymbol X]\)</span>. É importante notar que esse estimador só faz sentido se <span class="math inline">\(E[\theta|\boldsymbol X]\in \mathcal{D}\)</span>. Nos casos em que isso não ocorre, tomamos um valor <span class="math inline">\({d}_x^* \in \mathcal{D}\)</span> próximo a <span class="math inline">\(E[\theta|\boldsymbol X]\)</span> tal que <span class="math inline">\(r_x\left({d}_x^*\right)\)</span> é mínimo.</p>
<p><span class="math inline">\(~\)</span></p>
<p>O risco a posteriori para esse estimador é</p>
<p><span class="math inline">\(r_x\left(\delta^*(\boldsymbol x)\right)\)</span> <span class="math inline">\(=r_x\left(E[\theta|\boldsymbol x]\right)\)</span> <span class="math inline">\(=\displaystyle \int_\Theta L\left(\delta^*(\boldsymbol x),\theta\right)dP(\theta|\boldsymbol x)\)</span> <span class="math inline">\(=\displaystyle \int_\Theta \left(\theta-E[\theta|\boldsymbol x]\right)^2 dP(\theta|\boldsymbol x)\)</span> <span class="math inline">\(=Var(\theta|\boldsymbol x)\)</span>,</p>
<p>de modo que o risco de Bayes é dado por</p>
<p><span class="math inline">\({\rho}^*\left(P\right)\)</span> <span class="math inline">\(=\rho\left(\delta^*(\boldsymbol X),P\right)\)</span> <span class="math inline">\(=\displaystyle \int_{\mathfrak{X}} \underbrace{ \int_{\Theta}(\theta-E[\theta|\boldsymbol{x}])^2dP(\theta|\boldsymbol{x})}_{Var[\theta|\boldsymbol{x}]}dP(\boldsymbol{x})\)</span> <span class="math inline">\(=E\left[Var(\theta|\boldsymbol X)\right]\)</span>.</p>
<p>A variância da posteriori <span class="math inline">\(Var(\theta|\boldsymbol x)\)</span> pode ser vista como uma medida de informação, no sentido que quanto menor essa variância, mais concentrada é a distribuição e há “<em>menos incerteza</em>” sobre <span class="math inline">\(\theta\)</span>. Nesse sentido, espera-se que ao observar <span class="math inline">\(\boldsymbol X=\boldsymbol x\)</span>, a variância <span class="math inline">\(Var(\theta|\boldsymbol x)\)</span> diminua em relação a variância da priori <span class="math inline">\(Var(\theta)\)</span>.</p>
<p><span class="math display">\[\underbrace{Var(\theta)}_{constante}=\underbrace{E\left[Var(\theta|\boldsymbol X)\right]}_{\boldsymbol \Downarrow}+\underbrace{Var\left[E(\theta|\boldsymbol X)\right]}_{\boldsymbol \Uparrow}\]</span></p>
<p>Aparentemente, quando espera-se que a variância da posteriori diminua, a variância do estimador deveria aumentar. Muitas vezes isso é colocado como se o objetivo fosse encontrar o estimador de maior variância, em contradição com a abordagem frequentista. Contudo, há outra interpretação desse resultado: deseja-se obter um estimador que varie bastante de acordo com o valor observado de <span class="math inline">\(\boldsymbol X\)</span>, isto é, a informação trazida pela amostra muda sua opinião sobre <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 2.</strong> Considere <span class="math inline">\(X_1,...X_n\)</span> c.i.i.d. tais que <span class="math inline">\(X_i|\theta\sim Poisson(\theta)\)</span> e, a priori, <span class="math inline">\(\theta \sim Gama(a,b)\)</span>.</p>
<p>A função de verossimilhança é <span class="math inline">\(f(\boldsymbol x | \theta)\propto \prod {\theta}^{x_i}~{e}^{-\theta}\)</span> e a priori é <span class="math inline">\(~f(\theta)\propto{\theta}^{a-1}~{e}^{-b\theta}\)</span>.</p>
<p>Assim, <span class="math inline">\(f(\theta | \boldsymbol x)\)</span> <span class="math inline">\(\propto {\theta}^{\sum x_i}~{e}^{-n\theta} ~\cdot~ {\theta}^{a-1}~{e}^{-b\theta}\)</span> <span class="math inline">\(\propto {\theta}^{a+\sum x_i-1}~{e}^{-(b+n)\theta}\)</span>, de modo que <span class="math inline">\(\theta|\boldsymbol X=\boldsymbol x\sim Gama\left(a+\sum x_i,b+n\right)\)</span>.</p>
<p>Como visto anteriormente, o estimador de Bayes contra a perda quadrática é</p>
<p><span class="math inline">\(\delta^*(\boldsymbol X)=E[\theta|\boldsymbol X]=\dfrac{a+\sum_iX_i}{b+n}\)</span>.</p>
<p>Para calcular o risco de Bayes, note que <span class="math inline">\(E[X_i|\theta]=\theta\)</span>, de modo que <span class="math inline">\(E[X_i]=E\left[E(X_i|\theta)\right]=E[\theta]=a/b\)</span>. Além disso, <span class="math inline">\(Var(\theta)=\dfrac{a}{b^2}\)</span> e <span class="math inline">\(Var(\theta|\boldsymbol X)=\dfrac{a+\sum_iX_i}{(b+n)^2}\)</span>. Então,</p>
<p><span class="math inline">\(\rho^*(P)\)</span> <span class="math inline">\(=E\left[Var(\theta|\boldsymbol X)\right]\)</span> <span class="math inline">\(=E\left[\dfrac{a+\sum_iX_i}{(b+n)^2}\right]\)</span> <span class="math inline">\(= \dfrac{\left(a+\sum E[X_i]\right)}{(b+n)^2}\)</span> <span class="math inline">\(=\dfrac{\dfrac{a}{b}\left(b+n\right)}{(b+n)^2}\)</span> <span class="math inline">\(=\dfrac{a}{b(b+n)}\)</span>.</p>
<p>Por fim, note que a decisão de Bayes pode ser escrita como uma combinação linear convexa da média da distribuição a priori e do estimador de máxima verossimilhança</p>
<p><span class="math inline">\(E[\theta|\boldsymbol X]\)</span> <span class="math inline">\(=\dfrac{a+\sum_iX_i}{b+n}\)</span> <span class="math inline">\(=\dfrac{b}{b+n}\left(\dfrac{a}{b}\right)+\dfrac{n}{b+n}\bar{X}\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado:</strong> Seja <span class="math inline">\(L(d,\theta)=\mathbb{I}(|\theta-d|&gt; \varepsilon)\)</span> <span class="math inline">\(=1-\mathbb{I}(d-\varepsilon\leq \theta \leq d+\varepsilon)\)</span> , <span class="math inline">\(\varepsilon &gt; 0\)</span>.
Então, <span class="math inline">\(\delta^*(\boldsymbol X)\)</span> é centro do intervalo modal, isto é, o intervalo de tamanho <span class="math inline">\(2\varepsilon\)</span> de maior densidade a posteriori. Em particular, quando <span class="math inline">\(\varepsilon \downarrow 0\)</span>, temos que <span class="math inline">\({\delta}^*(\boldsymbol X)=Moda(\theta|\boldsymbol X)\)</span>.</p>
<p><strong>Demo:</strong> O risco posterior de uma decisão <span class="math inline">\(d\)</span> é</p>
<p><span class="math inline">\(r_{\boldsymbol{x}}(d)\)</span> <span class="math inline">\(=E\left[L(d,\theta)|\boldsymbol{x}\right]\)</span> <span class="math inline">\(=E\left[\mathbb{I}(|\theta-d|&gt; \varepsilon)\right]\)</span> <span class="math inline">\(=E\left[1-\mathbb{I}(d-\varepsilon\leq \theta \leq d+\varepsilon)|\boldsymbol x\right]\)</span> <span class="math inline">\(=1-P(d-\varepsilon\leq \theta \leq d+\varepsilon|\boldsymbol x)\)</span>.</p>
<p>O risco <span class="math inline">\(r_{\boldsymbol{x}}(d)\)</span> é mínimo quando a probabilidade <span class="math inline">\(P(d-\varepsilon\leq \theta \leq d+\varepsilon|\boldsymbol x)\)</span> é máxima. Assim, basta tomar o intervalo <span class="math inline">\(\left[{d}_x^*-\varepsilon ~;~ {d}_x^*+\varepsilon\right]\)</span> com maior probabilidade a posteriori e o estimador de Bayes nesse caso será o valor central desse intervalo, <span class="math inline">\({d}_x^*\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 3.</strong> Considere o exemplo anterior onde <span class="math inline">\(\theta|\boldsymbol x\sim Gama(a+\sum x_i,b+n)\)</span> e a função de perda do resultado anterior, <span class="math inline">\(L(d,\theta)=\mathbb{I}(|\theta-d|&gt; \varepsilon)\)</span>. Temos que</p>
<p><span class="math inline">\(f(\theta|\boldsymbol x)\)</span> <span class="math inline">\(\propto \theta^{\overbrace{a+\sum x_i-1}^{A_x}}e^{-\overbrace{(b+n)}^{B_x}\theta}\)</span> <span class="math inline">\(=\theta^{A_x}e^{-{B_x}\theta}\)</span></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="Estimacao.html#cb8-1"></a>theta =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="fl">1.2</span>,<span class="fl">0.01</span>)</span>
<span id="cb8-2"><a href="Estimacao.html#cb8-2"></a><span class="co">#Parâmetros da dist a posteriori gama</span></span>
<span id="cb8-3"><a href="Estimacao.html#cb8-3"></a>a1 =<span class="st"> </span><span class="dv">3</span></span>
<span id="cb8-4"><a href="Estimacao.html#cb8-4"></a>b1 =<span class="st"> </span><span class="dv">10</span></span>
<span id="cb8-5"><a href="Estimacao.html#cb8-5"></a>posterior =<span class="st"> </span><span class="kw">dgamma</span>(theta, a1, b1 )</span>
<span id="cb8-6"><a href="Estimacao.html#cb8-6"></a><span class="co"># Escolhendo valores de epsilon e calculando a perda mínima associada</span></span>
<span id="cb8-7"><a href="Estimacao.html#cb8-7"></a>e=<span class="kw">c</span>(<span class="fl">0.5</span>,<span class="fl">0.4</span>,<span class="fl">0.3</span>,<span class="fl">0.25</span>,<span class="fl">0.2</span>,<span class="fl">0.15</span>,<span class="fl">0.1</span>,<span class="fl">0.05</span>,<span class="dv">0</span>)</span>
<span id="cb8-8"><a href="Estimacao.html#cb8-8"></a>loss &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb8-9"><a href="Estimacao.html#cb8-9"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(e)){</span>
<span id="cb8-10"><a href="Estimacao.html#cb8-10"></a>  loss[i] &lt;-<span class="st"> </span>theta[<span class="kw">which.min</span>(<span class="kw">as.vector</span>(<span class="kw">apply</span>(<span class="kw">matrix</span>(theta), <span class="dv">1</span>,</span>
<span id="cb8-11"><a href="Estimacao.html#cb8-11"></a>                                              <span class="cf">function</span>(d) <span class="kw">sum</span>(posterior<span class="op">*</span>(<span class="kw">abs</span>(theta<span class="op">-</span>d)<span class="op">&gt;</span>e[i])))))]}</span>
<span id="cb8-12"><a href="Estimacao.html#cb8-12"></a><span class="co"># Criando o gráfico </span></span>
<span id="cb8-13"><a href="Estimacao.html#cb8-13"></a>n &lt;-<span class="st"> </span><span class="kw">length</span>(e)</span>
<span id="cb8-14"><a href="Estimacao.html#cb8-14"></a><span class="kw">tibble</span>(<span class="dt">x=</span><span class="kw">rep</span>(loss,<span class="dt">each=</span><span class="kw">length</span>(theta)),</span>
<span id="cb8-15"><a href="Estimacao.html#cb8-15"></a>       <span class="dt">e=</span><span class="kw">rep</span>(<span class="kw">round</span>(e,<span class="dv">2</span>),<span class="dt">each=</span><span class="kw">length</span>(theta)),</span>
<span id="cb8-16"><a href="Estimacao.html#cb8-16"></a>       <span class="dt">theta=</span><span class="kw">rep</span>(theta,(n)), <span class="dt">post =</span> <span class="kw">rep</span>(posterior,n)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb8-17"><a href="Estimacao.html#cb8-17"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb8-18"><a href="Estimacao.html#cb8-18"></a><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">xend=</span>x, <span class="dt">y=</span><span class="dv">0</span>,<span class="dt">yend=</span><span class="kw">dgamma</span>(x, a1, b1 ),<span class="dt">colour=</span><span class="kw">as.factor</span>(e))) <span class="op">+</span></span>
<span id="cb8-19"><a href="Estimacao.html#cb8-19"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span><span class="dv">0</span>,<span class="dt">colour=</span><span class="kw">as.factor</span>(e))) <span class="op">+</span></span>
<span id="cb8-20"><a href="Estimacao.html#cb8-20"></a><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x<span class="op">-</span>e, <span class="dt">xend=</span>x<span class="op">+</span>e, <span class="dt">y=</span><span class="dv">0</span>,<span class="dt">yend=</span><span class="dv">0</span>,<span class="dt">colour=</span><span class="kw">as.factor</span>(e))) <span class="op">+</span></span>
<span id="cb8-21"><a href="Estimacao.html#cb8-21"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>post, <span class="dt">colour=</span><span class="st">&quot;Dist. a posteriori&quot;</span>)) <span class="op">+</span></span>
<span id="cb8-22"><a href="Estimacao.html#cb8-22"></a><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span>(a1<span class="dv">-1</span>)<span class="op">/</span>b1, <span class="dt">xend=</span>(a1<span class="dv">-1</span>)<span class="op">/</span>b1, <span class="dt">y=</span><span class="dv">0</span>,<span class="dt">yend=</span><span class="kw">dgamma</span>((a1<span class="dv">-1</span>)<span class="op">/</span>b1, a1, b1 ), <span class="dt">colour =</span> <span class="st">&quot;Moda a posteriori&quot;</span>),<span class="dt">lty=</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb8-23"><a href="Estimacao.html#cb8-23"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(theta)) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;f(&quot;</span>,theta,<span class="st">&quot;|x)&quot;</span>))) <span class="op">+</span></span>
<span id="cb8-24"><a href="Estimacao.html#cb8-24"></a><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;epsilon&quot;</span>) <span class="op">+</span></span>
<span id="cb8-25"><a href="Estimacao.html#cb8-25"></a><span class="st">  </span>gganimate<span class="op">::</span><span class="kw">transition_states</span>(<span class="kw">rev</span>(e))</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-17-1.gif" width="80%" style="display: block; margin: auto;" /></p>
<p>Como comentado no resultado anterior, quando <span class="math inline">\(\varepsilon \downarrow 0\)</span>, temos que <span class="math inline">\({\delta}^*(\boldsymbol x)=Moda(\theta|\boldsymbol x)\)</span> <span class="math inline">\(= \displaystyle\sup_{\theta} f(\theta|\boldsymbol x)\)</span>.</p>
<p><span class="math inline">\(\dfrac{\partial f(\theta|\boldsymbol x)}{\partial \theta}\)</span> <span class="math inline">\(=(A_x-B_x\theta)\theta^{A_x-1}e^{-B_x\theta}=0\)</span> <span class="math inline">\(\Leftrightarrow \theta =\dfrac{A_x}{B_x}\)</span></p>
<p><span class="math inline">\({\delta}^*(\boldsymbol X) = Moda(\theta|\boldsymbol X)\)</span> <span class="math inline">\(=\dfrac{a+\sum X_i-1}{b+n}\)</span> <span class="math inline">\(=\dfrac{b}{b+n}\left(\dfrac{a-1}{b}\right)+\dfrac{n}{b+n}~\bar{X}\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Resultado.</strong> Seja <span class="math inline">\(L(d,\theta)=c_1(d-\theta)~\mathbb{I}(d\geq \theta)+c_2(\theta-d)~\mathbb{I}(d&lt;\theta)\)</span> com <span class="math inline">\(c_1&gt;0\)</span>, <span class="math inline">\(c_2 &gt;0\)</span>. Então, <span class="math inline">\({\delta}^*(\boldsymbol{x})\)</span> é tal que <span class="math inline">\(P\left(\theta\leq {\delta}^*(\boldsymbol{x})\big|\boldsymbol x\right)=\dfrac{c_1}{c_1+c_2}\)</span>. Em particular, se <span class="math inline">\(c_1=c_2=c\)</span>, temos a <em>perda absoluta</em> <span class="math inline">\(L(d,\theta)=c~|d-\theta|\)</span> e <span class="math inline">\({\delta}^*(\boldsymbol{X})=Med(\theta|\boldsymbol X)\)</span>.</p>
<p><strong>Demo:</strong> exercício.</p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="estimação-por-regiões" class="section level2">
<h2><span class="header-section-number">4.2</span> Estimação por Regiões</h2>
<p>Em um problema de estimação por regiões (ou estimação intervalar, no caso univariado), o objetivo é obter um conjunto de valores razoáveis para <span class="math inline">\(\theta\)</span>. Mais formalmente, temos um problema aonde a decisão consiste em escolher um subconjunto do espaço paramétrico, de modo que <span class="math inline">\(\mathcal{D}=\mathcal{A}\)</span>, onde <span class="math inline">\(\mathcal{A}\)</span> é <span class="math inline">\(\sigma\)</span>-algebra de subconjuntos de <span class="math inline">\(\Theta\)</span>. Uma estimativa por região é comumente chamada na literatura Bayesiana de <strong>região de credibilidade</strong> (<strong>intervalo de credibilidade</strong>, no caso univariado) ou <strong>região de probabilidade</strong> <span class="math inline">\(~\gamma=1-\alpha\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 1.</strong> Suponha que a distribuição a posteriori é <span class="math inline">\(f(\theta|\boldsymbol{x})=4\theta~\mathbb{I}_{[0,1/2)}(\theta)+4(1-\theta)~\mathbb{I}_{[1/2,1]}(\theta)\)</span>. Uma possível estimativa intervalar é um intervalo central ou um intervalo simétrico em torno da média (ou da moda) com uma probabilidade <span class="math inline">\(\gamma = 1-\alpha\)</span>. Nesse caso, vamos considerar um intervalo central no sentido que deixa de fora conjuntos caudais de probabilidade <span class="math inline">\(\alpha/2\)</span>. Note que é possível obter o intervalo de forma analítica nesse exemplo. A seguir, são apresentadas as funções de distribuição <span class="math inline">\(F\)</span> e quantílica <span class="math inline">\(Q\)</span> a posteriori e o intervalo de credibilidade <span class="math inline">\(\alpha\)</span>.</p>
<p><span class="math inline">\(F(\theta|\boldsymbol x)\)</span> <span class="math inline">\(=\displaystyle \int_0^\theta f(t|x)dt\)</span>
<span class="math inline">\(=\displaystyle \int_0^\theta\left[4t~\mathbb I_{[0,1/2]}(t)+(4-4t)~\mathbb I_{(1/2,1]}(t)\right]dt\)</span>
<span class="math inline">\(=\left\{\begin{array}{lcc} 2\theta^2 &amp;,&amp; \theta\leq 1/2\\ -2\theta^2+4\theta-1 &amp;,&amp; \theta&gt;1/2\end{array}\right.\)</span></p>
<p><span class="math inline">\(Q(p)=\left\{\begin{array}{lcc} \sqrt{\dfrac{p}{2}} &amp;,&amp; p\leq 1/2\\ 1-\sqrt{\dfrac{1-p}{2}} &amp;,&amp; p&gt;1/2\end{array}\right.\)</span></p>
<p><span class="math inline">\(I.C.(1-\alpha)=\left[\sqrt{\dfrac{\alpha/2}{2}};1-\sqrt{\dfrac{\alpha/2}{2}}\right]\)</span>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="Estimacao.html#cb9-1"></a>alpha=<span class="fl">0.1</span></span>
<span id="cb9-2"><a href="Estimacao.html#cb9-2"></a>theta =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb9-3"><a href="Estimacao.html#cb9-3"></a><span class="co"># Densidade a posteriori</span></span>
<span id="cb9-4"><a href="Estimacao.html#cb9-4"></a>dpost =<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(t){ <span class="dv">4</span><span class="op">*</span>t<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;=</span><span class="dv">0</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="fl">0.5</span>)<span class="op">+</span></span>
<span id="cb9-5"><a href="Estimacao.html#cb9-5"></a><span class="st">    </span><span class="dv">4</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>t)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="fl">0.5</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="dv">1</span>) })</span>
<span id="cb9-6"><a href="Estimacao.html#cb9-6"></a><span class="co"># F. Distribuição a posteriori</span></span>
<span id="cb9-7"><a href="Estimacao.html#cb9-7"></a>ppost =<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(t){ <span class="dv">2</span><span class="op">*</span>(t<span class="op">^</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;=</span><span class="dv">0</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="fl">0.5</span>)<span class="op">+</span></span>
<span id="cb9-8"><a href="Estimacao.html#cb9-8"></a><span class="st">    </span><span class="dv">4</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>t)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="fl">0.5</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="dv">1</span>)<span class="op">+</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="dv">1</span>) })</span>
<span id="cb9-9"><a href="Estimacao.html#cb9-9"></a><span class="co"># F. Quantílica a posteriori</span></span>
<span id="cb9-10"><a href="Estimacao.html#cb9-10"></a>qpost =<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(t){ <span class="kw">ifelse</span>(t<span class="op">&lt;=</span><span class="fl">0.5</span>, <span class="kw">sqrt</span>(t<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="dv">0</span>),</span>
<span id="cb9-11"><a href="Estimacao.html#cb9-11"></a>    (<span class="dv">1</span><span class="op">-</span><span class="kw">sqrt</span>((<span class="dv">1</span><span class="op">-</span>t)<span class="op">/</span><span class="dv">2</span>))<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;</span><span class="dv">1</span>)<span class="op">+</span><span class="kw">I</span>(t<span class="op">&gt;=</span><span class="dv">1</span>)) })</span>
<span id="cb9-12"><a href="Estimacao.html#cb9-12"></a>post =<span class="st"> </span><span class="kw">dpost</span>(theta)</span>
<span id="cb9-13"><a href="Estimacao.html#cb9-13"></a>l =<span class="st"> </span><span class="kw">c</span>(<span class="kw">qpost</span>((alpha<span class="op">/</span><span class="dv">2</span>)),<span class="kw">qpost</span>((<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>)))</span>
<span id="cb9-14"><a href="Estimacao.html#cb9-14"></a>X =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">theta=</span>theta,<span class="dt">Posterior=</span>post)</span>
<span id="cb9-15"><a href="Estimacao.html#cb9-15"></a><span class="kw">ggplot</span>(<span class="dt">data=</span>X,<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>Posterior)) <span class="op">+</span></span>
<span id="cb9-16"><a href="Estimacao.html#cb9-16"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">lwd=</span><span class="fl">1.5</span>) <span class="op">+</span></span>
<span id="cb9-17"><a href="Estimacao.html#cb9-17"></a><span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">data=</span><span class="kw">subset</span>(X, theta <span class="op">&gt;=</span><span class="st"> </span>l[<span class="dv">1</span>] <span class="op">&amp;</span><span class="st"> </span>theta <span class="op">&lt;=</span><span class="st"> </span>l[<span class="dv">2</span>]),<span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.5</span>)<span class="op">+</span></span>
<span id="cb9-18"><a href="Estimacao.html#cb9-18"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-18-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 2.</strong> Por fim, suponha que a distribuição a posteriori é <span class="math inline">\(f(\theta|\boldsymbol{x})=(2-4\theta)~\mathbb{I}_{[0,1/2)}(\theta)+(4\theta-2)~\mathbb{I}_{[1/2,1]}(\theta)\)</span>. Vamos construir um intervalo como no Exemplo anterior.</p>
<p><span class="math inline">\(F(\theta|\boldsymbol x)\)</span> <span class="math inline">\(=\left\{\begin{array}{lcc} 2\theta(1-\theta) &amp;,&amp; \theta\leq 1/2\\ 2\theta(\theta-1)+1 &amp;,&amp; \theta&gt;1/2\end{array}\right.\)</span></p>
<p><span class="math inline">\(Q(p)=\left\{\begin{array}{lcc} \dfrac{1}{2}-\dfrac{\sqrt{1-2p}}{2} &amp;,&amp; p\leq 1/2\\ \dfrac{1}{2}+\dfrac{\sqrt{2p-1}}{2} &amp;,&amp; p&gt;1/2\end{array}\right.\)</span></p>
<p><span class="math inline">\(I.C.(1-\alpha)=\left[\dfrac{1}{2}-\dfrac{\sqrt{1-\alpha}}{2};\dfrac{1}{2}+\dfrac{\sqrt{1-\alpha}}{2}\right]\)</span>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="Estimacao.html#cb10-1"></a>alpha=<span class="fl">0.1</span></span>
<span id="cb10-2"><a href="Estimacao.html#cb10-2"></a>theta =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb10-3"><a href="Estimacao.html#cb10-3"></a><span class="co"># Densidade a posteriori</span></span>
<span id="cb10-4"><a href="Estimacao.html#cb10-4"></a>dpost =<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(t){ (<span class="dv">2-4</span><span class="op">*</span>t)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;=</span><span class="dv">0</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="fl">0.5</span>)<span class="op">+</span></span>
<span id="cb10-5"><a href="Estimacao.html#cb10-5"></a><span class="st">    </span>(<span class="dv">4</span><span class="op">*</span>t<span class="dv">-2</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="fl">0.5</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="dv">1</span>) })</span>
<span id="cb10-6"><a href="Estimacao.html#cb10-6"></a><span class="co"># F. Distribuição a posteriori</span></span>
<span id="cb10-7"><a href="Estimacao.html#cb10-7"></a>ppost =<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(t){ <span class="dv">2</span><span class="op">*</span>t<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>t)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;=</span><span class="dv">0</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="fl">0.5</span>)<span class="op">+</span></span>
<span id="cb10-8"><a href="Estimacao.html#cb10-8"></a><span class="st">    </span>(<span class="dv">2</span><span class="op">*</span>(t<span class="op">^</span><span class="dv">2</span>)<span class="op">-</span><span class="dv">2</span><span class="op">*</span>t<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="fl">0.5</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="dv">1</span>)<span class="op">+</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="dv">1</span>) })</span>
<span id="cb10-9"><a href="Estimacao.html#cb10-9"></a><span class="co"># F. Quantílica a posteriori</span></span>
<span id="cb10-10"><a href="Estimacao.html#cb10-10"></a>qpost =<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(t){ <span class="kw">ifelse</span>(t<span class="op">&lt;=</span><span class="fl">0.5</span>, (<span class="fl">0.5</span><span class="op">-</span><span class="kw">sqrt</span>(<span class="dv">1-2</span><span class="op">*</span>t)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="dv">0</span>),</span>
<span id="cb10-11"><a href="Estimacao.html#cb10-11"></a>    (<span class="fl">0.5</span><span class="op">+</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>t<span class="dv">-1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;</span><span class="dv">1</span>)<span class="op">+</span><span class="kw">I</span>(t<span class="op">&gt;=</span><span class="dv">1</span>)) })</span>
<span id="cb10-12"><a href="Estimacao.html#cb10-12"></a>post =<span class="st"> </span><span class="kw">dpost</span>(theta)</span>
<span id="cb10-13"><a href="Estimacao.html#cb10-13"></a>l =<span class="st"> </span><span class="kw">c</span>(<span class="kw">qpost</span>((alpha<span class="op">/</span><span class="dv">2</span>)),<span class="kw">qpost</span>((<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>)))</span>
<span id="cb10-14"><a href="Estimacao.html#cb10-14"></a>X =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">theta=</span>theta,<span class="dt">Posterior=</span>post)</span>
<span id="cb10-15"><a href="Estimacao.html#cb10-15"></a><span class="kw">ggplot</span>(<span class="dt">data=</span>X,<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>Posterior)) <span class="op">+</span></span>
<span id="cb10-16"><a href="Estimacao.html#cb10-16"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">lwd=</span><span class="fl">1.5</span>) <span class="op">+</span></span>
<span id="cb10-17"><a href="Estimacao.html#cb10-17"></a><span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">data=</span><span class="kw">subset</span>(X, theta <span class="op">&gt;=</span><span class="st"> </span>l[<span class="dv">1</span>] <span class="op">&amp;</span><span class="st"> </span>theta <span class="op">&lt;=</span><span class="st"> </span>l[<span class="dv">2</span>]),<span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.5</span>)<span class="op">+</span></span>
<span id="cb10-18"><a href="Estimacao.html#cb10-18"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-19-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Note que, nesse exemplo, as regiões que tem mais densidade a posteriori foram excluídas do intervalo. Isso não faz muito sentido pois essas regiões têm maior chance de conter o <span class="math inline">\(\theta\)</span> que quaquer outra região de mesmo tamanho.</p>
<p><span class="math inline">\(~\)</span></p>
<!-- **Exemplo 3.** Suponha que $\Theta = [0,1]$ e a distribuição a posteriori é uma $Beta(2,2)$, ou seja, $f(\theta|\boldsymbol x) = 6\theta(1-\theta)$. -->
<!-- ```{r} -->
<!-- a=2; b=2 -->
<!-- alpha=0.1 -->
<!-- theta = seq(0,1,0.01) -->
<!-- post = dbeta(theta,a,b) -->
<!-- l = c(qbeta((alpha/2),a,b),qbeta((1-alpha/2),a,b)) -->
<!-- X = tibble(theta=theta,Posterior=post) -->
<!-- ggplot(data=X,mapping = aes(x=theta,y=Posterior)) + -->
<!--   geom_line(lwd=1.5) + -->
<!--   geom_area(data=subset(X, theta >= l[1] & theta <= l[2]),fill = "blue", alpha=0.5) -->
<!-- ``` -->
<!-- $~$ -->
<p><span class="math inline">\(~\)</span></p>
<p>Uma <em>função de perda</em> razoável para um problema de estimação por região deve levar em consideração dois fatores:</p>
<ul>
<li><p>O tamanho da região <span class="math inline">\(d \in \mathcal{A}\)</span> (deseja-se uma região que seja menor que o espaço paramétrico);</p></li>
<li><p>Pertinência de <span class="math inline">\(\theta\)</span> na região <span class="math inline">\(d\)</span>.</p></li>
</ul>
<p>Assim, considere uma função de perda da forma</p>
<p><span class="math inline">\(L(d,\theta)=\lambda(d)-k~\mathbb I_d(\theta)\)</span>,</p>
<p>onde <span class="math inline">\(\lambda(d)\)</span> é o “tamanho” da região <span class="math inline">\(d\)</span>. Por exemplo, a medida de Lebesgue, no caso contínuo, ou a medida de contagem, no caso discreto (no caso geral, considere uma medida que domina a distribuição a posteriori, <span class="math inline">\(P(\theta|\boldsymbol x) \ll \lambda\)</span>). No caso absolutamente contínuo, o risco a posteriori de uma decisão <span class="math inline">\(d \in \mathcal{A}\)</span> é</p>
<p><span class="math inline">\({r}_{x}(d)\)</span> <span class="math inline">\(=\displaystyle\int_\Theta \left[\lambda(d)-k~\mathbb I_d(\theta)\right]dP(\theta|\boldsymbol x)\)</span> <span class="math inline">\(=\displaystyle \int_\Theta\mathbb I_d(\theta)d\theta-\int_\Theta k~\mathbb I_d(\theta)f(\theta|\boldsymbol x)d\theta\)</span> <span class="math inline">\(=\displaystyle \int_d\left(1-kf(\theta|\boldsymbol x)\right)d\theta\)</span>.</p>
<p>Esse risco é mínimo quando <span class="math inline">\(d=\left\{\theta\in\Theta:1-kf(\theta|\boldsymbol x)\leq 0\right\}\)</span> <span class="math inline">\(\Leftrightarrow d=\{\theta\in\Theta:f(\theta|\boldsymbol x)\geq 1/k\}\)</span>.</p>
<p>Assim, a decisão de Bayes contra essa função de perda consiste em escolher uma região <span class="math inline">\(d \in \mathcal{A}\)</span> que contêm os pontos do espaço paramétrico com maior densidade a posteriori.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Definição:</strong> A região <span class="math inline">\(R\subseteq \Theta\)</span> é dita ser uma região HPD (Highest Posterior Density) de probabilidade <span class="math inline">\(\gamma\)</span> se</p>
<ol style="list-style-type: lower-roman">
<li><p><span class="math inline">\(P(\theta\in R|\boldsymbol x)=\gamma\)</span>;</p></li>
<li><p><span class="math inline">\(\forall \theta \in R\)</span> e <span class="math inline">\(\forall \theta^\prime\notin R\)</span>, <span class="math inline">\(f(\theta|\boldsymbol x)\geq f(\theta^\prime|\boldsymbol x)\)</span>.</p></li>
</ol>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Voltando ao Exemplo 2.</strong> As regiões centrais nesse exemplo tem menor densidade a posteriori. Assim, uma região HPD de probabilidade <span class="math inline">\(\gamma=1-\alpha\)</span> é dada por</p>
<p><span class="math inline">\(I.C.(1-\alpha)=\left[0~;~\dfrac{1}{2}-\dfrac{\sqrt{\alpha}}{2}\right]\bigcup \left[\dfrac{1}{2}+\dfrac{\sqrt{\alpha}}{2}~;~1\right]\)</span></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="Estimacao.html#cb11-1"></a>alpha=<span class="fl">0.1</span></span>
<span id="cb11-2"><a href="Estimacao.html#cb11-2"></a>theta =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb11-3"><a href="Estimacao.html#cb11-3"></a><span class="co"># Densidade a posteriori</span></span>
<span id="cb11-4"><a href="Estimacao.html#cb11-4"></a>dpost =<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(t){ (<span class="dv">2-4</span><span class="op">*</span>t)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;=</span><span class="dv">0</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="fl">0.5</span>)<span class="op">+</span></span>
<span id="cb11-5"><a href="Estimacao.html#cb11-5"></a><span class="st">    </span>(<span class="dv">4</span><span class="op">*</span>t<span class="dv">-2</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="fl">0.5</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="dv">1</span>) })</span>
<span id="cb11-6"><a href="Estimacao.html#cb11-6"></a><span class="co"># F. Distribuição a posteriori</span></span>
<span id="cb11-7"><a href="Estimacao.html#cb11-7"></a>ppost =<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(t){ <span class="dv">2</span><span class="op">*</span>t<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>t)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;=</span><span class="dv">0</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="fl">0.5</span>)<span class="op">+</span></span>
<span id="cb11-8"><a href="Estimacao.html#cb11-8"></a><span class="st">    </span>(<span class="dv">2</span><span class="op">*</span>(t<span class="op">^</span><span class="dv">2</span>)<span class="op">-</span><span class="dv">2</span><span class="op">*</span>t<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="fl">0.5</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;=</span><span class="dv">1</span>)<span class="op">+</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="dv">1</span>) })</span>
<span id="cb11-9"><a href="Estimacao.html#cb11-9"></a><span class="co"># F. Quantílica a posteriori</span></span>
<span id="cb11-10"><a href="Estimacao.html#cb11-10"></a>qpost =<span class="st"> </span><span class="kw">Vectorize</span>(<span class="cf">function</span>(t){ <span class="kw">ifelse</span>(t<span class="op">&lt;=</span><span class="fl">0.5</span>, (<span class="fl">0.5</span><span class="op">-</span><span class="kw">sqrt</span>(<span class="dv">1-2</span><span class="op">*</span>t)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;</span><span class="dv">0</span>),</span>
<span id="cb11-11"><a href="Estimacao.html#cb11-11"></a>    (<span class="fl">0.5</span><span class="op">+</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>t<span class="dv">-1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&lt;</span><span class="dv">1</span>)<span class="op">+</span><span class="kw">I</span>(t<span class="op">&gt;=</span><span class="dv">1</span>)) })</span>
<span id="cb11-12"><a href="Estimacao.html#cb11-12"></a>post =<span class="st"> </span><span class="kw">dpost</span>(theta)</span>
<span id="cb11-13"><a href="Estimacao.html#cb11-13"></a>l =<span class="st"> </span><span class="kw">c</span>(<span class="kw">qpost</span>((<span class="dv">1</span><span class="op">-</span>alpha)<span class="op">/</span><span class="dv">2</span>),<span class="kw">qpost</span>((alpha<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb11-14"><a href="Estimacao.html#cb11-14"></a>X =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">theta=</span>theta,<span class="dt">Posterior=</span>post)</span>
<span id="cb11-15"><a href="Estimacao.html#cb11-15"></a><span class="kw">ggplot</span>(<span class="dt">data=</span>X,<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>Posterior)) <span class="op">+</span></span>
<span id="cb11-16"><a href="Estimacao.html#cb11-16"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">lwd=</span><span class="fl">1.5</span>) <span class="op">+</span></span>
<span id="cb11-17"><a href="Estimacao.html#cb11-17"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept=</span><span class="kw">dpost</span>(l[<span class="dv">1</span>]), <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;darkgray&quot;</span>) <span class="op">+</span></span>
<span id="cb11-18"><a href="Estimacao.html#cb11-18"></a><span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">data=</span><span class="kw">subset</span>(X, theta <span class="op">&lt;=</span><span class="st"> </span>l[<span class="dv">1</span>]),<span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.5</span>) <span class="op">+</span></span>
<span id="cb11-19"><a href="Estimacao.html#cb11-19"></a><span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">data=</span><span class="kw">subset</span>(X, theta <span class="op">&gt;=</span><span class="st"> </span>l[<span class="dv">2</span>]),<span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.5</span>)<span class="op">+</span></span>
<span id="cb11-20"><a href="Estimacao.html#cb11-20"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-20-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Note que na solução anterior, o comprimento do intervalo era <span class="math inline">\(\sqrt{1-\alpha}\)</span>, enquanto que o comprimento do HPD é <span class="math inline">\(1-\sqrt{\alpha}\)</span>. Tomando, por exemplo, <span class="math inline">\(\alpha=0.1\)</span> temos que <span class="math inline">\(\sqrt{1-\alpha} \approx 0.95\)</span> enquanto <span class="math inline">\(1-\sqrt{\alpha}\approx 0.68\)</span>. Por conter apenas os pontos com maior densidade, o HPD sempre terá comprimento menor ou igual a qualquer intervalo com mesma probabilidade.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 3.</strong> Considere <span class="math inline">\(X_1,...,X_n\)</span> c.i.i.d. tais que <span class="math inline">\(X_i|\theta\sim N(\theta,1/\tau)\)</span> , <span class="math inline">\(\tau=1/\sigma^2\)</span> , com <span class="math inline">\(\tau\)</span> conhecido (fixado). Vimos que se, a priori, <span class="math inline">\(\theta\sim N(m,1/v)\)</span> então <span class="math inline">\(\theta|\boldsymbol x\sim N\left(\underbrace{\dfrac{vm+n\tau\bar x}{v+n\tau}}_{M_x},\underbrace{\dfrac{1}{v+n\tau}}_{V_x}\right)\)</span> e, assim, <span class="math inline">\(Z=\dfrac{\theta-M_x}{\sqrt V_x}~\Bigg|~\boldsymbol x\sim N(0,1)\)</span>.</p>
<p>O intervalo HPD de probabilidade <span class="math inline">\(\gamma=1-\alpha=0.95\)</span> é</p>
<p><span class="math inline">\(I.C.(1-\alpha)=\)</span> <span class="math inline">\(\left[M-z_{\alpha/2}\sqrt V;M+z_{\alpha/2}\sqrt V\right]\)</span> <span class="math inline">\(=\left[\dfrac{vm+n\tau\bar x}{v+n\tau}\pm1.96\sqrt{\dfrac{1}{v+n\tau}}\right]\)</span>.</p>
<p>Uma possível forma de representar falta de informação a priori é tomar o limite <span class="math inline">\(~v\downarrow 0~~\)</span> (<span class="math inline">\(1/v\uparrow \infty\)</span>). Dessa forma, tem-se</p>
<p><span class="math inline">\(\theta|\boldsymbol x\sim N(\bar x,1/(n\tau))\sim N(\bar x,\sigma^2/n)\)</span>,</p>
<p>e o intervalo HPD coincide com o I.C. frequentista</p>
<p><span class="math inline">\(I.C.(1-\alpha)=\left[\bar x\pm 1.96\dfrac{\sigma}{\sqrt{n}}\right]\)</span>.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="Estimacao.html#cb12-1"></a>mx=<span class="dv">2</span>; vx=<span class="kw">sqrt</span>(<span class="dv">3</span>)</span>
<span id="cb12-2"><a href="Estimacao.html#cb12-2"></a>alpha=<span class="fl">0.05</span></span>
<span id="cb12-3"><a href="Estimacao.html#cb12-3"></a>theta =<span class="st"> </span><span class="kw">seq</span>(<span class="kw">qnorm</span>(<span class="fl">0.001</span>,mx,vx),<span class="kw">qnorm</span>(<span class="fl">0.999</span>,mx,vx),<span class="dt">length.out=</span><span class="dv">100</span>)</span>
<span id="cb12-4"><a href="Estimacao.html#cb12-4"></a>post =<span class="st"> </span><span class="kw">dnorm</span>(theta,mx,vx)</span>
<span id="cb12-5"><a href="Estimacao.html#cb12-5"></a>l =<span class="st"> </span><span class="kw">c</span>(<span class="kw">qnorm</span>(alpha<span class="op">/</span><span class="dv">2</span>,mx,vx),<span class="kw">qnorm</span>(<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>,mx,vx))</span>
<span id="cb12-6"><a href="Estimacao.html#cb12-6"></a>X =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">theta=</span>theta,<span class="dt">Posterior=</span>post)</span>
<span id="cb12-7"><a href="Estimacao.html#cb12-7"></a><span class="kw">ggplot</span>(<span class="dt">data=</span>X,<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>Posterior)) <span class="op">+</span></span>
<span id="cb12-8"><a href="Estimacao.html#cb12-8"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">lwd=</span><span class="fl">1.5</span>) <span class="op">+</span></span>
<span id="cb12-9"><a href="Estimacao.html#cb12-9"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept=</span><span class="kw">dnorm</span>(l[<span class="dv">1</span>],mx,vx), <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;darkgray&quot;</span>) <span class="op">+</span></span>
<span id="cb12-10"><a href="Estimacao.html#cb12-10"></a><span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">data=</span><span class="kw">subset</span>(X, theta <span class="op">&gt;=</span><span class="st"> </span>l[<span class="dv">1</span>] <span class="op">&amp;</span><span class="st"> </span>theta <span class="op">&lt;=</span><span class="st"> </span>l[<span class="dv">2</span>]),<span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.5</span>)<span class="op">+</span></span>
<span id="cb12-11"><a href="Estimacao.html#cb12-11"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-21-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo 4:</strong> Considere <span class="math inline">\(X_1,...,X_n\)</span> c.i.i.d. tais que <span class="math inline">\(X_i|\theta\sim Unif(0,\theta)\)</span>. Vimos que se <span class="math inline">\(\theta\sim Pareto(a,b)\)</span>, então <span class="math inline">\(\theta|\boldsymbol x\sim Pareto (a+n,\max\{x_{(n)},b\})\)</span></p>
<p><span class="math inline">\(f(\theta|\boldsymbol x) =\dfrac{(a+n)[\max\{x_{(n)},b\}]^{a+n}}{\theta^{a+n+1}}~\mathbb I_{[\max\{x_{(n)},b\},\infty)}\)</span></p>
<p>Note que a função de densidade a posteriori é estritamente decrescente de modo que o extremo inferior da região HPD é <span class="math inline">\(\max\{x_{(n)},b\}\)</span>. A função de distribuição a posteriori é</p>
<p><span class="math inline">\(F(\theta|\boldsymbol x)=1-\left(\dfrac{\max\{x_{(n)},b\}}{\theta}\right)^{a+n}\)</span>,</p>
<p>de modo que o extremo superior do intervalo pode ser obtido fazendo</p>
<p><span class="math inline">\(1-\left(\dfrac{\max\{x_{(n)},b\}}{\theta}\right)^{a+n}=\gamma\)</span> <span class="math inline">\(\Leftrightarrow\dfrac{\max\{x_{(n)},b\}}{\theta^*}=(1-\gamma)^{1/(a+n)}\)</span> <span class="math inline">\(\Leftrightarrow \theta^*=\dfrac{\max\{x_{(n)},b\}}{(1-\gamma)^{1/(a+n)}}\)</span>.</p>
<p><span class="math inline">\(I.C.(1-\alpha)=\left[\max\{x_{(n)},b\},\dfrac{\max\{x_{(n)},b\}}{\alpha^{1/(a+n)}}\right]\)</span></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="Estimacao.html#cb13-1"></a>ax=<span class="dv">2</span>; bx=<span class="dv">1</span></span>
<span id="cb13-2"><a href="Estimacao.html#cb13-2"></a>maxt=bx<span class="op">/</span>((alpha<span class="op">/</span><span class="dv">3</span>)<span class="op">^</span>(<span class="dv">1</span><span class="op">/</span>ax))</span>
<span id="cb13-3"><a href="Estimacao.html#cb13-3"></a>alpha=<span class="fl">0.1</span></span>
<span id="cb13-4"><a href="Estimacao.html#cb13-4"></a>limsup=bx<span class="op">/</span>(alpha<span class="op">^</span>(<span class="dv">1</span><span class="op">/</span>ax))</span>
<span id="cb13-5"><a href="Estimacao.html#cb13-5"></a>theta =<span class="st"> </span><span class="kw">seq</span>(bx,maxt,<span class="fl">0.1</span>)</span>
<span id="cb13-6"><a href="Estimacao.html#cb13-6"></a>dpareto=<span class="kw">Vectorize</span>(<span class="cf">function</span>(t){</span>
<span id="cb13-7"><a href="Estimacao.html#cb13-7"></a>  ax<span class="op">*</span>(bx<span class="op">^</span>ax)<span class="op">*</span><span class="kw">I</span>(t<span class="op">&gt;=</span>bx) <span class="op">/</span><span class="st"> </span>(t<span class="op">^</span>(ax<span class="op">+</span><span class="dv">1</span>)) })</span>
<span id="cb13-8"><a href="Estimacao.html#cb13-8"></a>post =<span class="st"> </span><span class="kw">dpareto</span>(theta)</span>
<span id="cb13-9"><a href="Estimacao.html#cb13-9"></a>X =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">theta=</span>theta,<span class="dt">Posterior=</span>post)</span>
<span id="cb13-10"><a href="Estimacao.html#cb13-10"></a><span class="kw">ggplot</span>(<span class="dt">data=</span>X,<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x=</span>theta,<span class="dt">y=</span>Posterior)) <span class="op">+</span></span>
<span id="cb13-11"><a href="Estimacao.html#cb13-11"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">lwd=</span><span class="fl">1.5</span>) <span class="op">+</span></span>
<span id="cb13-12"><a href="Estimacao.html#cb13-12"></a><span class="st">  </span><span class="kw">xlim</span>(<span class="kw">c</span>(<span class="dv">0</span>,maxt))<span class="op">+</span></span>
<span id="cb13-13"><a href="Estimacao.html#cb13-13"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept=</span><span class="kw">dpareto</span>(limsup), <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;darkgray&quot;</span>) <span class="op">+</span></span>
<span id="cb13-14"><a href="Estimacao.html#cb13-14"></a><span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">data=</span><span class="kw">subset</span>(X, theta <span class="op">&lt;=</span><span class="st"> </span>limsup),<span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.5</span>)<span class="op">+</span></span>
<span id="cb13-15"><a href="Estimacao.html#cb13-15"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-22-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p><span class="math inline">\(~\)</span></p>
</div>
<div id="custo-das-observações" class="section level2">
<h2><span class="header-section-number">4.3</span> Custo das Observações</h2>
<p>Suponha agora que o custo para observar uma amostra de tamanho <span class="math inline">\(n\)</span> é dado por uma função custo <span class="math inline">\(c(n)\)</span> e, antes de observar <span class="math inline">\(X_1,\ldots,X_n\)</span>, você precisa decidir qual o tamanho amostral ótimo, <span class="math inline">\(n^*\)</span>. Desta forma, considere a função de perda <span class="math inline">\(L(d,\theta,n) = L(d,\theta) + c(n)\)</span> com risco</p>
<p><span class="math inline">\(\rho_n(\delta,P)\)</span> <span class="math inline">\(= E\left[L(d,\theta,n)\right]\)</span> <span class="math inline">\(= E\left[L(d,\theta) + c(n)\right]\)</span> <span class="math inline">\(= \rho_n(\delta,P) + c(n)\)</span>.</p>
<p>Note que (supostamente, por simplicidade) o custo <span class="math inline">\(c(n)\)</span> não depende de <span class="math inline">\(\theta\)</span>. Se <span class="math inline">\(\delta^*\)</span> é função de decisão de Bayes contra <span class="math inline">\(L(d,\theta)\)</span> e a priori <span class="math inline">\(P\)</span>, o tamanho amostral ótimo <span class="math inline">\(n^*\)</span> é o valor que minimiza</p>
<p><span class="math inline">\(\rho_n(P)\)</span> <span class="math inline">\(= \rho(\delta,P) + c(n)\)</span> <span class="math inline">\(= \rho^*(P) + c(n)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p><strong>Exemplo.</strong> Considere o exemplo visto anteriorimente em que <span class="math inline">\(\mathcal{D}=\{d_1,d_2\}\)</span>, <span class="math inline">\(\Theta=\{\theta_1,\theta_2\}=\{3/4,1/3\}\)</span>, <span class="math inline">\(P(\theta_1)=1/2\)</span> e a função de perda é <span class="math inline">\(L(d,\theta)=10~\mathbb{I}(d_1,\theta_2) + 5~\mathbb{I}(d_2,\theta_1)\)</span>. Se <span class="math inline">\(X|\theta \sim Ber(\theta)\)</span>, a função de decisão de Bayes é <span class="math inline">\(\delta^*(x)=d_1~\mathbb{I}(x=1)+d_2~\mathbb{I}(x=0)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Suponha agora que é possível observar <span class="math inline">\(X_1,\ldots,X_n\)</span> v.a. c.i.i.d. tais que <span class="math inline">\(X_i|\theta \sim Ber(\theta)\)</span>. Note que <span class="math inline">\(T(\boldsymbol X)=\sum X_i\)</span> é suficiente para <span class="math inline">\(\theta\)</span> com <span class="math inline">\(T(\boldsymbol X)|\theta \sim Bin(n,\theta)\)</span> e</p>
<p><span class="math inline">\(f(\theta_1|T(\boldsymbol X)=t)\)</span>
<span class="math inline">\(=\dfrac{f(t|\theta_1)P(\theta_1)}{\displaystyle \sum_{i\in\{1,2\}} f(t|\theta_i)P(\theta_i)}\)</span>
<span class="math inline">\(=\dfrac{f(t|\theta_1)}{\displaystyle \sum_{i\in\{1,2\}} f(t|\theta_i)}\)</span>
<span class="math inline">\(=\dfrac{\binom{n}{t}\left(\frac{3}{4}\right)^t\left(\frac{1}{4}\right)^{n-t}}{\binom{n}{t}\left(\frac{3}{4}\right)^t\left(\frac{1}{4}\right)^{n-t}+\binom{n}{t}\left(\frac{1}{3}\right)^t\left(\frac{2}{3}\right)^{n-t}}\)</span>
<span class="math inline">\(=\dfrac{1}{1+\left(\frac{1}{6}\right)^t\left(\frac{8}{3}\right)^{n}}\)</span> <span class="math inline">\(=p_x\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>O risco posterior das decisões <span class="math inline">\(d_1\)</span> e <span class="math inline">\(d_2\)</span> são, respectivamente, <span class="math inline">\(r_x(d_1)=10(1-p_x)\)</span> e <span class="math inline">\(r_x(d_2)=5p_x\)</span>, de modo que decide-se por <span class="math inline">\(d_1\)</span> se</p>
<p><span class="math inline">\(r_x(d_1)\leq r_x(d_2)\)</span> <span class="math inline">\(~\Longleftrightarrow~ 10(1-p_x) \leq 5p_x\)</span>
<span class="math inline">\(~\Longleftrightarrow~ p_x \geq \frac{10}{15}= \frac{2}{3}\)</span>
<span class="math inline">\(~\Longleftrightarrow~ \dfrac{1}{1+\left(\frac{1}{6}\right)^t\left(\frac{8}{3}\right)^{n}} \geq \frac{2}{3}\)</span>
<span class="math inline">\(~\Longleftrightarrow~ \left(\frac{1}{6}\right)^t\left(\frac{8}{3}\right)^{n} \leq \frac{1}{2}\)</span>
<span class="math inline">\(~\Longleftrightarrow~ \left(\frac{1}{6}\right)^t\left(\frac{8}{3}\right)^{n} \leq \frac{1}{2}\)</span>
<span class="math inline">\(~\Longleftrightarrow~ -t\log(6) \leq n\log\left(\frac{3}{8}\right)-\log\left(2\right)\)</span>
<span class="math inline">\(~\Longleftrightarrow~ t\geq -n\log_6\left(\frac{3}{8}\right)+\log_6\left(2\right) = k_n\)</span>,</p>
<p>e a função de decisão de Bayes é</p>
<p><span class="math inline">\({\delta}^*(\boldsymbol X) = \left\{ \begin{array}{ccl} d_1 &amp;,&amp; \sum X_i ~\geq~ k_n ~~\approx~~ 0.55 n + 0.39 \\ d_2 &amp;,&amp; \text{caso contrário} \end{array}\right.\)</span></p>
<p><span class="math inline">\(~\)</span></p>
<p>O risco de Bayes neste caso é</p>
<p><span class="math inline">\({\rho}^*(P)\)</span> <span class="math inline">\(= E\left[L\left(\delta^*(x),\theta\right)\right]\)</span>
<span class="math inline">\(=10~P\left(\delta^*(x)=d_1,\theta=\theta_2\right)+5~P\left(\delta^*(x)=d_2,\theta=\theta_1\right)\)</span>
<span class="math inline">\(=10\dfrac{1}{2}~P\left(\sum X_i ~\geq~ k_n ~\Big|~ \theta=\dfrac{1}{3}\right)+5~\dfrac{1}{2}~P\left(\sum X_i ~&lt;~ k_n ~\Big|~ \theta=\dfrac{3}{4}\right)\)</span>
<span class="math inline">\(=5~P\left(Bin\left(n,\frac{1}{3}\right) ~\geq~ k_n \right)+2.5~P\left(Bin\left(n,\frac{3}{4}\right) ~&lt;~ k_n \right)\)</span>.</p>
<p><span class="math inline">\(~\)</span></p>
<p>Suponha agora que há um custo <span class="math inline">\(c(n)\)</span> por essas <span class="math inline">\(n\)</span> observações e que a função de perda é dada por <span class="math inline">\(L(d,\theta,n) = L(d,\theta) + c(n)\)</span>. Essa função custo <span class="math inline">\(c: \mathbb{N} \rightarrow \mathbb{R}\)</span> pode depender de questões além das financeiras, como, por exemplo, o tempo de coleta da amostra ou algum risco aos envolvidos no experimento. Considere, por simplicidade, uma função de custo linear <span class="math inline">\(c(n) = 0.02n\)</span>, de modo que o risco é</p>
<p><span class="math inline">\({\rho}_n(P)\)</span> <span class="math inline">\(= {\rho}^*(P) + c(n)\)</span> <span class="math inline">\(=5~P\left(Bin\left(n,\frac{1}{3}\right) ~\geq~ k_n \right)+2.5~P\left(Bin\left(n,\frac{3}{4}\right) ~&lt;~ k_n \right) + 0.02n\)</span>.</p>
<p>A seguir é apresentado um gráfico desse risco para alguns valores de <span class="math inline">\(n\)</span> e é possível notar que o tamanho amostral ótimo é <span class="math inline">\({n}^*=20\)</span>.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="Estimacao.html#cb14-1"></a><span class="kw">tibble</span>(<span class="dt">n=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">80</span>),</span>
<span id="cb14-2"><a href="Estimacao.html#cb14-2"></a>       <span class="dt">kn=</span><span class="op">-</span>n<span class="op">*</span><span class="kw">log</span>(<span class="dv">3</span><span class="op">/</span><span class="dv">8</span>,<span class="dv">6</span>)<span class="op">+</span><span class="kw">log</span>(<span class="dv">2</span>,<span class="dv">6</span>),</span>
<span id="cb14-3"><a href="Estimacao.html#cb14-3"></a>       <span class="dt">risco=</span><span class="dv">5</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pbinom</span>(kn,n,<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>))<span class="op">+</span><span class="fl">2.5</span><span class="op">*</span><span class="kw">pbinom</span>(kn,n,<span class="dv">3</span><span class="op">/</span><span class="dv">4</span>)<span class="op">+</span><span class="fl">0.02</span><span class="op">*</span>n) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb14-4"><a href="Estimacao.html#cb14-4"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb14-5"><a href="Estimacao.html#cb14-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>n,<span class="dt">y=</span>risco)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb14-6"><a href="Estimacao.html#cb14-6"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>n[<span class="kw">which.min</span>(risco)],<span class="dt">y=</span><span class="kw">min</span>(risco)),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">cex=</span><span class="fl">2.5</span>)</span></code></pre></div>
<p><img src="InfBayes_files/figure-html/unnamed-chunk-23-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(~\)</span></p>
<p>No exemplo anterior, foi apresentado uma maneira de considerar custos das observações e obter um tamanho amostral ótimo para determinado problema de decisão. Quando o custo está relacionado somente a quantidades monetárias, funções de custo lineares não são as mais adequadas. Para uma discussão bastante didática sobre esse problema, veja o artigo <em>O Paradoxo de São Petersburgo</em> (Peixoto, C. M. e Wechsler, S.) no <a href="https://www.ime.usp.br/~isbra/boletim/boletim_2013_v06_n02.pdf">Boletim da ISBrA, 6(2)</a>.</p>
<p><span class="math inline">\(~\)</span></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="TeoDec.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Test.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["InfBayes.pdf", "InfBayes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
